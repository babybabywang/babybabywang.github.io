<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[快速入门JAVA 8新特性]]></title>
    <url>%2F2019%2F02%2F24%2F%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8JAVA8%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[1. Java 8新特性简介 速度更快 代码更少(增加了新的语法Lambda表达式) 强大的Stream API 便于并行 最大化减少空指针异常Optional 2.对于HashMap的数据结构改造 ​ 将JDK1.7中Hash Map的数组+链表的数据结构在JDK1.8时改变为数组+链表+红黑树，当Hash Map数组的总容量大于64，链表长度大于8时，会自动将链表扩展为红黑树，这样有利于解决hash冲突，解决了链表过长时，hash算法后的equals算法的效率变低的情况。红黑树的效率除了添加不如链表外，其他都远远大于链表的效率。类似的HashSet和ConcurrentHashMap的数据结构都变了、 3.ConcurrentHashMap ​ JDK1.7时concurrentLevel(并发级别)为16，在JDK1.8时改为无锁算法CAS算法。因此效率也大大提升了。 4.底层内存结构 ​ JDK1.8中底层内存结构也发现了改变，HotSpot虚拟机中将永久区(PremGen)用MetaSpace元空间代替，它使用的为物理内存。JVM调优中的PremSize和MaxPremSize都已经不被支持了，取而代之的为MetaSpaceSize和MaxMetaSpaceSize，这种情况下也不容易出现OOM异常了。 5.Lambda表达式 ​ Lambda 是一个匿名函数，我们可以把 Lambda 表达式理解为是一段可以传递的代码（将代码像数据一样进行传递）。可以写出更简洁、更灵活的代码。作为一种更紧凑的代码风格，使Java的语言表达能力得到了 以下几段代码可以让我们感受下Lambda表达式的有点 1.快速入门1.匿名内部类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * 匿名内部类的转换 * @author huangsm * @version V1.0 */public class LambdaTest1 &#123; public static void main(String[] args) &#123; //使用匿名内部类比较俩个Integer大小 Comparator&lt;Integer&gt; comparator=new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return Integer.compare(o1,o2); &#125; &#125;; //使用匿名内部类 TreeSet&lt;Integer&gt; ts=new TreeSet&lt;&gt;(comparator); //使用lambda表达式解决匿名内部类 Comparator&lt;Integer&gt; com = (a, b) -&gt; Integer.compare(a, b); List&lt;Employee&gt; employees= Arrays.asList( new Employee("huangsm",22,40020.0), new Employee("huangsm1",24,52300.0), new Employee("huangsm2",26,40100.0), new Employee("huangsm3",21,42300.0) ); //需求:获取当前公司中员工年龄大于25的员工信息（优化方式1.策略模式优化方式这里就不实现了，直接使用匿名内部类的方式优化） /** * 优化方法2，匿名内部类 */ List&lt;Employee&gt; employees1 = filterEmployees(employees, new MyPredicat&lt;Employee&gt;() &#123; @Override public boolean test(Employee employee) &#123; return employee.getAge() &gt; 25; &#125; &#125;); /** * 使用lambda表达式优化 */ List&lt;Employee&gt; employees2 = filterEmployees(employees, (e)-&gt;e.getAge()&gt;25); employees2.forEach(System.out::println); &#125; /** * 过滤方法 * @param employees * @param myPredicat * @return */ public static List&lt;Employee&gt; filterEmployees(List&lt;Employee&gt; employees,MyPredicat&lt;Employee&gt; myPredicat)&#123; List&lt;Employee&gt; emps=new ArrayList&lt;&gt;(); employees.forEach(e-&gt;&#123; if (myPredicat.test(e))&#123; emps.add(e); &#125; &#125;); return emps; &#125;&#125; ### 2.Stream函数的最终优化 12345/*** * stream方式操作 过滤掉年龄小于25的员工 */List&lt;Employee&gt; collect = employees.stream().filter((e) -&gt; e.getAge() &lt; 25).collect(Collectors.toList());collect.forEach(System.out::println); 123456789/*** * stream方式操作 得到员工名第一个年龄小于25 */List&lt;String&gt; names = employees.stream(). filter((e) -&gt; e.getAge() &lt; 25). limit(1). map(Employee::getName). collect(Collectors.toList());names.forEach(System.out::println); 2.Lambda表达式的基本语法 ​Lambda 表达式在Java 语言中引入了一个新的语法元素和操作符。这个操作符为 “-&gt;” ， 该操作符被称为 Lambda 操作符或剪头操作符。它将 Lambda 分为两个部分： 左侧：指定了 Lambda 表达式需要的所有参数右侧：指定了 Lambda 体，即 Lambda 表达式要执行的功能 1.语法一123456789101112/** * lambda表达式的基本语法 * 语法格式一:无参数，无返回值 * ()-&gt;System.out.println("hello"); */@Testpublic void lambda1()&#123; //JDK1.7以前必须为final，Java8后不需要我们手动加final了 int num=0; Runnable hello = () -&gt; System.out.println("hello"+num); hello.run();&#125; 2.语法二123456789/** * 语法格式二:一个参数，无返回值,如果左侧有一个参数小括号可以省略不写 * (e)-&gt;System.out.println(e); */@Testpublic void lambda2()&#123; Consumer&lt;String&gt; consumer=x-&gt; System.out.println(x); consumer.accept("你好兄弟");&#125; 3.语法三1234567891011121314/** * 语法格式三:多个参数，又返回值，并且Lambda体中有多条语句，如果只有一条语句，return和大括号都可以不写 */@Testpublic void lambda3()&#123; Comparator&lt;Integer&gt; com=(x,y)-&gt;&#123; System.out.println("函数式接口"); return x+y; &#125;; //如果只有一条语句，return和大括号都可以不写 Comparator&lt;Integer&gt; com1=(x,y)-&gt; x+y; int compare = com.compare(1, 2); System.out.println(compare);&#125; 4.语法四1234567891011121314151617181920/** * 语法格式6:Lambda表达式的参数列表的数据类型可以省略不写， * 因为JVM编译器通过上下文推断出类型， * 这个过程成为类型推断 */@Testpublic void lambda4()&#123; /** * 类型推断上述 Lambda 表达式中的参数类型都是由编译器推断得出的。 * Lambda 表达式中无需指定类型，程序依然可以编译，这是因为 javac 根据程序的上下文， * 在后台推断出了参数的类型。 * Lambda 表达式的类型依赖于上下文环境，是由编译器推断出来的。 * 这就是所谓的"类型推断" * JAVA8中可以通过目标方法就能推断出类型。 */ Comparator&lt;Integer&gt; com=(Integer x,Integer y)-&gt;&#123; System.out.println("函数式接口"); return x+y; &#125;;&#125; 注意: Lambda表达式左右遇一括号省，左侧推断类型省 ３.函数式接口 只包含一个抽象方法的接口，称为函数式接口。 你可以通过 Lambda 表达式来创建该接口的对象。（若 Lambda 表达式抛出一个受检异常，那么该异常需要在目标接口的抽象方法上进行声明）。 我们可以在任意函数式接口上使用 @FunctionalInterface 注解，这样做可以检查它是否是一个函数式接口，同时 javadoc 也会包含一条声明，说明这个接口是一个函数式接 1.函数式接口Demo123456789package com.study.newjava8.lambda;/** * 函数式接口 */@FunctionalInterfacepublic interface MyFunction &#123; public Integer getValue(Integer num);&#125; 12345678910//需求:对一个数进行运算@Testpublic void functionInterface1() &#123; Integer operation = operation(100, (x) -&gt; x * x); System.out.println(operation);&#125;public Integer operation(Integer num, MyFunction mf) &#123; return mf.getValue(num);&#125; 2.使用Java8内置函数接口 消费型接口Consumer接口 123456789101112/** * Java8内置的四大核心函数式接口 * Consumer&lt;T&gt;:消费型接口 * void accept(T t) */@Testpublic void consumer()&#123; happy(100.0,(x)-&gt; System.out.println("消费了"+x+"钱"));&#125;public void happy(double money,Consumer&lt;Double&gt; consumer)&#123; consumer.accept(money);&#125; 供给型接口Supplier接口 1234567891011121314151617181920212223/** * Supplier&lt;T&gt;:供给型接口 * T get() */@Testpublic void supplier()&#123; List&lt;Integer&gt; numList = getNumList(10, () -&gt;(int)(Math.random() * 100)); numList.forEach(System.out::println);&#125;/** * 产生数的集合 * @param num * @param sup * @return */public List&lt;Integer&gt; getNumList(int num,Supplier&lt;Integer&gt; sup)&#123; List&lt;Integer&gt; list=new ArrayList&lt;&gt;(); for (int i = 0; i &lt; num; i++) &#123; list.add(sup.get()); &#125; return list;&#125; 函数型接口Function接口 1234567891011121314151617181920/** * Function&lt;T&gt;: 函数型接口 * R apply(T t) */@Testpublic void function()&#123; //将小写转换为大写 String abcdec = handlerStr("abcdec", (str) -&gt; str.toUpperCase()); System.out.println(abcdec);&#125;/** * 处理字符串函数 * @param str * @param function * @return */public String handlerStr(String str, Function&lt;String,String&gt; function)&#123; return function.apply(str);&#125; 断定型接口Predicate接口 123456789101112131415161718192021222324252627/** * Predicate&lt;T&gt;:断言型接口 * boolean test(T t) */@Testpublic void predicate() &#123; List&lt;String&gt; list = Arrays.asList("hello", "huangsm", "lambda"); List&lt;String&gt; strings = filterStr(list, (a) -&gt; a.length() &gt; 3); strings.forEach(System.out::println);&#125;/** * 将满足条件的字符串放入新的集合中 * * @param list * @param predicate * @return */public List&lt;String&gt; filterStr(List&lt;String&gt; list, Predicate&lt;String&gt; predicate) &#123; List&lt;String&gt; strList = new ArrayList&lt;&gt;(); list.forEach(str -&gt; &#123; if (predicate.test(str)) &#123; strList.add(str); &#125; &#125;); return strList;&#125; 4.方法引用与构造器引用1.方法引用 当要传递给Lambda体的操作，已经有实现的方法了，可以使用方法引用！（实现抽象方法的参数列表，必须与方法引用方法的参数列表保持一致！）方法引用：使用操作符 “::” 将方法名和对象或类的名字分隔开来。 如下三种主要使用情况 对象 :: 实例方法名 123456789101112131415161718192021222324252627282930/** * 方法引用:若Lambda体中的内容有方法已经实现了，我们可以使用"方法引用" * (可以理解为方法引用是Lambda 表达式的另一种表达形式) * * 主要有三种语法格式 * 对象 :: 实例方法名 * 类 :: 静态方法名 * 类 :: 实力方法名 * * (Lambda 体中调用方法的参数列表与返回值类型，要与函数式接口的参数列表与返回值保持一致) */@Testpublic void test1()&#123; Consumer&lt;String&gt; con=x-&gt; System.out.println(x); //对象 :: 实例方法名 PrintStream out = System.out; Consumer&lt;String&gt; con1=out::println;&#125;@Testpublic void test2()&#123; Employee employee=new Employee(); Supplier&lt;String&gt; sup=()-&gt;employee.getName(); System.out.println(sup.get()); Supplier&lt;Integer&gt;sup2=employee::getAge; System.out.println(sup2.get());&#125; 类 :: 静态方法名 123456789/** * 类 :: 静态方法名 */@Testpublic void test3()&#123; Comparator&lt;Integer&gt; com=(x,y)-&gt;Integer.compare(x,y); Comparator&lt;Integer&gt;com1=Integer::compare; com1.compare(1,2);&#125; 类 :: 实力方法名 123456789101112/** * 类 :: 实力方法名 * Lambda参数列表中的第一个参数是实例方法的调用者，而第二个参数是实例方法的参数时，可以使用ClassName::method */@Testpublic void test4()&#123; BiPredicate&lt;String,String&gt; biPredicate=(x,y)-&gt;x.equals(y); System.out.println(biPredicate.test("hsm","huang")); BiPredicate&lt;String,String&gt; b1=String::equals; System.out.println(b1.test("hsm","hsm"));&#125; 2.构造器引用 与函数式接口相结合，自动与函数式接口中方法兼容。可以把构造器引用赋值给定义的方法，与构造器参数列表要与接口中抽象方法的参数列表一致！ 123456789101112131415161718192021222324252627/** * 构造器引用 * ClassName::new */@Testpublic void test5()&#123; Supplier&lt;Employee&gt;sup=()-&gt;new Employee(); //构造器引用 Supplier&lt;Employee&gt;sup2=Employee::new;&#125;/*** 使用多参数的构造器* 注意:需要调用的构造器的参数列表要与函数式接口中抽象方法的参数列表保持一直*/@Testpublic void test6()&#123; Function&lt;Integer,Employee&gt;fun=Employee::new; Employee apply = fun.apply(1); System.out.println(apply); //使用俩个参数的构造器 BiFunction&lt;String,Integer,Employee&gt;bf=Employee::new; Employee huangsm = bf.apply("huangsm", 22); System.out.println(huangsm);&#125; 3.数组引用12345678910111213/** * 数组引用 * type::new */@Testpublic void test7()&#123; Function&lt;Integer,String[]&gt; fun=(x)-&gt;new String[x]; String[] apply = fun.apply(10); System.out.println(apply.length); Function&lt;Integer,String[]&gt; fun1=String[]::new; System.out.println(fun1.apply(11).length);&#125; 6.Stream Api1.了解Stream Java 8中有两大最为重要的改变。第一个是 Lambda 表达式；另外一个则是 StreamAPI(java.util.stream.*)。Stream 是 Java 8 中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的查找、过滤和映射数据等操作。使用Stream API 对集合数据进行操作，就类似于使用 SQL 执行的数据库查询。也可以使用 Stream API 来并行执行操作。简而言之，Stream API 提供了一种高效且易于使用的处理数据的方式。 2.什么是Stream流（Stream）到底是什么呢? 是数据渠道，用于操作数据源(集合、数组等)所生成的元素序列。 “集合讲的是数据，流讲的是计算” 注意: Stream 自己不会存储元素。 Stream 不会改变源对象。相反，他们会返回一个持有结构的新Stream。 Stream‘ 操作是延迟执行的。这意味着他们会等到需要结果的时候才执行。 3.创建流的三个步骤 4.创建流的四种方式123456789101112131415161718192021222324/** * 创建Stream的四种方式 */@Testpublic void test1()&#123; //1.可以通过Collection系列集合提供的stream()或parallelStream() List&lt;String&gt; list=new ArrayList&lt;&gt;(); //获取流的第一种方式 Stream&lt;String&gt; stream1 = list.stream(); //2.通过Arrays中的静态方法stream()获取数组流 Employee [] employees=new Employee[10]; Stream&lt;Employee&gt; stream2 = Arrays.stream(employees); //3.通过Stream类的静态方法of() Stream&lt;String&gt; stream3 = Stream.of("aaa", "bb"); //4.创建无限流，通过iterate()和generate() //迭代 Stream&lt;Integer&gt; stream4 = Stream.iterate(0, (x) -&gt; x + 2); stream4.limit(10).forEach(System.out::println); //生成 产生随机double Stream&lt;Double&gt; stream5 = Stream.generate(() -&gt; Math.random()); stream5.limit(10).forEach(System.out::println);&#125; 5.流的中间操作 多个中间操作可以连接起来形成一个流水线，除非流水线上触发终止操作，否则中间操作不会执行任何的处理！而在终止操作时一次性全部处理，称为“惰性求值”。 1.筛选与切片 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354List&lt;Employee&gt; employees = Arrays.asList( new Employee("huangsm", 22, 40020.0), new Employee("huangsm1", 24, 52300.0), new Employee("huangsm1", 24, 52300.0), new Employee("huangsm1", 24, 52300.0), new Employee("huangsm2", 26, 40100.0), new Employee("huangsm3", 21, 42300.0));/** * 筛选与切片 * filter--接收一个Lambda，从流中排除某些元素 */@Testpublic void test1() &#123; Stream&lt;Employee&gt; stream = employees.stream() .filter(e -&gt; e.getAge() &gt; 25); //终止操作 stream.forEach(System.out::println);&#125;/** * limit--截断流，使其元素不超过给定数量。 * 只需要找到满足条件的结果以后，后续操作不需要在操作了。 */@Testpublic void test2() &#123; employees.stream() .limit(4) .forEach(System.out::println);&#125;/** * skip(n)--跳过元素，返回一个扔掉了前n个元素的流。若流中元素 * 不足n个，则返回一个空流。与limit(n)互补。 */@Testpublic void test3() &#123; //跳过前两个 employees.stream() .skip(2) .forEach(System.out::println);&#125;/** * distinct--筛选，通过流锁生成元素的hashCode()和equals()去除重复元素 */@Testpublic void test4() &#123; //去重复 employees.stream() .distinct() .forEach(System.out::println);&#125; 2.映射 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 映射 * map--接收Lambda，将元素转换成其他形式或提取信息。接收一个函数作为参数，该元素会被应用到每个元素上，并将映射成一个新的元素 */@Testpublic void test1()&#123; employees.stream() .map(Employee::getAge) .distinct() .forEach(System.out::println);&#125;/** * 将字符串转换为字符流 * @param str * @return */public static Stream&lt;Character&gt; filterCharacter(String str)&#123; List&lt;Character&gt;list=new ArrayList&lt;&gt;(); for (Character character : str.toCharArray()) &#123; list.add(character); &#125; return list.stream();&#125;/** * flatMap--接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流 */@Testpublic void test2()&#123; List&lt;String&gt; list = Arrays.asList("aa", "bb", "cc"); Stream&lt;Stream&lt;Character&gt;&gt; streamStream = list.stream() .map(TestStreamAPI3::filterCharacter);//&#123;a,a&#125;,&#123;b,b&#125; //遍历 streamStream.forEach((sm)-&gt;&#123; sm.forEach(System.out::println); &#125;); //使用flatMap list.stream() .flatMap(TestStreamAPI3::filterCharacter)//&#123;a,a,b,b&#125; .forEach(System.out::println);&#125; 3.排序 123456789101112131415161718192021/** * 排序 * sorted()--自然排序 * sorted(Comparator com)--定制排序 */@Testpublic void test3()&#123; List&lt;String&gt; list = Arrays.asList("cc","dd","aa", "bb", "ee"); list.stream() .sorted() .forEach(System.out::println); employees.stream() .sorted((e1,e2)-&gt;&#123; if (e1.getAge().equals(e2.getAge()))&#123; return e1.getName().compareTo(e2.getName()); &#125;else &#123; return e1.getAge().compareTo(e2.getAge()); &#125; &#125;).forEach(System.out::println);&#125; 6.Stream Api的终止操作 终端操作会从流的流水线生成结果。其结果可以是任何不是流的值，例如：List、Integer，甚至是 void 。 1.查找与匹配 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 查询与匹配 * allMatch-检查是否匹配所有元素 */@Testpublic void test1() &#123; boolean b1 = employees.stream() .allMatch((e) -&gt; e.getStatus().equals(Employee.Status.BUSY)); System.out.println(b1);&#125;/** * anyMatch-检查是否至少匹配一个元素 */@Testpublic void test2()&#123; boolean b = employees.stream() .anyMatch(e -&gt; e.getStatus().equals(Employee.Status.BUSY)); System.out.println(b);&#125;/** * noneMatch--检查是否没有匹配所有元素 * findFirst--返回第一个元素 * findAny--返回当前流中的任意元素 * count--返回流中元素的总个数 * max--返回流中的最大值 * min--返回流中最小值 */@Testpublic void test3()&#123; Optional&lt;Employee&gt; first = employees.stream() .sorted((e1, e2) -&gt; Double.compare(e1.getSalary(), e2.getSalary())) .findFirst(); System.out.println(first.get()); Optional&lt;Employee&gt; any = employees.parallelStream() .filter(e-&gt;e.getStatus().equals(Employee.Status.FREE)) .findAny(); System.out.println(any.get()); long count = employees.stream() .count(); System.out.println(count); Optional&lt;Employee&gt; max = employees.stream() .max((e1, e2) -&gt; Double.compare(e1.getSalary(), e2.getSalary())); System.out.println(max.get()); //最低工资 Optional&lt;Double&gt; min = employees.stream() .map(Employee::getSalary) .min(Double::compareTo); System.out.println(min.get());&#125; 2.归约 1234567891011121314151617181920/** * 归约 * reduce(T identity,BinaryOperator)/reduce(BinaryOperator) * 可以将流中反复结合起来，得到一个值 */@Testpublic void test4()&#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10); //从0+10的总和 Integer sum = list.stream() .reduce(0, (a, n) -&gt; a + n); System.out.println(sum); //计算当前公司中工资的总和 Optional&lt;Double&gt; salary = employees.stream() .map(Employee::getSalary) .reduce(Double::sum); System.out.println(salary.get());&#125; 3.收集 Collector 接口中方法的实现决定了如何对流执行收集操作(如收集到 List、Set、Map)。但是 Collectors 实用类提供了很多静态方法，可以方便地创建常见收集器实例，具体方法与实例如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576/** * 收集 * collect--将流转换为其他形式。接收一个Collector接口的实现，用于Stream中元素做汇总方法 */@Testpublic void test5()&#123; List&lt;String&gt; collect = employees.stream() .map(Employee::getName) .collect(Collectors.toList()); collect.forEach(System.out::println); //搜集的数据放到特殊集合中 HashSet&lt;String&gt; collect1 = employees.stream() .map(Employee::getName) .collect(Collectors.toCollection(HashSet::new));&#125;@Testpublic void test6()&#123; Long collect = employees.stream() .collect(Collectors.counting()); //总数 System.out.println(collect); Double collect1 = employees.stream() .collect(Collectors.averagingDouble((e1) -&gt; e1.getSalary())); //工资的平均值 System.out.println(collect1); DoubleSummaryStatistics collect2 = employees.stream() .collect(Collectors.summarizingDouble(e -&gt; e.getSalary())); //综合 System.out.println(collect2.getSum()); //得到工资最小值 Optional&lt;Double&gt; collect3 = employees.stream() .map(Employee::getSalary) .collect(Collectors.minBy(Double::compare)); System.out.println(collect3.get());&#125;/** * 分组 */@Testpublic void test7()&#123; Map&lt;Employee.Status, List&lt;Employee&gt;&gt; collect1 = employees.stream() .collect(Collectors.groupingBy(Employee::getStatus)); Map&lt;Employee.Status, List&lt;Employee&gt;&gt; collect = collect1; System.out.println(collect1);&#125;/** * 多级分组 */@Testpublic void test8()&#123; Map&lt;Employee.Status, Map&lt;String, List&lt;Employee&gt;&gt;&gt; collect = employees.stream() .collect(Collectors.groupingBy(Employee::getStatus, Collectors.groupingBy(e -&gt; &#123; if (e.getAge() &lt;= 35) &#123; return "青年"; &#125; else &#123; return "老年"; &#125; &#125;))); System.out.println(collect);&#125;/** * 分区 */@Testpublic void test9()&#123; Map&lt;Boolean, List&lt;Employee&gt;&gt; collect = employees.stream() .collect(Collectors.partitioningBy(e -&gt; e.getSalary() &gt; 45000)); System.out.println(collect);&#125; 7.并行流与串行流 并行流就是把一个内容分成多个数据块，并用不同的线程分别处理每个数据块的流。Java 8 中将并行进行了优化，我们可以很容易的对数据进行并行操作。Stream API 可以声明性地通过 parallel() 与sequential() 在并行流与顺序流之间进行切换。 1.了解Fork/Join框架 Fork/Join 框架：就是在必要的情况下，将一个大任务，进行拆分(fork)成若干个小任务（拆到不可再拆时），再将一个个的小任务运算的结果进行 join 汇总。 Fork/Join 框架与传统线程池的区别 采用 “工作窃取”模式（work-stealing）：当执行新的任务时它可以将其拆分分成更小的任务执行，并将小任务加到线程队列中，然后再从一个随机线程的队列中偷一个并把它放在自己的队列中。 相对于一般的线程池实现,fork/join框架的优势体现在对其中包含的任务的处理方式上.在一般的线程池中,如果一个线程正在执行的任务由于某些原因无法继续运行,那么该线程会处于等待状态.而在fork/join框架实现中,如果某个子问题由于等待另外一个子问题的完成而无法继续运行.那么处理该子问题的线程会主动寻找其他尚未运行的子问题来执行.这种方式减少了线程的等待时间,提高了性能。 1.自定义Fork/Join类1234567891011121314151617181920212223242526272829303132333435363738394041/** * 使用Fork/Join框架 * RecursiveAction 里面的方法没有返回值 * RecursiveTask有返回值 */public class ForkJoinText extends RecursiveTask&lt;Long&gt; &#123; private long start; private long end; public ForkJoinText(long start, long end) &#123; this.start = start; this.end = end; &#125; /** * 拆分的临界值 */ private static final long THRESHOLD = 10000; @Override protected Long compute() &#123; long length = end - start; if (length &lt;= THRESHOLD) &#123; long sum = 0; for (long i = start; i &lt;=end; i++) &#123; sum += i; &#125; return sum; &#125; else &#123; long middle = (start + end) / 2; ForkJoinText left = new ForkJoinText(start, middle); //拆分子任务，同时压入线程队列 left.fork(); ForkJoinText right = new ForkJoinText(middle + 1, end); right.fork(); return left.join() + right.join(); &#125; &#125;&#125; 1234567891011121314/** * 使用ForkJoin完成0到1亿累加 */@Testpublic void test1()&#123; ForkJoinPool pool=new ForkJoinPool(); Instant start = Instant.now(); ForkJoinTask&lt;Long&gt; task= new ForkJoinText(0,10000000000L); Long sum = pool.invoke(task); Instant end =Instant.now(); System.out.println(sum); System.out.println(Duration.between(start,end).toMillis());&#125; 2.JAVA8并行流的使用12345678910111213141516/** * java并行流 */@Testpublic void test3()&#123; Instant start = Instant.now(); //切换成并行流 long sum = LongStream.rangeClosed(0, 100000000L) .parallel() .reduce(0, Long::sum); Instant end =Instant.now(); System.out.println(sum); System.out.println(Duration.between(start,end).toMillis());&#125; 7.Optional 类 Optional 类(java.util.Optional) 是一个容器类，代表一个值存在或不存在，原来用 null 表示一个值不存在，现在 Optional 可以更好的表达这个概念。并且可以避免空指针异常。 常用方法：Optional.of(T t) : 创建一个 Optional 实例Optional.empty() : 创建一个空的 Optional 实例Optional.ofNullable(T t):若 t 不为 null,创建 Optional 实例,否则创建空实例isPresent() : 判断是否包含值orElse(T t) : 如果调用对象包含值，返回该值，否则返回torElseGet(Supplier s) :如果调用对象包含值，返回该值，否则返回 s 获取的值map(Function f): 如果有值对其处理，并返回处理后的Optional，否则返回 Optional.empty()flatMap(Function mapper):与 map 类似，要求返回值必须是Optional 123456@AllArgsConstructor@NoArgsConstructor@Datapublic class NewMan &#123; private Optional&lt;Godness&gt; godness=Optional.empty();&#125; 1234567@Data@AllArgsConstructor@NoArgsConstructorpublic class Godness &#123; private String name;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * Optional容器类 */public class OptionalDemo &#123; /** * Optional.of(T t) : 创建一个 Optional 实例 * Optional.empty() : 创建一个空的 Optional 实例 * Optional.ofNullable(T t):若 t 不为 null,创建 Optional 实例,否则创建空实例 * isPresent() : 判断是否包含值 * orElse(T t) : 如果调用对象包含值，返回该值，否则返回t * orElseGet(Supplier s) :如果调用对象包含值，返回该值，否则返回 s 获取的值 * map(Function f): 如果有值对其处理，并返回处理后的Optional，否则返回 Optional.empty() * flatMap(Function mapper):与 map 类似，要求返回值必须是Optional */ @Test public void map()&#123; Optional&lt;Employee&gt; op = Optional.of(new Employee(1)); /* Optional&lt;Integer&gt; s = op.map(e -&gt; e.getAge()); System.out.println(s.get());*/ Optional&lt;Integer&gt; integer = op.flatMap((e) -&gt; Optional.of(e.getAge())); System.out.println(integer.get()); &#125; @Test public void test3()&#123; Optional&lt;Employee&gt; employee = Optional.ofNullable(new Employee()); /*if (employee.isPresent())&#123; System.out.println(employee.get()); &#125;*/ Employee employee1 = employee.orElseGet(Employee::new); System.out.println(employee1); &#125; @Test public void test2()&#123; Optional&lt;Object&gt; empty = Optional.empty(); System.out.println(empty.get()); &#125; @Test public void test1()&#123; //of中不能构建null Optional&lt;Employee&gt; op = Optional.of(new Employee()); System.out.println(op.get()); &#125; //题目 @Test public void test5()&#123; /* Man man=new Man(); String godnessName = getGodnessName(man); System.out.println(godnessName);*/ // man.setGodness(new Godness("张三")); Optional&lt;NewMan&gt; op = Optional.ofNullable(new NewMan(Optional.of(new Godness("王菠萝")))); String godnessName2 = getGodnessName2(op); System.out.println(godnessName2); &#125; public String getGodnessName2(Optional&lt;NewMan&gt; newMan)&#123; return newMan.orElse(new NewMan()) .getGodness() .orElse(new Godness("wangqq")) .getName(); &#125; //获取一个男人心中女神的名字 public String getGodnessName(Man man)&#123; return man.getGodness().getName(); &#125;&#125; 8.接口中的默认方法与静态方法1.接口中的默认 Java 8中允许接口中包含具有具体实现的方法，该方法称为“默认方法”，默认方法使用 default 关键字修饰。 接口默认方法的”类优先”原则若一个接口中定义了一个默认方法，而另外一个父类或接口又定义了一个同名的方法时。 123456789public interface MyFun &#123; /** * 可以不被实现，默认方法 * @return */ default String getName()&#123; return "huangsm"; &#125;&#125; 选择父类中的方法。如果一个父类提供了具体的实现，那么接口中具有相同名称和参数的默认方法会被忽略 接口冲突。如果一个父接口提供一个默认方法，而另一个接口也提供了一个具有相同名称和参数列表的方法（不管方是否是默认方法），那么必须覆盖该方法来解决冲突 2.接口默认方法的”类优先”原则123456789public interface MyFun &#123; /** * 可以不被实现，默认方法 * @return */ default String getName()&#123; return "huangsm"; &#125;&#125; 12345public class MyClass &#123; public String getName()&#123; return "wqq"; &#125;&#125; 12public class SubClass extends MyClass implements MyFun &#123;&#125; 12345public static void main(String[] args) &#123; SubClass sc=new SubClass(); String name = sc.getName(); System.out.println(name);&#125; 3.接口中的静态 Java8 中，接口中允许添加静态 12345678public interface MyInterface &#123; default String getName()&#123; return "王球球"; &#125; public static String getHello()&#123; return "hello"; &#125;&#125; 9.新时间日期 API1.使用 LocalDate、LocalTime、LocalDateTime LocalDate、LocalTime、LocalDateTime 类的实例是不可变的对象，分别表示使用 ISO-8601日历系统的日期、时间、日期和时间。它们提供了简单的日期或时间，并不包含当前的时间信息。也不包含与时区相关的信息。 123456789101112131415161718192021222324252627/** *1.LocalDate LocalTime LocalDateTime */@Testpublic void test1()&#123; LocalDateTime localDateTime=LocalDateTime.now(); System.out.println(localDateTime); //自定义时间 LocalDateTime of = LocalDateTime.of(2015, 10, 19, 13, 22, 33); System.out.println(of); //时间运算 加10天，其他类似 LocalDateTime localDateTime1 = localDateTime.plusDays(10); System.out.println(localDateTime1); //加2个月 LocalDateTime localDateTime2 = localDateTime.minusMonths(2); System.out.println(localDateTime2); //得到年月或者月对象 System.out.println(localDateTime.getYear()); System.out.println(localDateTime.getDayOfMonth()); System.out.println(localDateTime.getMonthValue()); System.out.println(localDateTime.getHour()); System.out.println(localDateTime.getSecond());&#125; 2.Instant 时间戳 用于“时间戳”的运算。它是以Unix元年(传统的设定为UTC时区1970年1月1日午夜时分)开始所经历的描述进行运算 12345678910111213141516/** * 2. Instant:时间戳(以Unix元年:1970年1月1日00:00:00到某个时间之间的毫秒值) */@Testpublic void test2()&#123; //默认获取UTC时区 世界协调时间 Instant ins1 = Instant.now(); System.out.println(ins1); //偏移8小时 OffsetDateTime odt = ins1.atOffset(ZoneOffset.ofHours(8)); System.out.println(odt); System.out.println(ins1.toEpochMilli()); Instant instant = Instant.ofEpochSecond(1000); System.out.println(instant);&#125; 3.Duration 和 Period Duration:用于计算两个“时间” Period:用于计算两个“日期” 12345678910111213141516171819202122232425262728293031323334/** * 3.Duration:计算"时间"之间的间隔 * Period: 计算两个"日期"之间的间隔 **/@Testpublic void test3()&#123; Instant ins1=Instant.now(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; Instant ins2 = Instant.now(); System.out.println(Duration.between(ins1,ins2).toMillis()); System.out.println("----------------------------------"); //两个时间间的间隔 LocalTime lt1=LocalTime.now(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; LocalTime lt2=LocalTime.now(); System.out.println(Duration.between(lt1,lt2).toMillis());&#125; @Testpublic void test4()&#123; LocalDate ld1=LocalDate.now(); LocalDate ld2=LocalDate.of(2015,1,1); int days = Period.between(ld2, ld1).getDays(); System.out.println(days);&#125; 4.日期的操纵 TemporalAdjuster : 时间校正器。有时我们可能需要获取例如：将日期调整到“下个周日”等操作。 TemporalAdjusters : 该类通过静态方法提供了大量的常用 TemporalAdjuster 的实现。 123456789101112131415161718192021222324252627282930313233/** * - TemporalAdjuster : 时间校正器。有时我们可能需要获取例如：将日期调整到“下个周日”等操作。 * - TemporalAdjusters : 该类通过静态方法提供了大量的常用 TemporalAdjuster 的实现。 */@Testpublic void test5()&#123; LocalDateTime ldt=LocalDateTime.now(); System.out.println(ldt); //将月中的日指定为10 LocalDateTime ldt2 = ldt.withDayOfMonth(10); System.out.println(ldt2); //下一个周五 LocalDateTime ldt3= ldt.with(TemporalAdjusters.next(DayOfWeek.FRIDAY)); System.out.println(ldt3); //自定义:下一个工作日 LocalDateTime ldt5 = ldt.with((l) -&gt; &#123; LocalDateTime ldt4 = (LocalDateTime) l; //获取是周几 DayOfWeek dayOfWeek = ldt4.getDayOfWeek(); if (dayOfWeek.equals(DayOfWeek.FRIDAY)) &#123; //加三天 return ldt4.plusDays(3); &#125; else if (dayOfWeek.equals(DayOfWeek.SATURDAY)) &#123; return ldt4.plusDays(2); &#125; else &#123; return ldt4.plusDays(1); &#125; &#125;); System.out.println(ldt5);&#125; 5.解析与格式化java.time.format.DateTimeFormatter 类：该类提供了三种 格式化方法： 预定义的标准格式 12345DateTimeFormatter dtf=DateTimeFormatter.ISO_DATE_TIME;LocalDateTime ldt = LocalDateTime.now();String format = ldt.format(dtf);System.out.println(format);System.out.println("-----------"); 语言环境相关的格式 自定义的格式 1234//自定义DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");String format1 = ldt.format(dateTimeFormatter);System.out.println(format1); 6.时区的处理 Java8 中加入了对时区的支持，带时区的时间为分别为： ZonedDate、ZonedTime、ZonedDateTime 其中每个时区都对应着 ID，地区ID都为 “{区域}/{城市}”的格式 例如 ：Asia/Shanghai 等 ZoneId：该类中包含了所有的时区信息 getAvailableZoneIds() : 可以获取所有时区时区信息 of(id) : 用指定的时区信息获取 ZoneId 123456789101112131415161718192021/** * ZonedDate、ZonedTime、ZonedDateTime */@Testpublic void test7()&#123; //支持的时区 Set&lt;String&gt; set = ZoneId.getAvailableZoneIds(); set.forEach(System.out::println);&#125;@Testpublic void test8()&#123; LocalDateTime now = LocalDateTime.now(ZoneId.of("Europe/Monaco")); System.out.println(now); LocalDateTime ldt2 = LocalDateTime.now(ZoneId.of("US/Pacific")); ZonedDateTime zdt = ldt2.atZone(ZoneId.of("US/Pacific")); System.out.println(zdt );&#125; 10.重复注解与类型注解 Java 8对注解处理提供了两点改进：可重复的注解及可用于类型的注解。 自定义注解 123456789/** * 自定义注解 */@Repeatable(MyAnnotations.class)@Target(&#123;TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface MyAnnotation &#123; String value() default "huangsm";&#125; 多个注解 123456789/** * 重复注解 */@Target(&#123;TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface MyAnnotations &#123; MyAnnotation[] value();&#125; 使用 1234567891011121314151617@Testpublic void test1() throws Exception &#123; Class&lt;TestAnnotation&gt; clazz = TestAnnotation.class; Method m1 = clazz.getMethod("show", String.class); MyAnnotation[] ma = m1.getAnnotationsByType(MyAnnotation.class); for (int i = 0; i &lt; ma.length; i++) &#123; String value = ma[i].value(); System.out.println(value); &#125; Annotation[] annotations = m1.getAnnotations(); System.out.println(annotations);&#125;@MyAnnotation("Hello")@MyAnnotation("Wolrd")public void show(@MyAnnotation String a)&#123;&#125;]]></content>
      <categories>
        <category>JAVA 8</category>
      </categories>
      <tags>
        <tag>JAVA 8</tag>
        <tag>Lambda</tag>
        <tag>Stream Api</tag>
        <tag>新时间类型</tag>
        <tag>Optional</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[thymeleaf基本使用和语法简介]]></title>
    <url>%2F2019%2F02%2F23%2Fthymeleaf%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E5%92%8C%E8%AF%AD%E6%B3%95%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[1.Thymeleaf介绍Thymeleaf是用来开发Web和独立环境项目的现代服务器端Java模板引擎。 Thymeleaf的主要目标是为您的开发工作流程带来优雅的自然模板 - HTML。可以在直接浏览器中正确显示，并且可以作为静态原型，从而在开发团队中实现更强大的协作。 借助Spring Framework的模块，可以根据自己的喜好进行自由选择，可插拔功能组件，Thymeleaf是现代HTML5 JVM Web开发的理想选择 - 尽管它可以做的更多。 Spring官方支持的服务的渲染模板中，并不包含jsp。而是Thymeleaf和Freemarker等，而Thymeleaf与SpringMVC的视图技术，及SpringBoot的自动化配置集成非常完美，几乎没有任何成本，你只用关注Thymeleaf的语法即可。 官方网站 2.Thymeleaf特点特点： 动静结合：Thymeleaf 在有网络和无网络的环境下皆可运行，即它可以让美工在浏览器查看页面的静态效果，也可以让程序员在服务器查看带数据的动态页面效果。这是由于它支持 html 原型，然后在 html 标签里增加额外的属性来达到模板+数据的展示方式。浏览器解释 html 时会忽略未定义的标签属性，所以 thymeleaf 的模板可以静态地运行；当有数据返回到页面时，Thymeleaf 标签会动态地替换掉静态内容，使页面动态显示。 开箱即用：它提供标准和spring标准两种方言，可以直接套用模板实现JSTL、 OGNL表达式效果，避免每天套模板、该jstl、改标签的困扰。同时开发人员也可以扩展和创建自定义的方言。 多方言支持：Thymeleaf 提供spring标准方言和一个与 SpringMVC 完美集成的可选模块，可以快速的实现表单绑定、属性编辑器、国际化等功能。 与SpringBoot完美整合，SpringBoot提供了Thymeleaf的默认配置，并且为Thymeleaf设置了视图解析器，我们可以像以前操作jsp一样来操作Thymeleaf。代码几乎没有任何区别，就是在模板语法上有区别。 3.环境准备1.引入依赖12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 2.默认配置Thymeleaf的默认配置 123456789public class ThymeleafProperties &#123; private static final Charset DEFAULT_ENCODING; public static final String DEFAULT_PREFIX = "classpath:/templates/"; public static final String DEFAULT_SUFFIX = ".html"; private boolean checkTemplate = true; private boolean checkTemplateLocation = true; private String prefix = "classpath:/templates/"; private String suffix = ".html"; private String mode = "HTML"; 不需要做任何配置，启动器已经帮我们把Thymeleaf的视图器配置完成： 而且，还配置了模板文件（html）的位置，与jsp类似的前缀+ 视图名 + 后缀风格： 默认前缀：classpath:/templates/ 默认后缀：.html 所以如果我们返回视图：users，会指向到 classpath:/templates/users.html Thymeleaf默认会开启页面缓存，提高页面并发能力。但会导致我们修改页面不会立即被展现，因此我们关闭缓存： 12# 关闭Thymeleaf的缓存spring.thymeleaf.cache=false 另外，修改完毕页面，需要使用快捷键：Ctrl + Shift + F9来刷新工程。 3.快速开始3.1创建controller12345678@Controllerpublic class HelloController &#123; @GetMapping("hello") public String toHello(Map data)&#123; data.put("name","hello"); return "hello"; &#125;&#125; 3.2创建html页面1234567891011!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;学习nio、Java8、JUC等&lt;/h1&gt; &lt;span th:text="$&#123;name&#125;"&gt;&lt;/span&gt;&lt;/body&gt;&lt;/html&gt; 注意:想要html识别thymeleaf语法需要加上xmlns:th=&quot;http://www.thymeleaf.org&quot;命名空间 4.Thymeleaf基本语法Thymeleaf的主要作用是把model中的数据渲染到html中，因此其语法主要是如何解析model中的数据。从以下方面来学习： 变量 方法 条件判断 循环 运算 逻辑运算 布尔运算 比较运算 条件运算 其它 ４.1变量变量案例我们先新建一个实体类：User 12345public class User &#123; String name; int age; User friend;// 对象类型属性&#125; 然后在模型中添加数据 12345678910@GetMapping("show2")public String show2(Model model)&#123; User user = new User(); user.setAge(21); user.setName("Jack Chen"); user.setFriend(new User("李小龙", 30)); model.addAttribute("user", user); return "show2";&#125; 语法说明： Thymeleaf通过${}来获取model中的变量，注意这不是el表达式，而是ognl表达式，但是语法非常像。 示例： 我们在页面获取user数据： 123&lt;h1&gt; 欢迎您：&lt;span th:text="$&#123;user.name&#125;"&gt;请登录&lt;/span&gt;&lt;/h1&gt; 效果： /%E4%B9%90%E4%BC%98%E5%95%86%E5%9F%8E%E9%A1%B9%E7%9B%AE%E5%85%A8/%E8%B5%84%E6%96%99/thymeleaf/assets/1526438010948.png) 感觉跟el表达式几乎是一样的。不过区别在于，我们的表达式写在一个名为：th:text的标签属性中，这个叫做指令 动静结合 指令： Thymeleaf崇尚自然模板，意思就是模板是纯正的html代码，脱离模板引擎，在纯静态环境也可以直接运行。现在如果我们直接在html中编写 ${}这样的表达式，显然在静态环境下就会出错，这不符合Thymeleaf的理念。 Thymeleaf中所有的表达式都需要写在指令中，指令是HTML5中的自定义属性，在Thymeleaf中所有指令都是以th:开头。因为表达式${user.name}是写在自定义属性中，因此在静态环境下，表达式的内容会被当做是普通字符串，浏览器会自动忽略这些指令，这样就不会报错了！ 现在，我们不经过SpringMVC，而是直接用浏览器打开页面看看： 静态页面中，th指令不被识别，但是浏览器也不会报错，把它当做一个普通属性处理。这样span的默认值请登录就会展现在页面 如果是在Thymeleaf环境下，th指令就会被识别和解析，而th:text的含义就是替换所在标签中的文本内容，于是user.name的值就替代了 span中默认的请登录 指令的设计，正是Thymeleaf的高明之处，也是它优于其它模板引擎的原因。动静结合的设计，使得无论是前端开发人员还是后端开发人员可以完美契合。 向下兼容 但是要注意，如果浏览器不支持Html5怎么办？ 如果不支持这种th:的命名空间写法，那么可以把th:text换成 data-th-text，Thymeleaf也可以兼容。 escape 另外，th:text指令出于安全考虑，会把表达式读取到的值进行处理，防止html的注入。 例如，&lt;p&gt;你好&lt;/p&gt;将会被格式化输出为$lt;p$gt;你好$lt;/p$lt;。 如果想要不进行格式化输出，而是要输出原始内容，则使用th:utext来代替. ognl表达式的语法糖刚才获取变量值，我们使用的是经典的对象.属性名方式。但有些情况下，我们的属性名可能本身也是变量，怎么办？ ognl提供了类似js的语法方式： 例如：${user.name} 可以写作${user[&#39;name&#39;]} 4.2.自定义变量 场景 看下面的案例： 12345&lt;h2&gt; &lt;p&gt;Name: &lt;span th:text="$&#123;user.name&#125;"&gt;Jack&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Age: &lt;span th:text="$&#123;user.age&#125;"&gt;21&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;friend: &lt;span th:text="$&#123;user.friend.name&#125;"&gt;Rose&lt;/span&gt;.&lt;/p&gt;&lt;/h2&gt; 我们获取用户的所有信息，分别展示。 当数据量比较多的时候，频繁的写user.就会非常麻烦。 因此，Thymeleaf提供了自定义变量来解决： 示例： 12345&lt;h2 th:object="$&#123;user&#125;"&gt; &lt;p&gt;Name: &lt;span th:text="*&#123;name&#125;"&gt;Jack&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Age: &lt;span th:text="*&#123;age&#125;"&gt;21&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;friend: &lt;span th:text="*&#123;friend.name&#125;"&gt;Rose&lt;/span&gt;.&lt;/p&gt;&lt;/h2&gt; 首先在 h2上 用 th:object=&quot;${user}&quot;获取user的值，并且保存 然后，在h2内部的任意元素上，可以通过 *{属性名}的方式，来获取user中的属性，这样就省去了大量的user.前缀了 4.3.方法 ognl表达式中的方法调用 ognl表达式本身就支持方法调用，例如： 1234&lt;h2 th:object="$&#123;user&#125;"&gt; &lt;p&gt;FirstName: &lt;span th:text="*&#123;name.split(' ')[0]&#125;"&gt;Jack&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;LastName: &lt;span th:text="*&#123;name.split(' ')[1]&#125;"&gt;Li&lt;/span&gt;.&lt;/p&gt;&lt;/h2&gt; 这里我们调用了name（是一个字符串）的split方法。 Thymeleaf内置对象 Thymeleaf中提供了一些内置对象，并且在这些对象中提供了一些方法，方便我们来调用。获取这些对象，需要使用#对象名来引用。 一些环境相关对象 对象 作用 #ctx 获取Thymeleaf自己的Context对象 #requset 如果是web程序，可以获取HttpServletRequest对象 #response 如果是web程序，可以获取HttpServletReponse对象 #session 如果是web程序，可以获取HttpSession对象 #servletContext 如果是web程序，可以获取HttpServletContext对象 Thymeleaf提供的全局对象： 对象 作用 #dates 处理java.util.date的工具对象 #calendars 处理java.util.calendar的工具对象 #numbers 用来对数字格式化的方法 #strings 用来处理字符串的方法 #bools 用来判断布尔值的方法 #arrays 用来护理数组的方法 #lists 用来处理List集合的方法 #sets 用来处理set集合的方法 #maps 用来处理map集合的方法 举例 我们在环境变量中添加日期类型对象 12345@GetMapping("show3")public String show3(Model model)&#123; model.addAttribute("today", new Date()); return "show3";&#125; 在页面中处理 123&lt;p&gt; 今天是: &lt;span th:text="$&#123;#dates.format(today,'yyyy-MM-dd')&#125;"&gt;2018-04-25&lt;/span&gt;&lt;/p&gt; 效果： 4.4 字面值有的时候，我们需要在指令中填写基本类型如：字符串、数值、布尔等，并不希望被Thymeleaf解析为变量，这个时候称为字面值。 字符串字面值 使用一对&#39;引用的内容就是字符串字面值了： 123&lt;p&gt; 你正在观看 &lt;span th:text="'thymeleaf'"&gt;template&lt;/span&gt; 的字符串常量值.&lt;/p&gt; th:text中的thymeleaf并不会被认为是变量，而是一个字符串 数字字面值 数字不需要任何特殊语法， 写的什么就是什么，而且可以直接进行算术运算 12&lt;p&gt;今年是 &lt;span th:text="2018"&gt;1900&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;两年后将会是 &lt;span th:text="2018 + 2"&gt;1902&lt;/span&gt;.&lt;/p&gt; 布尔字面值 布尔类型的字面值是true或false： 123&lt;div th:if="true"&gt; 你填的是true&lt;/div&gt; 这里引用了一个th:if指令，跟vue中的v-if类似 4.5 拼接我们经常会用到普通字符串与表达式拼接的情况： 1&lt;span th:text="'欢迎您:' + $&#123;user.name&#125; + '!'"&gt;&lt;/span&gt; 字符串字面值需要用&#39;&#39;，拼接起来非常麻烦，Thymeleaf对此进行了简化，使用一对|即可： 1&lt;span th:text="|欢迎您:$&#123;user.name&#125;|"&gt;&lt;/span&gt; 与上面是完全等效的，这样就省去了字符串字面值的书写。 4.6 运算需要注意：${}内部的是通过OGNL表达式引擎解析的，外部的才是通过Thymeleaf的引擎解析，因此运算符尽量放在${}外进行。 算术运算 支持的算术运算符：+ - * / % 12&lt;span th:text="$&#123;user.age&#125;"&gt;&lt;/span&gt;&lt;span th:text="$&#123;user.age&#125;%2 == 0"&gt;&lt;/span&gt; 比较运算 支持的比较运算：&gt;, &lt;, &gt;= and &lt;= ，但是&gt;, &lt;不能直接使用，因为xml会解析为标签，要使用别名。 注意 == and !=不仅可以比较数值，类似于equals的功能。 可以使用的别名：gt (&gt;), lt (&lt;), ge (&gt;=), le (&lt;=), not (!). Also eq (==), neq/ne (!=). 条件运算 三元运算 1&lt;span th:text="$&#123;user.sex&#125; ? '男':'女'"&gt;&lt;/span&gt; 三元运算符的三个部分：conditon ? then : else ​ condition：条件 ​ then：条件成立的结果 ​ else：不成立的结果 其中的每一个部分都可以是Thymeleaf中的任意表达式。 默认值 有的时候，我们取一个值可能为空，这个时候需要做非空判断，可以使用 表达式 ?: 默认值简写： 1&lt;span th:text="$&#123;user.name&#125; ?: '二狗'"&gt;&lt;/span&gt; 当前面的表达式值为null时，就会使用后面的默认值。 注意：?:之间没有空格。 4.7 循环循环也是非常频繁使用的需求，我们使用th:each指令来完成： 假如有用户的集合：users在Context中。 1234&lt;tr th:each="user : $&#123;users&#125;"&gt; &lt;td th:text="$&#123;user.name&#125;"&gt;Onions&lt;/td&gt; &lt;td th:text="$&#123;user.age&#125;"&gt;2.41&lt;/td&gt;&lt;/tr&gt; ${users} 是要遍历的集合，可以是以下类型： Iterable，实现了Iterable接口的类 Enumeration，枚举 Interator，迭代器 Map，遍历得到的是Map.Entry Array，数组及其它一切符合数组结果的对象 在迭代的同时，我们也可以获取迭代的状态对象： 1234&lt;tr th:each="user,stat : $&#123;users&#125;"&gt; &lt;td th:text="$&#123;user.name&#125;"&gt;Onions&lt;/td&gt; &lt;td th:text="$&#123;user.age&#125;"&gt;2.41&lt;/td&gt;&lt;/tr&gt; stat对象包含以下属性： index，从0开始的角标 count，元素的个数，从1开始 size，总元素个数 current，当前遍历到的元素 even/odd，返回是否为奇偶，boolean值 first/last，返回是否为第一或最后，boolean值 4.8 逻辑判断有了if和else，我们能实现一切功能^_^。 Thymeleaf中使用th:if 或者 th:unless ，两者的意思恰好相反。 1&lt;span th:if="$&#123;user.age&#125; &lt; 24"&gt;小鲜肉&lt;/span&gt; 如果表达式的值为true，则标签会渲染到页面，否则不进行渲染。 以下情况被认定为true： 表达式值为true 表达式值为非0数值 表达式值为非0字符 表达式值为字符串，但不是&quot;false&quot;,&quot;no&quot;,&quot;off&quot; 表达式不是布尔、字符串、数字、字符中的任何一种 其它情况包括null都被认定为false 4.9 分支控制switch这里要使用两个指令：th:switch 和 th:case 12345&lt;div th:switch="$&#123;user.role&#125;"&gt; &lt;p th:case="'admin'"&gt;用户是管理员&lt;/p&gt; &lt;p th:case="'manager'"&gt;用户是经理&lt;/p&gt; &lt;p th:case="*"&gt;用户是别的玩意&lt;/p&gt;&lt;/div&gt; 需要注意的是，一旦有一个th:case成立，其它的则不再判断。与java中的switch是一样的。 另外th:case=&quot;*&quot;表示默认，放最后。 页面： 4.10.JS模板模板引擎不仅可以渲染html，也可以对JS中的进行预处理。而且为了在纯静态环境下可以运行，其Thymeleaf代码可以被注释起来： 123456&lt;script th:inline="javascript"&gt; const user = /*[[$&#123;user&#125;]]*/ &#123;&#125;; const age = /*[[$&#123;user.age&#125;]]*/ 20; console.log(user); console.log(age)&lt;/script&gt; 在script标签中通过th:inline=&quot;javascript&quot;来声明这是要特殊处理的js脚本 语法结构： 1const user = /*[[Thymeleaf表达式]]*/ "静态环境下的默认值"; 因为Thymeleaf被注释起来，因此即便是静态环境下， js代码也不会报错，而是采用表达式后面跟着的默认值。 看看页面的源码： 我们的User对象被直接处理为json格式了，非常方便。 控制台：]]></content>
      <categories>
        <category>thymeleaf</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>thymeleaf</tag>
        <tag>语法糖</tag>
        <tag>ognl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用数据库表优化和SKU及SPU表结构分析]]></title>
    <url>%2F2019%2F02%2F16%2F%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E4%BC%98%E5%8C%96%E5%92%8CSKU%E5%8F%8ASPU%E8%A1%A8%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[数据库优化常用数据库表优化1.表垂直拆分 1.对于表中字段数量打的一系列字段可以使用表的垂直拆分将大的字段拆分出去 2.对于一张表中如果存在经常不修改的字段和需要大量修改的字段可以使用垂直拆分将需要修改的字段拆分出去 3.对于多字段表可以尝试面向对象的思想，创建表使用列级 4.对于需要查询多个字段可以定义一个索引，根据索引可以快速定位字段 后期扩展 2.SKU及SPU表结构分析看一下spu的表结构和spu垂直拆分出的结构 TABLE `tb_spu` (12345678910111213 `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;spu id&apos;, `name` varchar(128) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;商品名称&apos;, `sub_title` varchar(256) DEFAULT &apos;&apos; COMMENT &apos;子标题&apos;, `cid1` bigint(20) NOT NULL COMMENT &apos;1级类目id&apos;, `cid2` bigint(20) NOT NULL COMMENT &apos;2级类目id&apos;, `cid3` bigint(20) NOT NULL COMMENT &apos;3级类目id&apos;, `brand_id` bigint(20) NOT NULL COMMENT &apos;商品所属品牌id&apos;, `saleable` tinyint(1) NOT NULL DEFAULT &apos;1&apos; COMMENT &apos;是否上架，0下架，1上架&apos;, `valid` tinyint(1) NOT NULL DEFAULT &apos;1&apos; COMMENT &apos;是否有效，0已删除，1有效&apos;, `create_time` datetime DEFAULT NULL COMMENT &apos;添加时间&apos;, `last_update_time` datetime DEFAULT NULL COMMENT &apos;最后修改时间&apos;, PRIMARY KEY (`id`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=196 DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC COMMENT=&apos;spu表，该表描述的是一个抽象性的商品，比如 iphone8&apos;; TABLE `tb_spu_detail` (12345678 `spu_id` bigint(20) NOT NULL, `description` text COMMENT &apos;商品描述信息&apos;, `generic_spec` varchar(2048) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;通用规格参数数据&apos;, `special_spec` varchar(1024) NOT NULL COMMENT &apos;特有规格参数及可选值信息，json格式&apos;, `packing_list` varchar(1024) DEFAULT &apos;&apos; COMMENT &apos;包装清单&apos;, `after_service` varchar(1024) DEFAULT &apos;&apos; COMMENT &apos;售后服务&apos;, PRIMARY KEY (`spu_id`) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC; 我们可以知道的是，像一些大数据量的字段都拆分出spu_detail中，这里也要说明下Spu是什么? SPU：Standard Product Unit （标准产品单位） ，一组具有共同属性的商品集 SKU：Stock Keeping Unit（库存量单位），SPU商品集因具体特性不同而细分的每个商品 SPU可以理解的是存一个共享属性，因此根据京东的页面我们可以分析出来它一些共享的属性。 SPU表中的字段我们没什么好解释的基本上都可以知道，Spu_detail中的几个字段我们需要解释一下，比如 generic_spec这个字段是存的一个通用规格的JSON串，也就是说一些同一种商品它通用规格的value值存放在这地方他的格式为:规格参数ID:规格参数值 special_spec:这些为页面进去后可以选择的信息 看一下sku表结构和sku垂直拆分出去的结构 TABLE `tb_sku` (12345678910111213 `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;sku id&apos;, `spu_id` bigint(20) NOT NULL COMMENT &apos;spu id&apos;, `title` varchar(256) NOT NULL COMMENT &apos;商品标题&apos;, `images` varchar(1024) DEFAULT &apos;&apos; COMMENT &apos;商品的图片，多个图片以‘,’分割&apos;, `price` bigint(15) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;销售价格，单位为分&apos;, `indexes` varchar(32) DEFAULT &apos;&apos; COMMENT &apos;特有规格属性在spu属性模板中的对应下标组合&apos;, `own_spec` varchar(1024) DEFAULT &apos;&apos; COMMENT &apos;sku的特有规格参数键值对，json格式，反序列化时请使用linkedHashMap，保证有序&apos;, `enable` tinyint(1) NOT NULL DEFAULT &apos;1&apos; COMMENT &apos;是否有效，0无效，1有效&apos;, `create_time` datetime NOT NULL COMMENT &apos;添加时间&apos;, `last_update_time` datetime NOT NULL COMMENT &apos;最后修改时间&apos;, PRIMARY KEY (`id`) USING BTREE, KEY `key_spu_id` (`spu_id`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=27359021730 DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC COMMENT=&apos;sku表,该表表示具体的商品实体,如黑色的 64g的iphone 8&apos;; TABLE `tb_stock` (123456 `sku_id` bigint(20) NOT NULL COMMENT &apos;库存对应的商品sku id&apos;, `seckill_stock` int(9) DEFAULT &apos;0&apos; COMMENT &apos;可秒杀库存&apos;, `seckill_total` int(9) DEFAULT &apos;0&apos; COMMENT &apos;秒杀总数量&apos;, `stock` int(9) NOT NULL COMMENT &apos;库存数量&apos;, PRIMARY KEY (`sku_id`) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC COMMENT=&apos;库存表，代表库存，秒杀库存等信息&apos;; 这里因为库存信息需要频繁的修改因此将这些属性垂直拆分出来。 sku存储的为商品的特有属性，这里可以看出来比如说商品的标题，图片等都是特有属性 这里我们要注意的是indexes和ovn_spec这俩个字段 3.2.2.1.indexes字段在SPU表中，已经对特有规格参数及可选项进行了保存，结构如下： 123456789101112131415&#123; "机身颜色": [ "香槟金", "樱花粉", "磨砂黑" ], "内存": [ "2GB", "3GB" ], "机身存储": [ "16GB", "32GB" ]&#125; 这些特有属性如果排列组合，会产生12个不同的SKU，而不同的SKU，其属性就是上面备选项中的一个。 比如： 红米4X，香槟金，2GB内存，16GB存储 红米4X，磨砂黑，2GB内存，32GB存储 你会发现，每一个属性值，对应于SPUoptions数组的一个选项，如果我们记录下角标，就是这样： 红米4X，0,0,0 红米4X，2,0,1 既然如此，我们是不是可以将不同角标串联起来，作为SPU下不同SKU的标示。这就是我们的indexes字段。 这个设计在商品详情页会特别有用： 当用户点击选中一个特有属性，你就能根据 角标快速定位到sku。 3.2.2.2.own_spec字段看结构： 1&#123;"机身颜色":"香槟金","内存":"2GB","机身存储":"16GB"&#125; 保存的是特有属性的键值对。 SPU中保存的是可选项，但不确定具体的值，而SKU中的保存的就是具体的键值对了。 这样，在页面展示规格参数信息时，就可以根据key来获取值，用于显示。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>spu</tag>
        <tag>sku</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决webpack-dev-server的host解析问题和Nginx基本反向代理配置]]></title>
    <url>%2F2019%2F02%2F12%2F%E8%A7%A3%E5%86%B3webpack-dev-server%E7%9A%84host%E8%A7%A3%E6%9E%90%E9%97%AE%E9%A2%98%E5%92%8CNginx%E5%9F%BA%E6%9C%AC%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[1.解决域名解析问题 开发前端工程的时候，本地域名解析后发现使用解析的域名访问Vue应用报错invalid host header; 原因：我们配置了项目访问的路径，虽然域名映射的IP也是127.0.0.1，但是webpack会验证host是否符合配置。 在webpack.dev.conf.js中取消host验证： 重新执行npm run dev，刷新浏览器，解决成功 2.Nginx反向代理配置 拉取nginx镜像 1docker pull nginx 启动nginx容器 1docker run -d --name mynginx -p 80:80 -v $PWD/conf:/etc/nginx/nginx.conf nginx 修改nginx配置 1234567891011121314151617181920212223242526272829303132333435http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; server &#123; listen 80; server_name 反向代理域名; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; location / &#123; proxy_pass http://主机IP:9001; proxy_connect_timeout 600; proxy_read_timeout 600; &#125; &#125; &#125; 修改vue工程对host的默认配置(解决网关报错502的问题) 1host: '0.0.0.0' 3.Nginx流程图 4.文件上传优化 SpringCloud中的文件上传会多次用到，因此需要特地创建一个文件上传的微服务。 话不多少上代码 1234567891011121314151617181920212223private static final List&lt;String&gt;ALLOW_TYPES =Arrays.asList("image/jpeg","image/png","image/bmp");public String upload(MultipartFile file) &#123; try &#123; String type = file.getContentType(); if (!ALLOW_TYPES.contains(type))&#123; throw new LyException(ExceptionEnums.FILE_TYPE_ERROR); &#125; //校验文件内容 BufferedImage read = ImageIO.read(file.getInputStream()); if (read==null)&#123; throw new LyException(ExceptionEnums.FILE_TYPE_ERROR); &#125; File dest = new File("D:\\image", file.getOriginalFilename()); file.transferTo(dest); return dest.getAbsolutePath(); &#125; catch (IOException e) &#123; //上传失败 log.error("上传失败"); throw new LyException(ExceptionEnums.FILE_UPLOAD_ERROR); &#125;&#125; 这段代码是一个简单的文件上传逻辑，见文件传到本地固定的目录下，做了一些文件的校验和类型的校验， 因为使用SpringCloud微服务会涉及到网关，这里我们需要让我们的图片上传微服务绕过网关，这里官方闻到文档也推荐这样，因为Zuul网关底层是Servlet它还是需要依赖SpringMvc的实体解析器，zuul每次会将进过网关的内容缓存。图片上传是文件的传输，如果也经过Zuul网关的代理，文件就会经过多次网路传输，造成不必要的网络负担。在高并发时，可能导致网络阻塞，Zuul网关不可用。这样我们的整个系统就瘫痪了。所以，我们上传文件的请求就不经过网关来处理了。 绕过Zuul网关配置123zuul: ignored-services: - upload-service 这样的话前端因为访问的是网关的地址，因此我们的文件上传微服务前台就无法使用了，所以需要利用niginx的rewrite指令来重写一个路径用于文件上传使用，话不多说上配置了。 1234567location /api/upload &#123; proxy_pass http://宿主机IP:8082; proxy_connect_timeout 600; proxy_read_timeout 600; rewrite "^/api/(.*)$" /$1 break; &#125; rewrite &quot;用来匹配路径的正则&quot; 重写后的路径 [指令]; 首先，我们映射路径是/api/upload，而下面一个映射路径是 / ，根据最长路径匹配原则，/api/upload优先级更高。也就是说，凡是以/api/upload开头的路径，都会被第一个配置处理 proxy_pass：反向代理，这次我们代理到8082端口，也就是upload-service服务 rewrite &quot;^/api/(.*)$&quot; /$1 break，路径重写： &quot;^/api/(.*)$&quot;：匹配路径的正则表达式，用了分组语法，把/api/以后的所有部分当做1组 /$1：重写的目标路径，这里用$1引用前面正则表达式匹配到的分组（组编号从1开始），即/api/后面的所有。这样新的路径就是除去/api/以外的所有，就达到了去除/api前缀的目的 break：指令，常用的有2个，分别是：last、break last：重写路径结束后，将得到的路径重新进行一次路径匹配 break：重写路径结束后，不再重新匹配路径。 我们这里不能选择last，否则以新的路径/upload/image来匹配，就不会被正确的匹配到8082端口了]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>webpack</tag>
        <tag>docker</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊服务端渲染技术NUXT]]></title>
    <url>%2F2019%2F02%2F05%2F%E8%81%8A%E8%81%8A%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%B8%B2%E6%9F%93%E6%8A%80%E6%9C%AFNUXT%2F</url>
    <content type="text"><![CDATA[服务端渲染技术NUXT说到NUXT首先我们要了解下什么是服务端渲染? 服务端渲染又称SSR (Server Side Render)是在服务端完成页面的内容，而不是在客户端通过AJAX获取数 据。 与传统 SPA（Single-Page Application - 单页应用程序）相比，服务器端渲染(SSR)的优势主要在于： 更好的 SEO，由于搜索引擎爬虫抓取工具可以直接查看完全渲染的页面。 请注意，截至目前，Google 和 Bing 可以很好对同步 JavaScript 应用程序进行索引。在这里，同步是关 键。如果你的应用程序初始展示 loading 菊花图，然后通过 Ajax获取内容，抓取工具并不会等待异步完成后再行抓 取页面内容。也就是说，如果 SEO 对你的站点至关重要，而你的页面又是异步获取内容，则你可能需要服务器端渲染 (SSR)解决此问题。 更快的内容到达时间(time-to-content)，特别是对于缓慢的网络情况或运行缓慢的设备。无需等待所有的 JavaScript 都完成下载并执行，才显示服务器渲染的标记，所以你的用户将会更快速地看到完整渲染的页面。通常可 以产生更好的用户体验，并且对于那些「内容到达时间(time-to-content)与转化率直接相关」的应用程序而言，服 务器端渲染(SSR)至关重要。 什么是NUXT Nuxt.js 是一个基于 Vue.js 的轻量级应用框架,可用来创建服务端渲染 (SSR) 应用,也可充当静态站点引擎生成静态站点应用,具有优雅的代码结构分层和热加载等特点。 Nuxt.js官网 NUXT环境搭建1.我们从网站上下载模板的压缩包 starter-template-master.zip 解压，修改template目录目录的package.json中的名称2.在命令提示符下进入该目录下的template目录3.安装依赖 npm install 4.修改package.json ...... &quot;name&quot;: &quot;studyNuxt&quot;, ...... 5.修改nuxt.config.js ...... title: &apos;学习NUXT&apos; ...... 6.测试运行 npm run dev NUXT的目录结果1.资源目录 assets 用于组织未编译的静态资源如 LESS、SASS 或 JavaScrip 2.组件目录 components 用于组织应用的 Vue.js 组件。Nuxt.js 不会扩展增强该目录下 Vue.js 组件，即这些组件不会像页面组件 那样有 asyncData 方法的特性。 3.布局目录 layouts 用于组织应用的布局组件 4.页面目录 pages 用于组织应用的路由及视图。Nuxt.js 框架读取该目录下所有的 .vue 文件并自动生成对应的路由配置。 5.插件目录 plugins 用于组织那些需要在 根vue.js应用 实例化之前需要运行的 Javascript 插件。 6.nuxt.config.js 文件 nuxt.config.js 文件用于组织Nuxt.js 应用的个性化配置，以便覆盖默认配置。 NUXT快速入门定义布局 我们通常的网站头部和尾部都是相同的，我们可以把头部为尾部提取出来，形成布局页 1.修改layouts目录下default.vue &lt;template&gt; &lt;div&gt; &lt;header&gt;NUXT布局&lt;/header&gt; &lt;nuxt/&gt; &lt;footer&gt;&lt;a href=&quot;https://www.babywang.huangsm.xyz&quot;&gt;个人博客&lt;/a&gt;&lt;/footer&gt; &lt;/div&gt; &lt;/template&gt; &lt;nuxt/&gt;为内容的区域,在pages目录下 页面路由 在page目录创建文件夹(NUXT的路由是根据目录自动生成的，无需手写) 修改default.vue，header中添加导航链接 &lt;template&gt; &lt;div&gt; &lt;header&gt; &lt;router-link to=&quot;/&quot;&gt;首页&lt;/router-link&gt; &lt;router-link to=&quot;/recruit&quot;&gt;招聘&lt;/router-link&gt; &lt;router-link to=&quot;/gathering&quot;&gt;活动&lt;/router-link&gt; &lt;/header&gt; &lt;nuxt/&gt; &lt;footer&gt; &lt;a href=&quot;https://www.babywang.huangsm.xyz&quot;&gt;个人博客&lt;/a&gt; &lt;/footer&gt; &lt;/div&gt; &lt;/template&gt; 数据渲染1.安装axios，用于异步获取数据 cnpm install axios --save 2.修改gathering目录的index.vue &lt;template&gt; &lt;div&gt; &lt;b&gt;活动列表&lt;/b&gt; &lt;div v-for=&quot;(item,index) in items&quot; :key=&quot;index&quot;&gt;{{item.name}}&lt;/div&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; //加载活动列表中的全部name信息 import axios from &quot;axios&quot;; export default { asyncData() { return axios .get( &quot;https://www.easy-mock.com/mock/5c57b3a6de5c260cd71d3b8d/api/gathering&quot; ) .then(response =&gt; { //console.log(JSON.stringify(response.data)); return { items: response.data.data }; }); console.log(&quot;这是在服务端运行的方法&quot;); } }; &lt;/script&gt; asyncData是用于异步加载数据的方法 动态路由 如果我们需要根据ID查询活动详情，就需要使用动态路由。NUXT的动态路由是以下划线开头的vue文件，参数名为下划线后边的文件名 1.创建pages/gathering/item/_id.vue &lt;template&gt; &lt;div&gt; &lt;b&gt;活动详情&lt;/b&gt; {{item.id}} &lt;br&gt; {{item.name}} &lt;/div&gt; &lt;/template&gt; &lt;script&gt; //根据ID查询活动详情 import axios from &quot;axios&quot;; export default { asyncData({ params }) { //params.id return axios .get( `https://www.easy-mock.com/mock/5c57b3a6de5c260cd71d3b8d/api/gathering/${params.id}` ) .then(response =&gt; { return { item: response.data.data }; }); } }; &lt;/script&gt; 2.在活动列表页点击链接进入详情页 &lt;!-- &lt;router-link :to=&quot;&apos;/gathering/item/&apos;+item.id&quot;&gt; {{item.name}}&lt;/router-link&gt; --&gt; &lt;nuxt-link :to=&quot;&apos;/gathering/item/&apos;+item.id&quot;&gt;{{item.name}}&lt;/nuxt-link&gt; 目前 nuxt‐link 的作用和 router‐link 致 ，都是进行路由的跳转 vue瀑布流插件使用安装: cnpm install vue-infinite-scroll 1.plugins下创建vue-infinite-scroll.js //加载瀑布流插件 import Vue from &apos;vue&apos;; import infiniteScroller from &apos;vue-infinite-scroll&apos;; //使用插件 Vue.use(infiniteScroller); 2.修改nuxt.config.js plugins: [ { src: &apos;~/plugins/vue-infinite-scroll&apos;, //不需要服务端加载 ssr: false } ], 3.修改页面pages/gathering/index.vue &lt;div class=&quot;activity-list&quot; v-infinite-scroll=&quot;loadMore()&quot;&gt; 添加pageNo用于记录 data () { return { //用来记录瀑布流页码号 pageNo: 1 } }, 编写方法loadMore methods: { loadMore(){ this.pageNo++; gatheringApi.getListByPage(this.pageNo, 12, { state: &quot;1&quot; }).then(resp =&gt; { this.items=this.items.concat( resp.data.data.rows); }) } }]]></content>
      <categories>
        <category>NUXT</category>
      </categories>
      <tags>
        <tag>Vue</tag>
        <tag>NUXT</tag>
        <tag>服务端渲染技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue2.0路由与状态管理]]></title>
    <url>%2F2019%2F02%2F04%2FVue2-0%E8%B7%AF%E7%94%B1%E4%B8%8E%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[路由与状态管理路由vue-router什么是vue-router vue-router就是vue官方提供的一个路由框架。使用 Vue.js ，我们已经可以通过组合组件来组成应用程序，当你要把 vue-router 添加进来，我们需要做的是，将组件(components)映射到路由(routes)，然后告诉 vue-router 在哪里渲染它们。 快速入门初始化工程1.全局安装vue-cli cnpm install -g vue-cli 2.创建一个基于webpack模版的新项目 vue init webpack vue-router-demo 3.安装依赖 cd vue-router-demo npm run dev 路由定义 src/App.vue是我们的主界面，其中的 &lt;router‐view/&gt; 标签用于显示各组件视图内容src/router/index.js是定义路由的脚本 path是路径， name是名称 ，component是跳转的组件. 1.我们现在定义两个页面组件，存放在src/components下 list.vue &lt;template&gt; &lt;div&gt; 这是一个列表! &lt;/div&gt; &lt;/template&gt; about.vue &lt;template&gt; &lt;div&gt; 关于我:huangsm &lt;/div&gt; &lt;/template&gt; 2.定义路由 修改src/router/index.js import Vue from &apos;vue&apos; import Router from &apos;vue-router&apos; import HelloWorld from &apos;@/components/HelloWorld&apos; import list from &apos;@/components/list&apos; import about from &apos;@/components/about&apos; Vue.use(Router) export default new Router({ routes: [ { path: &apos;/&apos;, name: &apos;HelloWorld&apos;, component: HelloWorld }, { path: &apos;/list&apos;, name: &apos;list&apos;, component: list }, { path: &apos;/about&apos;, name: &apos;about&apos;, component: about } ] }) 3.放置跳转链接 修改src/app.vue ,添加链接 &lt;router-link to=&quot;/&quot;&gt;首页&lt;/router-link&gt; &lt;router-link to=&quot;/list&quot;&gt;列表&lt;/router-link&gt; &lt;router-link to=&quot;/about&quot;&gt;关于&lt;/router-link&gt; 通过router-link标签实现路由的跳转 深入了解动态路由 我们经常会遇到这样的需求，有一个新闻列表，点击某一条进入新闻详细页，我们通常是传递新闻的ID给详细页，详细页根据ID进行处理。这时我们就会用到动态路由个『路径参数』使用冒号 : 标记。当匹配到一个路由时，参数值会被到 this.$route.params 如何实现? 1.在src/components下创建item.vue &lt;div&gt; 接收的参数:{{$route.params.id}} &lt;/div&gt; 2.修改src/router/index.js，引入item组件 import item from &apos;@/components/item&apos; 3.添加路由设置 { path: &apos;/item/:id&apos;, name: &apos;item&apos;, component: item } 4.修改src/components/list.vue, 增加链接 &lt;router-link to=&quot;/item/1&quot;&gt;新闻1&lt;/router-link&gt; &lt;router-link to=&quot;/item/2&quot;&gt;新闻2&lt;/router-link&gt; &lt;router-link to=&quot;/item/3&quot;&gt;新闻3&lt;/router-link&gt; 嵌套路由 实际生活中的应用界面，通常由多层嵌套的组件组合而成。同样地，URL 中各段动态路径也按某种结构对应嵌套的各层组件，例如： 如何实现? 1.在src/components下创建address.vue &lt;template&gt; &lt;div&gt; 地址:郑州 &lt;/div&gt; &lt;/template&gt; 创建linkman.vue &lt;template&gt; &lt;div&gt; 联系人:王球球 &lt;/div&gt; &lt;/template&gt; 2.修改src/router/index.js 引入linkman和address import address from &apos;@/components/address&apos; import linkman from &apos;@/components/linkman&apos; 配置嵌套路由: { path: &apos;/about&apos;, name: &apos;about&apos;, component: about, children: [ { path: &apos;address&apos;, component: address }, { path: &apos;linkman&apos;, component: linkman } ] }, 3.修改src/components/about.vue &lt;div&gt; 关于我: &lt;router-link to=&quot;/about/address&quot;&gt;address&lt;/router-link&gt; &lt;router-link to=&quot;/about/linkman&quot;&gt;linkman&lt;/router-link&gt; &lt;router-view/&gt; &lt;/div&gt; 状态管理Vuex 我们经过测试会发现，用户登陆后可以访问其它页面的资源。未登录或退出登录后，再次访问资源会跳回到登陆页，这是如何实现的呢？长话短说，这是通过一种叫Vuex的技术来实现的。 Vuex简介 官方的解释： Vuex 是一个专为 Vue.js 应用程序开发的状态管理模式。它采用集中式存储管理应用的所有组件的状态，并以相应的规则保证状态以一种可预测的方式发生变化。 快速理解：每个组件都有它自己数据属性，封装在data()中，每个组件之间data是完全隔离的，是私有的。如果我们需要各个组件都能访问到数据数据，或是需要各个组件之间能互相交换数据，这就需要一个单独存储的区域存放公共属性。这就是状态管理所要解决的问题。 快速入门工程搭建vue init webpack vuexdemo cd vuexdemo cnpm install ‐‐save vuex npm run dev 读取状态值 每一个 Vuex 应用的核心就是 store（仓库）。“store”基本上就是一个容器，它包含着你的应用中大部分的状态 (state)。 长话短说下面我们来实现吧 1.在src下创建store，store下创建index.js //定义仓库(Vuex的核心) import Vue from &apos;vue&apos;; import Vuex from &apos;vuex&apos;; //打开Vue状态管理的开关 Vue.use(Vuex); const store = new Vuex.Store({ //定义仓库中所有的状态 state: { count: 0 } }) export default store; 2.修改main.js，引入和装载store import store from &apos;./store&apos;; Vue.config.productionTip = false /* eslint-disable no-new */ new Vue({ el: &apos;#app&apos;, router, store, components: { App }, template: &apos;&lt;App/&gt;&apos; }) 3.修改components\HelloWorld.vue &lt;template&gt; &lt;div&gt; {{$store.state.count}} &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { } &lt;/script&gt; 改变状态值 你不能直接改变 store 中的状态。改变 store 中的状态的唯一途径就是显式地提交(commit) mutation。这样使得我们可以方便地跟踪每一个状态的变化，从而让我们能够实现一些工具帮助我们更好地了解我们的应用。 1.修改store/index.js ,增加mutation定义 //相当于定义一堆方法 mutations: { increment(state){ state.count++ } } 2.修改components\HelloWorld.vue ，调用mutation export default { methods: { addCount(){ //调用mutations this.$store.commit(&apos;increment&apos;); console.log(this.$store.state.count); } } } &lt;/script&gt; 提交载荷 所谓载荷（payload）就是 向 store.commit 传入额外的参数。 1.修改store下的index.js mutations: { increment(state,x){ state.count+=x; } } 2.修改HelloWorld.vue &lt;script&gt; export default { methods: { addCount(){ //调用mutations this.$store.commit(&apos;increment&apos;,10); console.log(this.$store.state.count); } } } &lt;/script&gt; ActionAction 类似于 mutation，不同在于： Action 提交的是 mutation，而不是直接变更状态。 Action 可以包含任意异步操 我们现在使用 Action 来封装increme 1.修改store/index.js //相当于封装了mutations支持异步 actions: { increment(context){ context.commit(&apos;increment&apos;,10); } } 2.修改show.vue //调用actions this.$store.dispatch(&apos;increment&apos;); 我们使用dispatch来调用action , Action也同样支持载荷 派生属性Getter 有时候我们需要从 store 中的 state 中派生出一些状态，例如我们在上例代码的基础上，我们增加一个叫 remark的属性，如果count属性值小于50则remark为加油，大于等于50小于100则remark为你真棒，大于100则remark的值为你是大神. 这时我们就需要用到getter为我们解决。 1.修改store/index.js ,增加getters getters: { remark(state){ if(state.count&lt;50){ return &apos;加油&apos;; }else if(state.count&lt;100){ return &apos;真棒&apos;; }else{ return &apos;强啊!&apos;; } } } Getter 接受 state 作为其第一个参数，也可以接受其他 getter 作为第二个参数 2.修改HelloWorld.vue 显示派生属性的值 &lt;!-- 显示getters --&gt; {{$store.getters.remark}} 模块化 由于使用单一状态树，应用的所有状态会集中到一个比较大的对象。当应用变得非常复杂时，store 对象就有可能变得相当臃肿. 为了解决以上问题，Vuex 允许我们将 store 分割成模块（module）。每个模块拥有自己的 state、mutation、action、getter、甚至是嵌套子模块——从上至下进行同样方式的分割 . 模块化后的store.js //定义仓库(Vuex的核心) import Vue from &apos;vue&apos;; import Vuex from &apos;vuex&apos;; //打开Vue状态管理的开关 Vue.use(Vuex); //模块化 const moduleA = { //定义仓库中所有的状态 state: { count: 0 }, //相当于定义一堆方法 mutations: { increment(state, x) { state.count += x; } }, //相当于封装了mutations支持异步 actions: { increment(context) { context.commit(&apos;increment&apos;, 10); } }, getters: { remark(state) { if (state.count &lt; 50) { return &apos;加油&apos;; } else if (state.count &lt; 100) { return &apos;真棒&apos;; } else { return &apos;强啊!&apos;; } } } } const store = new Vuex.Store({ modules:{ a:moduleA } }) export default store; 调用方式 &lt;template&gt; &lt;div&gt; {{$store.state.a.count}} &lt;button @click=&quot;addCount()&quot;&gt;测试&lt;/button&gt; &lt;!-- 显示getters --&gt; {{$store.getters.remark}} &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { methods: { addCount(){ //调用mutations //this.$store.commit(&apos;increment&apos;,10); //调用actions this.$store.dispatch(&apos;increment&apos;); console.log(this.$store.state.a.count); } } } &lt;/script&gt; 标准工程结构 现在我们按照上图结构，重新改善我们的工程 1.store下创建modules文件夹，文件夹下创建a.js //标准工厂结构下的--store export default{ state: { count: 0 }, mutations: { increment(state,x){ state.count+=x; } }, actions: { increment(context){ context.commit(&apos;increment&apos;,10); } } } 2.store下创建getters.js //标准工厂结果---getters派生属性 export default{ remark: state=&gt;{ if(state.a.count&lt;50){ return &apos;加油&apos;; }else if(state.a.count&lt;100){ return &apos;真棒&apos;; }else{ return &apos;强啊!&apos;; } }, count: state=&gt;state.a.count } 3.修改store/index.js //定义仓库(Vuex的核心) import Vue from &apos;vue&apos;; import Vuex from &apos;vuex&apos;; import a from &apos;./modules/a&apos;; import getters from &apos;./getters&apos;; //打开Vue状态管理的开关 Vue.use(Vuex); const store=new Vuex.Store({ getters, modules:{ a } }) export default store; 4.修改HelloWorld.vue &lt;template&gt; &lt;div&gt; {{$store.getters.count}} &lt;button @click=&quot;addCount()&quot;&gt;测试&lt;/button&gt; &lt;!-- 显示getters --&gt; {{$store.getters.remark}} &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { methods: { addCount(){ //调用mutations //this.$store.commit(&apos;increment&apos;,10); //调用actions this.$store.dispatch(&apos;increment&apos;); console.log(this.$store.getters.count); } } } &lt;/script&gt;]]></content>
      <categories>
        <category>Vue2.0</category>
      </categories>
      <tags>
        <tag>Vuex</tag>
        <tag>vue-router</tag>
        <tag>vue-cli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElementUI的概念和基本控件的使用]]></title>
    <url>%2F2019%2F02%2F04%2FElementUI%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%8E%A7%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[ElementUI什么是ElementUI element 饿了么前端出品的一套 Vue.js 后台组件库 官网 神器的脚手架快速搭建 官网上提供了非常基础的脚手架，如果我们使用官网的脚手架需要自己写很多代码比如登录页面、主界面菜单等内容。课程已经提供了功能完整的脚手架，我们可以拿过来在此基础上开发、这样可以极大节省我们开发的时间。 1.解压vueAdmin-template-master 2.在命令提示符进入该目录，输入命令： cnpm install 3.输入命令: npm run dev 了解工程结构以下是主要的目录结构： 项目初始化关闭语法规范性检查 修改config/index.js ，将useEslint的值改为false。此配置作用: 是否开启语法检查，语法检查是通过ESLint 来实现的。我们现在科普一下,什么是ESLint : ESLint 是一个语法规则和代码风格的检查工具，可以用来保证写出语法正确、风格统一的代码。如果我们开启了Eslint , 也就意味着要接受它非常苛刻的语法检查，包括空格不能少些或多些，必须单引不能双引，语句后不可以写分号等等，这些规则其实是可以设置的。我们作为前端的初学者，最好先关闭这种校验，否则会浪费很多精力在语法的规范性上。如果以后做真正的企业级开发，建议开启。 对接Easy-Mock1.修改config下的dev.env.js中的BASE_API为easy-mock的Base URL BASE_API: &apos;&quot;https://www.easy-mock.com/mock/5c57b3a6de5c260cd71d3b8d&quot;&apos; 2.准备对应的user/login和user/info接口 更改标题与菜单1.修改index.html里的标题为&quot;Element学习&quot;，修改后浏览器自动刷新。 这就是脚手架中已经为我们添加了热部署功能。 2.修改src/router 下的index.js 中constantRouterMap的内容 活动管理-列表表格组件1.在src/api创建gathering.js //封装对restFul接口的访问 const group_name=&apos;api&apos;; import request from &apos;@/utils/request&apos; export default { getList(){ return request( { url:&apos;/api/gathering&apos;, method:&apos;get&apos; } ); } } 2.创建gathering.vue中 ，编写脚本部分 &lt;script&gt; import gatheringApi from &quot;@/api/gathering&quot;; export default { //定义成员变量，定义页面属性 data() { return { //接收列表 list: [] }; }, //钩子函数 created () { this.feechData(); }, //所有的方法 methods: { feechData() { gatheringApi.getList().then(response =&gt; { this.list = response.data; }); } } }; &lt;/script&gt; 3.修改gathering.vue，编写html代码部分 &lt;!-- template:模版区视图区 - table控件 script:逻辑区(控制视图区的显示) --&gt; &lt;template&gt; &lt;el-table :data=&quot;list&quot; border style=&quot;width: 100%&quot;&gt; &lt;el-table-column prop=&quot;id&quot; label=&quot;活动ID&quot; width=&quot;180&quot;&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=&quot;name&quot; label=&quot;活动名称&quot; width=&quot;180&quot;&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=&quot;sponsor&quot; label=&quot;主办方&quot; width=&quot;180&quot;&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=&quot;starttime&quot; label=&quot;开始时间&quot; width=&quot;180&quot;&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=&quot;endtime&quot; label=&quot;结束时间&quot; width=&quot;180&quot;&gt;&lt;/el-table-column&gt; &lt;/el-table&gt; &lt;/template&gt; table的属性官方文档 分页组件我们已经通过表格组件完成了列表的展示，接下来需要使用分页组件完成分页功能 准备工作：修改接口/gathering/gathering/search/{page}/{size} method:POST 1.修改src/api/gathering.js，增加方法导出 //分页查询 getListByPage(page,size,searchMap){ return request({ url:&apos;/api/gathering/search/{page}/{size}&apos;, method:&apos;post&apos;, data:searchMap }); } 2.修改src/views/table/gathering.vue，编写脚本部分 import gatheringApi from &quot;@/api/gathering&quot;; export default { //定义成员变量，定义页面属性 data() { return { //接收列表 total:0,//总记录数 list: [], cuurentPage: 1,//当前页 pageSize: 10, //每页大小 searchMap:{}//查询条件 }; }, //钩子函数 created() { this.feechData(); }, //所有的方法 methods: { feechData() { gatheringApi.getListByPage(this.cuurentPage,this.pageSize,this.searchMap).then(response =&gt; { this.list = response.data.rows; this.total=response.data.total; }); } } }; 3.修改src/views/table/gathering.vue，增加分页栏 &lt;div&gt; &lt;el-table :data=&quot;list&quot; border style=&quot;width: 100%&quot;&gt; &lt;el-table-column prop=&quot;id&quot; label=&quot;活动ID&quot; width=&quot;180&quot;&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=&quot;name&quot; label=&quot;活动名称&quot; width=&quot;180&quot;&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=&quot;sponsor&quot; label=&quot;主办方&quot; width=&quot;180&quot;&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=&quot;starttime&quot; label=&quot;开始时间&quot; width=&quot;180&quot;&gt;&lt;/el-table-column&gt; &lt;el-table-column prop=&quot;endtime&quot; label=&quot;结束时间&quot; width=&quot;180&quot;&gt;&lt;/el-table-column&gt; &lt;/el-table&gt; &lt;el-pagination @size-change=&quot;feechData&quot; @current-change=&quot;feechData&quot; :current-page=&quot;cuurentPage&quot; :page-sizes=&quot;[5, 10, 20]&quot; :page-size=&quot;10&quot; layout=&quot;total, sizes, prev, pager, next, jumper&quot; :total=&quot;total&quot; &gt;&lt;/el-pagination&gt; &lt;/div&gt; currentPage为当前页 ， total为总记录数注意：template里面要求必须有唯一的跟节点，我们这里用div将表格和分页控件包起来。 分页控件官方文档 条件查询1.修改src/views/table/gathering.vue，增加查询表单 &lt;br&gt; &lt;el-form :inline=&quot;true&quot;&gt; &lt;el-form-item label=&quot;活动名称&quot;&gt; &lt;el-input v-model=&quot;searchMap.name&quot; placeholder=&quot;活动名称&quot;&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;开始日期&quot;&gt; &lt;el-date-picker v-model=&quot;searchMap.starttime_1&quot; type=&quot;date&quot; placeholder=&quot;选择开始日期&quot;&gt;&lt;/el-date-picker&gt; &lt;el-date-picker v-model=&quot;searchMap.starttime_2&quot; type=&quot;date&quot; placeholder=&quot;选择截至日期&quot;&gt;&lt;/el-date-picker&gt; &lt;/el-form-item&gt; &lt;el-button type=&quot;primary&quot; @click=&quot;feechData&quot;&gt;查询&lt;/el-button&gt; &lt;/el-form&gt; 表单组件 Input 输入框 日期选择器组件 活动管理-增加弹出窗口1.修改src/api/gathering.js，在template中增加对话框组件 &lt;el-dialog title=&quot;编辑&quot; :visible.sync=&quot;dislogFormVisble&quot;&gt; &lt;/el-dialog&gt; 2.变量dialogFormVisible用于控制对话框的显示。我们在脚本代码中定义 return { ..... dislogFormVisble: false //编辑窗口是否可见 .... }; 3.template中增加按钮，用于打开对话框 &lt;el-button type=&quot;primary&quot; @click=&quot;dislogFormVisble=true&quot;&gt;新增&lt;/el-button&gt; diglog组件文档 编辑表单1.修改src/views/table/gathering.vue，在弹出窗口添加编辑 &lt;el-dialog title=&quot;编辑&quot; :visible.sync=&quot;dislogFormVisble&quot;&gt; &lt;el-form label-width=&quot;80px&quot;&gt; &lt;el-form-item label=&quot;活动名称&quot;&gt; &lt;el-input v-model=&quot;pojo.name&quot; placeholder=&quot;活动名称&quot;&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;基本地址&quot;&gt; &lt;el-input v-model=&quot;pojo.address&quot; placeholder=&quot;基本地址&quot;&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;开始日期&quot;&gt; &lt;el-date-picker type=&quot;date&quot; v-model=&quot;pojo.starttime&quot; placeholder=&quot;开始日期&quot;&gt;&lt;/el-date-picker&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;截至日期&quot;&gt; &lt;el-date-picker type=&quot;date&quot; v-model=&quot;pojo.endtime&quot; placeholder=&quot;截至日期&quot;&gt;&lt;/el-date-picker&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;报名截至&quot;&gt; &lt;el-date-picker type=&quot;date&quot; v-model=&quot;pojo.enrolltime&quot; placeholder=&quot;报名截至&quot;&gt;&lt;/el-date-picker&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;活动详情&quot;&gt; &lt;el-input v-model=&quot;pojo.detail&quot; placeholder=&quot;活动详情&quot; type=&quot;textarea&quot; :rows=&quot;2&quot;&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;是否可见&quot;&gt; &lt;el-switch v-model=&quot;pojo.status&quot; active-value=&quot;1&quot; inactive-value=&quot;0&quot; active-color=&quot;#13ce66&quot; inactive-color=&quot;#ff4949&quot; &gt;&lt;/el-switch&gt; &lt;el-form-item&gt; &lt;el-button type=&quot;primary&quot;&gt;保存&lt;/el-button&gt; &lt;el-button @click=&quot;dislogFormVisble=false&quot; type=&quot;danger&quot;&gt;关闭&lt;/el-button&gt; &lt;/el-form-item&gt; &lt;/el-form-item&gt; &lt;/el-form&gt; &lt;/el-dialog&gt; 这里我们主要要掌握多行文本编辑框与开关组件switch的使用 下拉选择框1.创建src/api/city.js //城市模块 const group_name = &apos;base&apos;; const method_name = &apos;city&apos;; import request from &apos;@/utils/request&apos; export default { getList() { return request({ url: `/${group_name}/${method_name}`, method: &apos;get&apos; }) } } 2.修改src/views/table/gathering.vue的js脚本部分 cityApi.getList().then(response =&gt; { this.cityList = response.data; }); cityList: [] //城市列表 3.修改src/views/table/gathering.vue，增加城市下拉框 &lt;el-form-item label=&quot;城市&quot;&gt; &lt;el-select v-model=&quot;pojo.city&quot; placeholder=&quot;选择城市&quot;&gt; &lt;el-option v-for=&quot;item in cityList&quot; :key=&quot;item.id&quot; :label=&quot;item.name&quot; :value=&quot;item.id&quot; &gt;&lt;/el-option&gt; &lt;/el-select&gt; &lt;/el-form-item&gt; 提交表单1.修改easymock中的/gathering/gathering （增加活动 POST） { &quot;code&quot;: 20000, &quot;flag&quot;: true, &quot;message&quot;: &quot;增加成功&quot; } 2.修改src/api/gathering.js，增加方法导出 //保存 save(pojo){ return request({ url:`/${group_name}/${method_name}`, method:&apos;post&apos;, data:pojo }) } 3.修改src/views/table/gathering.vue的js脚本部分 增加方法执行保存 saveData() { gatheringApi.save(this.pojo).then(response =&gt; { alert(response.message); if (response.code == 20000) { this.feechData(); //刷新列表 } }); this.dislogFormVisble = false; //关闭窗口 } &lt;el-button type=&quot;primary&quot; @click=&quot;saveData()&quot;&gt;保存&lt;/el-button&gt; 活动管理-修改在表格的操作列增加”修改”按钮，点击修改按钮弹出窗口并显示数据，点击保存按钮保存修改并刷新 根据ID加载数据1.修改easymock 接口 /gathering/gathering/{id} （GET） { &quot;code&quot;: 20000, &quot;flag&quot;: true, &quot;message&quot;: &quot;查询成功&quot;, &quot;data&quot;: { &quot;id|+1&quot;: 1, &quot;name&quot;: &quot;@cword(8,12)&quot;, &quot;summary&quot;: &quot;@cword(20,40)&quot;, &quot;detail&quot;: &quot;@cword(20,40)&quot;, &quot;sponsor&quot;: &quot;@string&quot;, &quot;image&quot;: &quot;@image&quot;, &quot;starttime&quot;: &quot;@date&quot;, &quot;endtime&quot;: &quot;@date&quot;, &quot;address&quot;: &quot;@county(true)&quot;, &quot;enrolltime&quot;: &quot;@date&quot;, &quot;state&quot;: &quot;@string&quot;, &quot;city&quot;: &quot;@string&quot; } } 2.修改src/api/gathering.js，增加方法定义 //根据ID查询活动信息 findById(id){ return request({ url:`/${group_name}/${method_name}/${id}`, method:&apos;get&apos; }) } 3.修改src/views/table/gathering.vue的js脚本部分 新增handleEdit方法 //根据ID查询活动信息 handleEdit(id) { //打开编辑窗口 this.dislogFormVisble = true; if (id != &quot;&quot;) {//修改数据 gatheringApi.findById(id).then(response =&gt; { if ((response.flag = true)) { //定义实体，用于数据回显 this.pojo = response.data; } }); }else{ this.pojo={}; } } 4.在表格table中增加模板列 ,模板列中防止修改按钮，调用handleEdit方法 &lt;el-table-column fixed=&quot;right&quot; label=&quot;操作&quot; width=&quot;100&quot;&gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;el-button @click=&quot;handleEdit(scope.row.id)&quot; type=&quot;text&quot; size=&quot;small&quot;&gt;修改&lt;/el-button&gt; &lt;/template&gt; &lt;/el-table-column&gt; 新增窗口表单清空&lt;el-button type=&quot;primary&quot; @click=&quot;handleEdit(&apos;&apos;)&quot;&gt;新增&lt;/el-button&gt; 保存修改准备工作：修改easymock 接口 /gathering/gathering/{id} （PUT) { &quot;code&quot;: 20000, &quot;flag&quot;: true, &quot;message&quot;: &quot;修改成功&quot; } 1.在gatherging.js添加update方法 //根据ID修改活动信息 update(id,pojo){ //优化 if(id==null||id==&apos;&apos;){ return this.save(pojo); } return request({ url:`/${group_name}/${method_name}/${id}`, method:&apos;put&apos;, data:pojo }) } 2.在gatherging.vue调用update方法 saveData() { gatheringApi.update(this.id, this.pojo).then(response =&gt; { alert(response.message); if (response.flag) { this.feechData(); } }); this.dislogFormVisble = false; //关闭窗口 } 消息提示框js原生的alert简直是丑爆了，有没有更漂亮的弹出框呀！当然有，用了elementUI提供了消息提示框！ alert(response.message)可以替换为以下代码： this.$message({ message: response.message, type: (response.flag?&apos;success&apos;:&apos;error&apos;) }); message组件文档 活动管理-删除EasyMock接口URL:gathering/:id Method: delete { &quot;code&quot;: 20000, &quot;flag&quot;: true, &quot;message&quot;: &quot;删除成功&quot; } 代码实现1.修改src/api/gathering.js，增加方法定义 //根据ID删除活动信息 deleteById(id){ return request({ url:`/${group_name}/${method_name}/${id}`, method:&apos;delete&apos; }) } 2.修改src/views/table/gathering.vue的js脚本部分 增加方法 //根据ID删除活动信息 deleteById(id) { this.$confirm(&quot;确定要删除此记录吗?&quot;, &quot;提示&quot;, { confirmButtonText: &quot;确定&quot;, cancelButtonText: &quot;取消&quot;, type: &quot;warning&quot; }) .then(() =&gt; { gatheringApi.deleteById(id).then(response =&gt; { this.$message({ message: response.message, type: response.flag ? &quot;success&quot; : &quot;error&quot; }); if (response.flag) { this.feechData(); //刷新数据 } }); }) .catch(() =&gt; {}); } 3.修改src/views/table/gathering.vue ，在操作列增加删除按钮 &lt;el-button @click=&quot;deleteById(scope.row.id)&quot; type=&quot;text&quot; size=&quot;small&quot;&gt;删除&lt;/el-button&gt;]]></content>
      <categories>
        <category>ElementUI</category>
      </categories>
      <tags>
        <tag>ElementUI</tag>
        <tag>vue</tag>
        <tag>nodejs</tag>
        <tag>npm</tag>
        <tag>easymock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本地部署EasyMock]]></title>
    <url>%2F2019%2F02%2F04%2F%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2EasyMock%2F</url>
    <content type="text"><![CDATA[EasyMock什么是EasyMock EasyMock是一个极其简单、高效、可视化、并且能快速生成模拟的在线mock服务。以项目管理的方式组织Mock List，能帮助我们更好的管理Mock数据。 地址 在线文档 本地部署EasyMockCentos部署node.js 将node官网下载的压缩包上传到服务器 解压xz文件 xz -d node-v8.11.1-linux-x64.tar.xz 解压tar文件 tar -xvf node-v8.11.1-linux-x64.tar.xz 目录重命名 mv node-v8.11.1-linux-x64 node 配置环境变量 vi /etc/profile export NODE_HOME=~/node export PATH=$NODE_HOME/bin:$PA 执行命令让环境变量生效 source /etc/profile 查看node版本看是否安装成功 node -v MongoDB安装与启动我们使用yum方式安装mongo 1.配置yum vi /etc/yum.repos.d/mongodb‐org‐3.2.repo [mongodb-org-3.2] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.2/x86_64/ gpgcheck=1 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-3.2.asc 2.安装MongoDB yum install ‐y mongodb‐org 3.启动MongoD systemctl start mongod Redis安装与启动1.下载fedora的epel仓库 yum install epel-release 2.下载安装reids yum install redis 3.启动redis服务 systemctl start redis 本地部署easy-mock1.项目下载地址:https://github.com/easy-mock/easy-mock 2.将easy-mock-dev.zip上传至服务器 3.安装zip和unzip yum install zip unzip 4.解压 unzip easy-mock-dev.zip 5.进入其目录，安装依赖 npm install 6.执行构建 npm run build 7.启动 npm run start 8.输入http://192.168.25.135:7300访问即可 导入swaggerAPI文档1.将SwaggerAPI文档扩展名改为yml 2.在easyMock中点击设置选项卡 3.SwaggerDocs API选择Upload 4.将SwaggerAPI闻到那股拖动到虚线区域，点击保存 5.回到主页面后点击“同步Swagger”]]></content>
      <categories>
        <category>EasyMock</category>
      </categories>
      <tags>
        <tag>easymock</tag>
        <tag>mockjs</tag>
        <tag>mongodb</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES6的概念以及基本使用]]></title>
    <url>%2F2019%2F02%2F03%2FES6%E7%9A%84%E6%A6%82%E5%BF%B5%E4%BB%A5%E5%8F%8A%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[ES6什么是ES6编程语言JavaScript是ECMAScript的实现和扩展 。ECMAScript是由ECMA(一个类似W3C的标准组织)参与进行标准化的语法规范。 ECMAScript定义了： 语言语法 – 语法解析规则、关键字、语句、声明、运算符等。 类型 – 布尔型、数字、字符串、对象等。 原型和继承 内建对象和函数的标准库 – JSON、Math、数组方法、对象自省方法等。 ECMAScript标准不定义HTML或CSS的相关功能，也不定义类似DOM(文档对象模型)的Web API，这些都在独立的标准中进行定义。 ECMAScript涵盖了各种环境中JS的使用场景，无论是浏览器环境还是类似node.js的非浏览器环境。 ECMAScript标准的历史版本分别是1、2、3、5。那么为什么没有第4版？ 其实，在过去确实曾计划发布提出巨量新特性的第4版，但最终却因想法太过激进而惨遭废除 （这一版标准中曾经有一个极其复杂的支持泛型和类型推断的内建静态类型系统）。 ES4饱受争议，当标准委员会最终停止开发ES4时，其成员同意发布一个相对谦和的ES5版本， 随后继续制定一些更具实质性的新特性。这一明确的协商协议最终命名为“Harmony”，因此，ES5规范中包含这样两句话 ECMAScript是一门充满活力的语言，并在不断进化中。未来版本的规范中将持续进行重要的技术改进 2009年发布的改进版本ES5，引入了Object.create()、Object.defineProperty()、getters 和setters、严格模式以及JSON对象。 ECMAScript 6.0（以下简称ES6）是JavaScript语言的下一代标准，2015年6月正式发 布。它的目标，是使得JavaScript语言可以用来编写复杂的大型应用程序，成为企业级开 发语言。 Node.js中使用ES6babel转换配置,项目根目录添加.babelrc 文件{ &quot;presets&quot;: [&quot;es2015&quot;] } 安装es6转换模块cnpm install babel‐preset‐es2015 ‐‐save‐d 全局安装命令行工具cnpm install babel‐cli ‐g 使用babel‐node js文件名 语法新特性6.3.1 变量声明let我们都是知道在ES6以前，var关键字声明变量。无论声明在何处，都会被视为声明在函数的最顶部(不在函数内即在全局作用域的最顶部)。这就是函数变量提升例如 1234567function aa() &#123; if(bool) &#123; var test = 'hello man' &#125; else &#123; console.log(test) &#125;&#125; 以上的代码实际上是: 12345678910function aa() &#123; var test // 变量提升 if(bool) &#123; test = 'hello man' &#125; else &#123; //此处访问test 值为undefined console.log(test) &#125; //此处访问test 值为undefined &#125; 所以不用关心bool是否为true or false。实际上，无论如何test都会被创建声明。 接下来ES6主角登场： 我们通常用let和const来声明，let表示变量、const表示常量。let和const都是块级作用域。怎么理解这个块级作用域？在一个函数内部 ，在一个代码块内部。看以下代码 //let function test(b){ if(b){ let a=&apos;abc&apos;; } console.log(a); } test(true); 6.3.2 常量声明const 用于声明常量，看以下代码 const name=&apos;abc&apos;; name=&apos;ccc&apos; console.log(name); 6.3.3 模板字符串es6模板字符简直是开发者的福音啊，解决了ES5在字符串功能上的痛点。 第一个用途，基本的字符串格式化。将表达式嵌入字符串中进行拼接。用${}来界定。 123456//es5 var name = 'lux'console.log('hello' + name)//es6const name = 'lux'console.log(`hello $&#123;name&#125;`) //hello lux 第二个用途，在ES5时我们通过反斜杠()来做多行字符串或者字符串一行行拼接。ES6反引号()直接搞定。 1234567// es5var msg = "Hi \man!"// es6const template = `&lt;div&gt; &lt;span&gt;hello world&lt;/span&gt;&lt;/div&gt;` 6.3.4 函数默认参数ES6为参数提供了默认值。在定义函数时便初始化了这个参数，以便在参数没有被传递进去时使用。 看例子代码 12345function action(num = 200) &#123; console.log(num)&#125;action() //200action(300) //300 6.3.5 箭头函数ES6很有意思的一部分就是函数的快捷写法。也就是箭头函数。 箭头函数最直观的三个特点。 1不需要function关键字来创建函数 2省略return关键字 3继承当前上下文的 this 关键字 看下面代码（ES6） 123(response,message) =&gt; &#123; .......&#125; 相当于ES5代码 123function(response,message)&#123; ......&#125; 6.3.6 对象初始化简写ES5我们对于对象都是以键值对的形式书写，是有可能出现键值对重名的。例如 123456function people(name, age) &#123; return &#123; name: name, age: age &#125;; &#125; 以上代码可以简写为 123456function people(name, age) &#123; return &#123; name, age &#125;; &#125; 6.3.7 解构数组和对象是JS中最常用也是最重要表示形式。为了简化提取信息，ES6新增了解构，这是将一个数据结构分解为更小的部分的过程 ES5我们提取对象中的信息形式如下 1234567const people = &#123; name: 'lux', age: 20&#125;const name = people.nameconst age = people.ageconsole.log(name + ' --- ' + age) 是不是觉得很熟悉，没错，在ES6之前我们就是这样获取对象信息的，一个一个获取。现在，ES6的解构能让我们从对象或者数组里取出数据存为变量，例如 123456789101112//对象 const people = &#123; name: 'lux', age: 20 &#125; const &#123; name, age &#125; = people console.log(`$&#123;name&#125; --- $&#123;age&#125;`) //数组 const color = ['red', 'blue'] const [first, second] = color console.log(first) //'red' console.log(second) //'blue' 6.3.8 Spread OperatorES6中另外一个好玩的特性就是Spread Operator 也是三个点儿…接下来就展示一下它的用途。 组装对象或者数组 123456789//数组const color = ['red', 'yellow']const colorful = [...color, 'green', 'pink']console.log(colorful) //[red, yellow, green, pink]//对象const alp = &#123; fist: 'a', second: 'b'&#125;const alphabets = &#123; ...alp, third: 'c' &#125;console.log(alphabets) //&#123; "fist": "a", "second": "b", "third": "c" 6.3.9 import 和 exportimport导入模块、export导出模块 lib.js 1234let fn0=function()&#123; console.log('fn0...');&#125;export &#123;fn0&#125; demo9.js 12import &#123;fn0&#125; from './lib'fn0(); 注意：node(v8.x)本身并不支持import关键字，所以我们需要使用babel的命令行工具来执行 1babel-node demo9 详细了解可以参考一下阮一峰的ECMAScript 6 入门ECMAScript 6 入门]]></content>
      <categories>
        <category>ES6</category>
      </categories>
      <tags>
        <tag>ES6</tag>
        <tag>babel</tag>
        <tag>VSCODE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Node.js的基本使用姿势]]></title>
    <url>%2F2019%2F02%2F03%2FNoDeJs%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E5%A7%BF%E5%8A%BF%2F</url>
    <content type="text"><![CDATA[Node.js什么是Node.js 简单的说 Node.js 就是运行在服务端的 JavaScript。Node.js 是一个基于Chrome JavaScript 运行时建立的一个平台。Node.js是一个事件驱动I/O服务端JavaScript环境，基于Google的V8引擎，V8引擎执行Javascript的速度非常快，性能非常好。 Node.js安装 下载对应你系统的Node.js版本: 下载node.js 选安装目录进行安装(默认即可) 快速入门控制台输出 输入node demo1.js执行即可 使用函数 模块化编程 创建web服务器//创建WEB服务器 var http=require(&apos;http&apos;); http.createServer(function(request,response){ // 发送 HTTP 头部 // HTTP 状态值: 200 : OK // 内容类型: text/plain response.writeHead(200, {&apos;Content-Type&apos;: &apos;text/plain&apos;}) // 发送响应数据 &quot;Hello World&quot; response.end(&apos;Hello World\n&apos;); }).listen(9000); // 终端打印如下信息 console.log(&apos;Server running at http://127.0.0.1:8888/&apos;); http为node.js内置的web模块 理解服务渲染//创建WEB服务器 var http=require(&apos;http&apos;); http.createServer(function(request,response){ // 发送 HTTP 头部 // HTTP 状态值: 200 : OK // 内容类型: text/plain response.writeHead(200,{&apos;Content-Type&apos;:&apos;text/plain&apos;}) // 发送响应数据 &quot;Hello World&quot; for(var i=0;i&lt;10;i++){ response.write(&apos;Hello World\n&apos;); } response.end(&apos;&apos;); }).listen(9000); // 终端打印如下信息 console.log(&apos;Server running at http://127.0.0.1:9000/&apos;); 我们右键“查看源代码”发现，并没有我们写的for循环语句，而是直接的10条Hello World，这就说明这个循环是在服务端完成的，而非浏览器（客户端）来完成。这与我们原来的JSP很是相似。 接收参数//接收参数 var http=require(&apos;http&apos;); var url=require(&apos;url&apos;); http.createServer(function(request,response){ response.writeHead(200,{&apos;Content-Type&apos;:&apos;text/plain&apos;}); //解析url参数 var params=url.parse(request.url,true).query; response.write(&quot;name:&quot;+params.name); response.write(&quot;\n&quot;); response.end(); }).listen(8888); 测试地址http://localhost:8888/?name=huangsm 包资源管理器NPM什么是NPM npm全称Node Package Manager，他是node包管理和分发工具。其实我们可以把NPM理解为前端的Maven .我们通过npm 可以很方便地下载js库，管理前端工程.最近版本的node.js已经集成了npm工具，在命令提示符输入 npm -v 可查看当前npm版本 NPM命令初始化工程 init命令是工程初始化命令。建立一个空文件夹，在命令提示符进入该文件夹 执行命令初始化 npm init 按照提示输入相关信息，如果是用默认值则直接回车即可。 name: 项目名称 version: 项目版本号 description: 项目描述 keywords: {Array}关键词，便于用户搜索到我们的项目 最后会生成package.json文件，这个是包的配置文件，相当于maven的pom.xml 我们之后也可以根据需要进行修改。 本地安装 install命令用于安装某个模块，如果我们想安装express模块（node的web框架），输出命令如下: npm install express 出现黄色的是警告信息，可以忽略，请放心，你已经成功执行了该命令。 在该目录下已经出现了一个node_modules文件夹 和package-lock.json node_modules文件夹用于存放下载的js库（相当于maven的本地仓库） package-lock.json是当 node_modules 或 package.json 发生变化时自动生成的文件。 这个文件主要功能是确定当前安装的包的依赖，以便后续重新安装的时候生成相同的依 赖，而忽略项目开发过程中有些依赖已经发生的更新。 我们再打开package.json文件，发现刚才下载的express已经添加到依赖列表中了. 关于版本号定义： 指定版本：比如1.2.2，遵循“大版本.次要版本.小版本”的格式规定，安装时只安装指定版 本。 波浪号（tilde）+指定版本：比如~1.2.2，表示安装1.2.x的最新版本（不低于1.2.2），但 是不安装1.3.x，也就是说安装时不改变大版本号和次要版本号。 插入号（caret）+指定版本：比如ˆ1.2.2，表示安装1.x.x的最新版本（不低于1.2.2），但 是不安装2.x.x，也就是说安装时不改变大版本号。需要注意的是，如果大版本号为0，则插 入号的行为与波浪号相同，这是因为此时处于开发阶段，即使是次要版本号变动，也可能带来 程序的不兼容。 latest：安装最新版本。 全局安装 刚才我们使用的是本地安装，会将js库安装在当前目录，而使用全局安装会将库安装到你的全局目录下。如果你不知道你的全局目录在哪里，执行命令 npm root ‐g 我的全局目录在C:\Users\Administrator\AppData\Roaming\npm\node_modules 比如我们全局安装jquery, 输入以下命令 npm install jquery ‐g 批量下载 我们从网上下载某些代码，发现只有package.json,没有node_modules文件夹，这时我们需要通过命令重新下载这些js库 进入目录（package.json所在的目录）输入命令 npm install 此时，npm会自动下载package.json中依赖的js库. 淘宝NPM镜像 有时我们使用npm下载资源会很慢，所以我们可以安装一个cnmp(淘宝镜像)来加快下载速度 输入命令，进行全局安装淘宝镜像。 npm install -g cnpm --registry=https://registry.npm.taobao.org 安装后，我们可以使用以下命令来查看cnpm的版本 cnpm -v 使用cnpm cnpm install 需要下载的js库 运行工程 如果我们想运行某个工程，则使用run命令如果package.json中定义的脚本如下dev是开发阶段测试运行build是构建编译工程lint 是运行js代码检测我们现在来试一下运行dev npm run dev 编译工程 我们接下来，测试一个代码的编译.编译后我们就可以将工程部署到nginx中,编译后的代码会放在dist文件夹中，首先我们先删除dist文件夹中的文件,进入命令提示符 输入命令 npm run build 生成后我们会发现只有个静态页面，和一个static文件夹 这种工程我们称之为单页Web应用（single page web application，SPA），就是只有一 张Web页面的应用，是加载单个HTML 页面并在用户与应用程序交互时动态更新该页面的Web应用程序。 这里其实是调用了webpack来实现打包的. Webpack什么是Webpack Webpack 是一个前端资源加载/打包工具。它将根据模块的依赖关系进行静态分析，然后将这些模块按照指定的规则生成对应的静态资源 从图中我们可以看出,Webpack可以将多种静态资源js、css、less 转换成一个静态文件,减少了页面的请求。接下来我们简单为大家介绍Webpack的安装与使用 Webpack安装 全局安装 cnpm install webpack -g cnpm install webpack-cli -g 安装后查看版本号 webpack -v 快速入门JS打包 创建src文件夹，创建bar.js exports.info=function(str){ document.write(str); }; src下创建logic.js exports.add=function(a,b){ return a+b; }; src下创建main.js var bar=require(&apos;./bar&apos;); var logic=require(&apos;./logic&apos;); bar.info(&apos;hello world!&apos;+logic.add(100,200)); 创建配置文件webpack.config.js ，该文件与src处于同级目录 const path = require(&apos;path&apos;); module.exports = { entry: &apos;./src/main.js&apos;, output: { path: path.resolve(__dirname, &apos;dist&apos;), filename: &apos;bundle.js&apos; } }; 以上代码的意思是：读取当前目录下src文件夹中的main.js（入口文件）内容，把对应的js文件打包，打包后的文件放入当前目录的dist文件夹下，打包后的js文件名为bundle. 执行编译命令 webpack 执行后查看bundle.js 会发现里面包含了上面两个js文件的 创建index.html ,引用bundle.js &lt;!doctype html&gt; &lt;html&gt; &lt;head&gt; &lt;/head&gt; &lt;body&gt; &lt;script src=&quot;dist/bundle.js&quot;&gt;&lt;/script&gt; &lt;/body&gt; &lt;/html&gt;]]></content>
      <categories>
        <category>Node.js</category>
      </categories>
      <tags>
        <tag>Node.js</tag>
        <tag>webpack</tag>
        <tag>NPM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[容器管理与容器监控]]></title>
    <url>%2F2019%2F02%2F03%2F%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86%E4%B8%8E%E5%AE%B9%E5%99%A8%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[容器管理与容器监控容器管理工具Rancher什么是Rancher Rancher是一个开源的企业级全栈化容器部署及管理平台。Rancher为容器提供一揽子基础架构服务：CNI兼容的网络服务、存储服务、主机管理、负载均衡、防护墙……Rancher让上述服务跨越公有云、私有云、虚拟机、物理机环境运行，真正实现一键式应用部署和管理 Rancher官网 Rancher安装 下载镜像 docker pull rancher/server 创建Rancher容器 docker run -d –name=rancher –restart=always -p 9090:8080 rancher/server restart为重启策略no，默认策略，在容器退出时不重启容器 on-failure，在容器非正常退出时（退出状态非0），才会重启 on-failure:3，在容器非正常退出时重启容器，最多重启3次 always，在容器退出时总是重启容器 unless-stopped，在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的 测试 http://192.168.25.134:9090/ Rancher初始化添加环境 Rancher 支持将资源分组归属到多个环境。 每个环境具有自己独立的基础架构资源及服务，并由一个或多个用户、团队或组织所管理。例如，您可以创建独立的“开发”、“测试”及“生产”环境以确保环境之间的安全隔离，将“开发”环境的访问权限赋予全部人员，但限制“生产”环境的访问权限给一个小的团队。 （1）选择“Default –&gt;环境管理 （2）填写名称，点击”创建”按钮 （3）按照上述步骤，添加服务测试环境和生产环境 （4）你可以通过点击logo右侧的菜单在各种环境下 添加镜像库 192.168.25.134 添加主机 选择基础架构–&gt;主机 菜单，点击添加主机 拷贝脚本 在服务器（虚拟机）上运行脚本 点击关闭按钮后，会看到界面中显示此主机。我们可以很方便地管理主机的每个容器的开启和关闭 添加应用(所有微服务的集合) 点击应用–&gt;全部(或用户) ，点击”添加应用”按钮 填写名称和描述 点击”创建”按钮，列表中增加了新增的应用 应用部署MySQL部署 镜像：centos/mysql-57-centos7 增加数据库服务 点击创建按钮，完成创建 上述操作相当于以下docker命令 docker run ‐d ‐‐name mysql ‐p 3306:3306 ‐e MYSQL_ROOT_PASSWORD=mysql centos/mysql‐57‐centos 微服务容器部署Eureka微服务容器化部署 在用户应用界面中点击”添加服务” 填写名称、描述、镜像和端口映射，点击创建按钮 服务添加成功 influxDB什么是influxDB influxDB是一个分布式时间序列数据库。cAdvisor仅仅显示实时信息，但是不存储监视数据。因此，我们需要提供时序数据库用于存储cAdvisor组件所提供的监控信息，以便显示除实时信息之外的时序数 influxDB安装 下载镜像 docker pull tutum/influxdb 创建容器 docker run -d -p 8083:8083 -p 8086:8086 –expose 8090 –expose 8099 –name influxsrv tutum/influxdb 端口概述： 8083端口:web访问端口 8086:数据写入 http://192.168.25.134:8083/ nfluxDB常用操作创建数据库 创建用户并授权 创建用户 查看用户 用户授权 grant all privileges on huangsm to huangsm grant WRITE on huangsm to huangsm grant READ on huangsm to huangsm 查看采集的数据 SHOW MEASUREMEN cAdvisor什么是cAdvisor Google开源的用于监控基础设施应用的工具，它是一个强大的监控工具，不需要任何配置就可以通过运行在Docker主机上的容器来监控Docker容器，而且可以监控Docker主机。更多详细操作和配置选项可以查看Github上的cAdvisor项目文档。 cAdvisor安装 拉去镜像 docker pull google/cadvisor 启动容器 docker run -v=/:/rootfs:ro -v=/var/run:/var/run:rw -v=/sys:/sys:ro -v=/var/lib/docker/:/var/lib/docker:ro -p 8080:8080 --detach=true --link influxsrv:influxsrv --name=cadvisor google/cadvisor -storage_driver=influxdb -storage_driver_db=huangsm -storage_driver_host=influxsrv:8086 WEB前端访问地址 http://192.168.25.134:8080/containers/ 性能指标含义参照如下地址 再次查看influxDB，发现已经有很多数据被采集进去 Grafana什么是Grafana Grafana是一个可视化面板（Dashboard），有着非常漂亮的图表和布局展示，功能齐全的度量仪表盘和图形编辑器。支持Graphite、zabbix、InfluxDB、Prometheus和OpenTSDB作为数据源。Grafana主要特性：灵活丰富的图形化选项；可以混合多种风格；支持白天和夜间模式；多个数据源。 Grafana安装 下载镜像 docker pull grafana/grafana 创建容器 docker run -d -p 3001:3000 -e INFLUXDB_HOST=influxsrv -e INFLUXDB_PORT=8086 -e INFLUXDB_NAME=cadvisor -e INFLUXDB_USER=huangsm -e INFLUXDB_PASS=1234 –link influxsrv:influxsrv –name=grafana grafana/grafana 访问(http://192.168.25.134:3001 初始帐号密码都为admin) 登录后提示你修改密码 之后进入主页面 Grafana的使用添加数据源 点击设置，DataSource 点击添加data source 为数据源起个名称，指定类型、地址、以及连接的数据库名、用户名和密码 添加仪表盘 选择Dashboards –Manager 点击“添加”按钮 点击Graph图标 出现下面图表的界面 ，点击Panel Title 选择Edit (编辑) 定义标题等基础信息 设置查询的信息为内存，指定容器名称 指定y轴的单位 为M 保存 预警通知设置 选择菜单 alerting–&gt; Notification channels 点击Add channel 按钮 填写名称，选择类型为webhook ,填写钩子地址（这个钩子地址是之前对base微服务扩容的地址） 点击SendTest 测试 观察基础微服务是否增加容器 点击save保存 按照同样的方法添加缩容地址 仪表盘预警设置 再次打开刚刚编辑的仪表盘 点击 Create Alert 选择通知]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>Rancher</tag>
        <tag>influxDB</tag>
        <tag>cAdvisor</tag>
        <tag>Grafana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务的持续化部署]]></title>
    <url>%2F2019%2F02%2F02%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%8C%81%E7%BB%AD%E5%8C%96%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[理解持续集成什么是持续集成 持续集成 Continuous integration ，简称CI &nbsp;&nbsp;&nbsp;随着软件开发复杂度的不断提高，团队开发成员间如何更好地协同工作以确保软件开发的质量已经慢慢成为开发过程中不可回避的问题。尤其是近些年来，敏捷（Agile）在软件工程领域越来越红火，如何能再不断变化的需求中快速适应和保证软件的质量也显得尤其的重要。 &nbsp;&nbsp;&nbsp;持续集成正是针对这一类问题的一种软件开发实践。它倡导团队开发成员必须经常集成他们的工作，甚至每天都可能发生多次集成。而每次的集成都是通过自动化的构建来验证，包括自动编译、发布和测试，从而尽快地发现集成错误，让团队能够更快的开发内聚的软件. 持续集成的特点 它是一个自动化的周期性的集成测试过程，从检出代码、编译构建、运行测试、结果记录、测试统计等都是自动完成的，无需人工干预； 需要有专门的集成服务器来执行集成构建； 需要有代码托管工具支持，我们下一小节将介绍Git以及可视化界面Gogs的 持续集成作用 保证团队开发人员提交代码的质量，减轻了软件发布时的压力； 持续集成中的任何一个环节都是自动完成的，无需太多的人工干预，有利于减少重复过程以节省时间、费用和工作量； Gogs什么是Gogs Gogs 是一款极易搭建的自助 Git 服务。 Gogs 的目标是打造一个最简单、最快速和最轻松的方式搭建自助 Git 服务。使用 Go 语言开发使得 Gogs 能够通过独立的二进制分发，并且支持 Go 语言支持的 所有平台，包括 Linux、Mac OS X、Windows 以及 ARM 平台。 地址：https://gitee.com/Unknown/gogs Gogs安装与配置安装 下载镜像 docker pull gogs/gogs 创建容器 docker run -d –name=gogs -p 10022:22 -p 3000:3000 -v /var/gogsdata:/data gogs/gogs 3000是外部访问使用，10022是内部使用 配置 假设我的centos虚拟机IP为192.168.25.134 完成以下步骤（1）在地址栏输入http://192.168.25.134:3000 会进入首次运行安装程序页面，我们可以选择一种数据库作为gogs数据的存储，最简单的是选择SQLite3。如果对于规模较大的公司，可以选择MySQL 剩下的操作类似与码云和gitHub这里就不一一赘述了 运用Jenkins实现持续集成Jenkins简介 Jenkins，原名Hudson，2011年改为现在的名字，它是一个开源的实现持续集成的软件工具。 官方网站：http://jenkins-ci.org/。Jenkins能实施监控集成中存在的错误，提供详细的日志文件和提醒功能，还能用图表的形式形象地展示项目构建的趋势和稳定性。 特点: 易安装：仅仅一个 java -jar jenkins.war，从官网下载该文件后，直接运行，无需额外的安装，更无需安装数据库； 易配置：提供友好的GUI配置界面； 变更支持：Jenkins能从代码仓库（Subversion/CVS）中获取并产生代码更新列表并输出到编译输出信息中；支持永久 链接：用户是通过web来访问Jenkins的，而这些web页面的链接地址都是永久链接地址，因此，你可以在各种文档中直接使用该链接； 集成E-Mail/RSS/IM：当完成一次集成时，可通过这些工具实时告诉你集成结果（据我所知，构建一次集成需要花费一定时间，有了这个功能，你就可以在等待结果过程中，干别的事情）； JUnit/TestNG测试报告：也就是用以图表等形式提供详细的测试报表功能； 支持分布式构建：Jenkins可以把集成构建等工作分发到多台计算机中完成； 文件指纹信息：Jenkins会保存哪次集成构建产生了哪些jars文件，哪一次集成构建使用了哪个版本的jars文件等构建记录； 支持第三方插件：使得 Jenkins 变得越来越 Jenkins安装JDK安装 将jdk-8u171-linux-x64.rpm上传至服务器（虚拟机） 执行安装命令 rpm ‐ivh jdk‐8u171‐linux‐x64.rpm RPM方式安装JDK，其根目录为：/usr/java/jdk1.8.0_171t Jenkins安装与启动 下载jenkins wget https://pkg.jenkins.io/redhat/jenkins‐2.83‐1.1.noarch.rpm 安装jenkins rpm ‐ivh jenkins‐2.83‐1.1.noarch.rpm 配置jenkins vi /etc/sysconfig/jenkins 修改用户和端口 JENKINS_USER=”root”JENKINSPORT=”8888” 启动服务 systemctl start jenkins 访问链接 http://192.168.25.134:8888 从/var/lib/jenkins/secrets/initialAdminPassword中获取初始密码串 安装插件 新建用户 Jenkins插件安装安装Maven插件 全局工具配置选择系统管理，全局工具配置 JDK安装 设置JAVA_HOME为 /usr/java/jdk1.8.0_171-amd64 Maven安装（这里的mavenhome是我服务器上maven的路径） 持续集成创建任务 回到首页，点击新建按钮 .如下图，输入名称，选择创建一个Maven项目，点击OK 可以看到控制台输出 持续集成成功 这样我们的持续集成就算配置完成了]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>gogs</tag>
        <tag>jenkins</tag>
        <tag>持续化部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dockerfile的基本使用以及服务的部署]]></title>
    <url>%2F2019%2F02%2F01%2Fdockerfile%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E4%BB%A5%E5%8F%8A%E6%9C%8D%E5%8A%A1%E7%9A%84%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[DockerFile什么是DockerFile?Dockerfile是由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。 1、对于开发人员：可以为开发团队提供一个完全一致的开发环境； 2、对于测试人员：可以直接拿开发时所构建的镜像或者通过Dockerfile文件构建一个新的镜像开始工作了； 3、对于运维人员：在部署时，可以实现应用的无缝移植。 常用命令 使用脚本创建镜像1.首先将jdk的压缩包上传到服务器 2.编写dockerfile #依赖镜像名称和ID FROM centos:7 #指定镜像创建者信息 MAINTAINER Huangsm #切换工作目录 WORKDIR /usr RUN mkdir /usr/local/java #ADD 是相对路径jar,把java添加到容器中 ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/ #配置java环境变量 ENV JAVA_HOME /usr/local/java/jdk1.8.0_171 ENV JRE_HOME $JAVA_HOME/jre ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH ENV PATH $JAVA_HOME/bin:$PATH 3.使用docker build构建镜像 使用命令docker build -t=&quot;huangsm/jdk8&quot; . 4.启动容器 docker run -it --name=myjdk8 huangsm/jdk8 /bin/bash Docker私有仓库私有仓库搭建与配置1.拉取私有仓库镜像 docker pull registry 2.启动私有仓库容器 docker run -d --name=huangsm_dockerresp -p 5000:5000 docker.io/registry 3.查看仓库内容 http://192.168.25.133:5000/v2/_catalog 4.修改daemon.json vi /etc/docker/daemon.json 添加如下内容: &quot;insecure-registries&quot;:[&quot;192.168.25.133:5000&quot;] 5.重启docker服务 systemctl restart docker 镜像上传至私有仓库（1）标记此镜像为私有仓库的镜像 docker tag huangsm/jdk8 192.168.25.133:5000/jdk1.8 （2）再次启动私服容器 docker start huangsm_dockerresp （3）上传标记的镜像 docker push 192.168.25.133:5000/jdk1.8 DockerMaven插件微服务部署有两种方法： （1）手动部署：首先基于源码打包生成jar包（或war包）,将jar包（或war包）上传至虚拟机并拷贝至JDK容器。 （2）通过Maven插件自动部署。 对于数量众多的微服务，手动部署无疑是非常麻烦的做法，并且容易出错。所以我们这里学习如何自动部署， 这也是企业实际开发中经常使用的方法 Maven插件自动部署步骤: （1）修改宿主机的docker配置，让其可以远程访问 vi /lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd-current -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock （2）刷新配置，重启服务 systemctl daemon‐reload systemctl restart docker docker start registry (3)在config配置中心工程pom.xml 增加配置插件 &lt;build&gt; &lt;finalName&gt;app&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- docker的maven插件，官网：https://github.com/spotify/docker‐maven‐plugin --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;192.168.25.134:5000/${project.artifactId}:${project.version}&lt;/imageName&gt; &lt;baseImage&gt;192.168.25.134:5000/jdk1.8&lt;/baseImage&gt; &lt;entryPoint&gt;[&quot;java&quot;, &quot;-jar&quot;,&quot;/${project.build.finalName}.jar&quot;]&lt;/entryPoint&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory}&lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;dockerHost&gt;http://192.168.25.134:2375&lt;/dockerHost&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 使用以上DockerMaven插件会自动创建Dockerfile (4) 使用mvn clean package docker:build -DpushImage 根据图片就可以看出我已经将我开发的微服务push到私人仓库中了]]></content>
      <categories>
        <category>Dockerfile</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>DockerFile</tag>
        <tag>DockerMaven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloudConfig和SpringCloudBus实战应用]]></title>
    <url>%2F2019%2F01%2F30%2FSpringCloudConfig%E5%92%8CSpringCloudBus%E5%AE%9E%E6%88%98%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[集中配置组件SpringCloudConfigSpring Cloud Config简介在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。 在Spring Cloud中，有分布式配置中心组件spring cloud config ，它支持配置服务放在配置服务的内存中(即本地)， 也支持放在远程Git仓库中。在spring cloud config 组件中，分两个角色，一是config server，二是config client。 Config Server是一个可横向扩展、集中式的配置服务器，它用于集中管理应用程序各个环境下的配置， 默认使用Git存储配置文件内容，也可以使用SVN存储，或者是本地文件存储。 Config Client是Config Server的客户端，用于操作存储在Config Server中的配置内容。 微服务在启动时会请求Config Server获取配置文件的内容，请求到后再启动容器。 详细内容看在线文档： https://springcloud.cc/spring-cloud-config.html 配置服务端 因为我们这里用的是Git仓库，所以我将我的配置文件放的我码云的仓库里 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; 修改配置文件 server: port: 12000 spring: application: name: tensquare-config cloud: config: server: git: uri: https://gitee.com/wangyuanbaby/study-config.git 在启动类添加@EnableConfigServer注解 配置客户端 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; 删除原来的配置文件，添加bootstrap.yml配置以下内容 spring: cloud: config: name: base label: master profile: dev uri: http://127.0.0.1:12000 application: name: base-dev 消息总线组件SpringCloudBusSpringCloudBus简介如果我们更新码云中的配置文件，那客户端工程是否可以及时接受新的配置信息呢？我们现在来做有一个测试， 修改一下码云中的配置文件中mysql的端口 ，然后测试http://localhost:9001/label 数据依然可以查询出来， 证明修改服务器中的配置并没有更新立刻到工程，只有重新启动程序才会读取配置。 那我们如果想在不重启微服务的情况下更新配置如何来实现呢? 我们使用SpringCloudBus来实现配置的自动更新。 配置Config服务端 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 修改配置文件 server: port: 12000 spring: application: name: tensquare-config cloud: config: server: git: uri: https://gitee.com/wangyuanbaby/study-config.git rabbitmq: host: 192.168.25.133 management: #暴露触发消息总线的地址 endpoints: web: exposure: include: bus-refresh 配置Config客户端1. 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 2. 在码云中修改对应服务配置文件 rabbitmq: host: 192.168.25.133 cloud: refresh: refreshable: none #解决引入actuator时所造成的数据源死循环问题 修改码云上的配置文件 ，将数据库连接IP 改为127.0.0.1 ，在本地部署一份数据库。 postman测试 Url: http://127.0.0.1:12000/actuator/bus-refresh Method:post 再次观察输出的数据是否是读取了本地的mysql数据。 如果需要通过BUS来动态获取配置文件中的自定义配置的话，需要在Controller上加@RefreshScope注解 结束语我这里只是使用SpringCloudConfig和SpringConfigBus在实战中的应用，想要了解更加详细的应用和配置可以去阅读官方文档，相信你会收获颇深！]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>SpringCloudConfig</tag>
        <tag>SpringCloudBus</tag>
        <tag>配置中心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务网关zuul的概念与实战]]></title>
    <url>%2F2019%2F01%2F28%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3zuul%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[微服务网关Zuul为什么需要微服务网关不同的微服务一般有不同的网络地址，而外部的客户端可能需要调用多个服务的接口才 能完成一个业务需求。比如一个电影购票的收集APP,可能回调用电影分类微服务，用户 微服务，支付微服务等。如果客户端直接和微服务进行通信，会存在一下问题： 客户端会多次请求不同微服务，增加客户端的复杂性 存在跨域请求，在一定场景下处理相对复杂 认证复杂，每一个服务都需要独立认证 难以重构，随着项目的迭代，可能需要重新划分微服务，如果客户端直接和微服务通信，那么重构会难以实施 某些微服务可能使用了其他协议，直接访问有一定困难 上述问题，都可以借助微服务网关解决。微服务网关是介于客户端和服务器端之间的中 间层，所有的外部请求都会先经过微服务网关。 什么是ZuulZuul是Netflix开源的微服务网关，他可以和Eureka,Ribbon,Hystrix等组件配合使 用。Zuul组件的核心是一系列的过滤器，这些过滤器可以完成以下功能： 身份认证和安全: 识别每一个资源的验证要求，并拒绝那些不符的请求 审查与监控： 动态路由：动态将请求路由到不同后端集群 压力测试：逐渐增加指向集群的流量，以了解性能 负载分配：为每一种负载类型分配对应容量，并弃用超出限定值的请求 静态响应处理：边缘位置进行响应，避免转发到内部集群 多区域弹性：跨域AWS Region进行请求路由，旨在实现ELB(ElasticLoad Balancing)使 用多样化 Spring Cloud对Zuul进行了整合和增强。 使用Zuul后，架构图演变为以下形式 Zuul路由转发 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; 修改application.yml文件 server: port: 9012 spring: application: name: tensquare-manager eureka: client: service-url: defaultZone: http://localhost:9010/eureka/ instance: prefer-ip-address: true instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}} zuul: routes: tensquare-base: /base/** tensquare-article: /article/** tensquare-user: /user/** jwt: config: key: huangsmzhenshuai hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 60000 # 解决请求超时连接问题 ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 management: endpoint: health: show-details: always endpoints: web: exposure: include: &quot;*&quot; 在启动类添加@EnableZuulProxy Zuul过滤器 Zuul过滤器快速体验 创建一个简单的zuul过滤器: /** * Zuul过滤器 * @author huangsm */ @Component public class WebFilter extends ZuulFilter { /** * filterType：返回一个字符串代表过滤器的类型，在zuul中定义了四种不同生命周期的过 * 滤器类型，具体如下： * * pre ：可以在请求被路由之前调用 * * route ：在路由请求时候被调用 * * post ：在route和error过滤器之后被调用 * * error ：处理请求时发生错误时被调用 * filterOrder ：通过int值来定义过滤器的执行顺序 * shouldFilter ：返回一个boolean类型来判断该过滤器是否要执行，所以通过此函数可 * 实现过滤器的开关。在上例中，我们直接返回true，所以该过滤器总是生效 * run ：过滤器的具体逻辑。 */ @Override public String filterType() { //前置过滤器 return &quot;pre&quot;; } @Override public int filterOrder() { //优先级为0,数字越大，优先级越低 return 0; } @Override public boolean shouldFilter() { //是否执行该过滤器，此处为true，说明需要过滤 return true; } @Override public Object run() throws ZuulException { System.out.println(&quot;进过了Zuul过滤器!&quot;); return null; } } filterType：返回一个字符串代表过滤器的类型，在zuul中定义了四种不同生命周期的过 滤器类型，具体如下： * pre ：可以在请求被路由之前调用 * route ：在路由请求时候被调用 * post ：在route和error过滤器之后被调用 * error ：处理请求时发生错误时被调用 filterOrder ：通过int值来定义过滤器的执行顺序 shouldFilter ：返回一个boolean类型来判断该过滤器是否要执行，所以通过此函数可 实现过滤器的开关。在上例中，我们直接返回true，所以该过滤器总是生效 run ：过滤器的具体逻辑。 网站前台的token转发 1.网关转发Token信息到下游服务 @Override public Object run() throws ZuulException { System.out.println(&quot;进过了Zuul过滤器!&quot;); //得到request上下文 RequestContext currentContext = RequestContext.getCurrentContext(); //得到request域 HttpServletRequest request = currentContext.getRequest(); //得到头信息 String authorization = request.getHeader(&quot;Authorization&quot;); //判断是否有头信息 if (StringUtils.isNotBlank(authorization)) { currentContext.addZuulRequestHeader(&quot;Authorization&quot;, authorization); } return null; } 管理后台过滤器实现token校验 @Override public Object run() throws ZuulException { RequestContext currentContext = RequestContext.getCurrentContext(); HttpServletRequest request = RequestContext.getCurrentContext().getRequest(); String authorization = request.getHeader(&quot;Authorization&quot;); //第一次请求时，进过OPTIONS方法来分发路径，不会带有头信息 if (request.getMethod().equals(&quot;OPTIONS&quot;)){ return null; } //如果login存在这为登录请求，就放行 if (request.getRequestURI().indexOf(&quot;/admin/login&quot;)&gt;0){ System.out.println(&quot;登录页面&quot;+request.getRequestURI()); return null; } if (StringUtils.isNotBlank(authorization)) { if (authorization.startsWith(&quot;Bearer &quot;)) { String token = authorization.substring(7); try { Claims claims = jwtUtil.parseJWT(token); String roles = (String) claims.get(&quot;roles&quot;); if (roles.equals(&quot;admin&quot;)) { currentContext.addZuulRequestHeader(&quot;Authorization&quot;, authorization); return null; } } catch (Exception e) { //终止运行 currentContext.setSendZuulResponse(false); currentContext.setResponseStatusCode(HttpStatus.SC_UNAUTHORIZED); currentContext.setResponseBody(&quot;无权访问&quot;); } } } //终止运行 currentContext.setSendZuulResponse(false); currentContext.setResponseStatusCode(HttpStatus.SC_UNAUTHORIZED); currentContext.setResponseBody(&quot;无权访问&quot;); currentContext.getResponse().setContentType(&quot;text/html;charset=UTF-8&quot;); return null; } 解决CORS跨域请求问题 /** * 解决cors跨域问题 * @author huangsm * @version V1.0 */ @Configuration public class WebMvcConfigurer { @Bean public WebMvcConfigurer corsConfigurer() { return new WebMvcConfigurer() { public void addCorsMappings(CorsRegistry registry) { registry.addMapping(&quot;/users/**&quot;) .allowedOrigins(&quot;http://huangsm.zyx.com&quot;) .allowedMethods(&quot;GET&quot;, &quot;POST&quot;); } }; } } 关于更加详细的Zuul网关的使用，可以了解下我的码云上的代码 SpringCloud-Zuul]]></content>
      <categories>
        <category>Zuul</category>
      </categories>
      <tags>
        <tag>Zuul</tag>
        <tag>统一权限管理与Token转发</tag>
        <tag>Zuul访问超时问题解决</tag>
        <tag>统一Cors跨域解决</tag>
        <tag>Zuul过滤器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud的Hystrix断路器在服务中的应用]]></title>
    <url>%2F2019%2F01%2F27%2FSpringCloud%E7%9A%84Hystrix%E6%96%AD%E8%B7%AF%E5%99%A8%E5%9C%A8%E6%9C%8D%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[熔断器Hystrix为什么要使用熔断器 &nbsp;&nbsp;&nbsp;在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程。 &nbsp;&nbsp;&nbsp;如果下图所示：A作为服务提供者，B为A的服务消费者，C和D是B的服务消费者。A不可用引起了B的不可用，并将不可用像滚雪球一样放大到C和D时，雪崩效应就形成了。 如何避免产生这种雪崩效应呢？我们可以使用Hystrix来实现熔断器。 什么是Hystrix Hystrix 能使你的系统在出现依赖服务失效的时候，通过隔离系统所依赖的服务，防止服务级联失败，同时提供失败回退机制，更优雅地应对失效，并使你的系统能更快地从异常中恢复。 了解熔断器模式请看下图: 快速入门 Feign 本身支持Hystrix，不需要额外引入依赖。修改application.yml配置文件 feign: hystrix: enabled: true 创建BaseClient实现类 @FeignClient(name = &quot;tensquare-base&quot;,fallback = BaseClientFallback.class,configuration = FallBackConfig.class) public interface BaseClient { /** * 调用base服务的根据ID查询文章接口 * @param labelId * @return */ @GetMapping(&quot;/label/{labelId}&quot;) Result findById(@PathVariable(&quot;labelId&quot;) String labelId); } /** * 熔断器 * @author huangsm */ @Component public class BaseClientFallback implements BaseClient{ @Override public Result findById(String labelId) { return new Result(false, StatusCode.ERROR,&quot;服务崩溃了~&quot;); } } 创建配置类，监控feign客户端日志 /** * feign配置类 * @author huangsm */ public class FallBackConfig { /** * 配置Feign的日志级别 * @return */ @Bean public Logger.Level feignLoggerLevel(){ return Logger.Level.FULL; } } 根据日志监听类 logging: level: com.tensquare.qa.client.BaseClient: debug]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
        <tag>Feign</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud基本概念以及服务注册与服务调用]]></title>
    <url>%2F2019%2F01%2F27%2FSpringCloud%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%BB%A5%E5%8F%8A%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[SpringCloud简介什么是SpringCloud? Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、熔断器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 &nbsp;&nbsp;&nbsp;Spring Cloud项目的官方网址 SpringCloud与SpringBoot的关系 &nbsp;&nbsp;&nbsp;Spring Boot 是 Spring 的一套快速配置脚手架，可以基于Spring Boot 快速开发单个微服务，Spring Cloud是一个基于Spring Boot实现的云应用开发工具；Spring Boot专注于快速、方便集成的单个微服务个体，Spring Cloud关注全局的服务治理框架；Spring Boot使用了默认大于配置的理念，很多集成方案已经帮你选择好了，能不配置就不配置，Spring Cloud很大的一部分是基于Spring Boot来实现，可以不基于Spring Boot吗？不可以。 Spring Boot可以离开Spring Cloud独立使用开发项目，但是Spring Cloud离不开Spring Boot，属于依赖的关系。 Spring Cloud和Dubbo对比 或许很多人会说Spring Cloud和Dubbo的对比有点不公平，Dubbo只是实现了服务治理，而Spring Cloud下面有17个子项目（可能还会新增）分别覆盖了微服务架构下的方方面面，服务治理只是其中的一个方面，一定程度来说，Dubbo只是Spring CloudNetflix中的一个子集。 这里可以去了解下我以前一篇文章了解下RPC和HTTP直接的区别，也可以帮助你了解Dubbo和SC之间的区别简述HTTP和RPC的优缺点 服务发现组件 EurekaEureka Eureka是Netflix开发的服务发现框架，SpringCloud将它集成在自己的子项目 spring-cloud-netflix中，实现SpringCloud的服务发现功能。Eureka包含两个组件： Eureka Server和Eureka Client。 Eureka Server提供服务注册服务，各个节点启动后，会在Eureka Server中进行注 册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点 的信息可以在界面中直观的看到。 Eureka Client是一个java客户端，用于简化与Eureka Server的交互，客户端同时也 就别一个内置的、使用轮询(round-robin)负载算法的负载均衡器。在应用启动后，将会 向Eureka Server发送心跳,默认周期为30秒，如果Eureka Server在多个心跳周期内没有 接收到某个节点的心跳，Eureka Server将会从服务注册表中把这个服务节点移除(默认90 秒)。 Eureka Server之间通过复制的方式完成数据的同步，Eureka还提供了客户端缓存机 制，即使所有的Eureka Server都挂掉，客户端依然可以利用缓存中的信息消费其他服务 的API。综上，Eureka通过心跳检查、客户端缓存等机制，确保了系统的高可用性、灵活 性和可伸缩性。 Eureka服务端开发 创建注册中心模块 引入依赖 &lt;properties&gt; &lt;spring-cloud.version&gt; Finchley.RELEASE&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 添加application.yml配置 server: port: 9010 spring: application: name: eureka-register eureka: client: service-url: defaultZone: http://localhost:${server.port}/eureka/ register-with-eureka: false fetch-registry: false 在启动类加上@EnableEurekaServer 服务注册 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; 编写application.yml文件 eureka: client: service-url: defaultZone: http://localhost:9010/eureka/ instance: prefer-ip-address: true instance-id: ${spring.application.name}:${spring.application.instance_id:${server.port}} 注意F版本后，客户端无需在启动类加@EnableEurekaClient注解 ### 保护模式 如果在Eureka Server的首页看到以下这段提示，则说明Eureka已经进入了保护模式： &nbsp;&nbsp;&nbsp;Eureka Server在运行期间，会统计心跳失败的比例在15分钟之内是否低于85%，如果出现低于的情况（在单机调试的时候很容易满足，实际在生产环境上通常是由于网络不稳定导致），Eureka Server会将当前的实例注册信息保护起来，同时提示这个警告。保护模式主要用于一组客户端和Eureka Server之间存在网络分区场景下的保护。一旦进入保护模式，Eureka Server将会尝试保护其服务注册表中的信息，不再删除服务注册表中的数据（也就是不会注销任何微服务）。 Feign实现服务间的调用Feign简介 &nbsp;&nbsp;&nbsp;Feign是简化Java HTTP客户端开发的工具（java-to-httpclient-binder），它的灵感来自于Retrofit、JAXRS-2.0和WebSocket。Feign的初衷是降低统一绑定Denominator到HTTP API的复杂度，不区分是否为restful. (通过Feign)实现问答服务调用基础服务 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; 在启动类添加@EnableFeignClients和@EnableDiscoveryClient 调用Base服务接口 /** * 通过Feign调用服务 * @author huangsm */ @FeignClient(name = &quot;tensquare-base&quot;) public interface BaseClient { /** * 调用base服务的根据ID查询文章接口 * @param labelId * @return */ @GetMapping(&quot;/label/{labelId}&quot;) Result findById(@PathVariable(&quot;labelId&quot;) String labelId); } 远程服务的使用 @Autowired private BaseClient baseClient; @GetMapping(value = &quot;/label/{labelid}&quot;) public Result findLabelById(@PathVariable String labelid){ Result result = baseClient.findById(labelid); return result; } 负载均衡因为Feign内集成了rabbion所以引入feign后服务带有负载均衡]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
        <tag>Dubbo</tag>
        <tag>Eureka</tag>
        <tag>Feign</tag>
        <tag>rabbion</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于JWT的微服务鉴权开发实现]]></title>
    <url>%2F2019%2F01%2F26%2F%E5%9F%BA%E4%BA%8EJWT%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%89%B4%E6%9D%83%E5%BC%80%E5%8F%91%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[鉴权微服务开发JWT工具类编写/** * JWT工具类 * @author huangsm */ @ConfigurationProperties(&quot;jwt.config&quot;) public class JwtUtil { private String key ; /** * 一个小时 */ private long ttl ; public String getKey() { return key; } public void setKey(String key) { this.key = key; } public long getTtl() { return ttl; } public void setTtl(long ttl) { this.ttl = ttl; } /** * 生成JWT * * @param id * @param subject * @return */ public String createJWT(String id, String subject, String roles) { long nowMillis = System.currentTimeMillis(); Date now = new Date(nowMillis); JwtBuilder builder = Jwts.builder().setId(id) .setSubject(subject) .setIssuedAt(now) .signWith(SignatureAlgorithm.HS256, key).claim(&quot;roles&quot;, roles); if (ttl &gt; 0) { builder.setExpiration( new Date( nowMillis + ttl)); } return builder.compact(); } /** * 解析JWT * @param jwtStr * @return */ public Claims parseJWT(String jwtStr){ return Jwts.parser() .setSigningKey(key) .parseClaimsJws(jwtStr) .getBody(); } } 管理员登陆后台签发token１． 修改全局配置文件，配置token的盐和过期时间 jwt: config: key: huangsmzhenshuai ttl: 3600000 将Jwt工具类放入Spring容器 @Bean public JwtUtil jwtUtil(){ return new JwtUtil(); } 管理员登录后台token签发 1.控制层代码: @PostMapping(value = &quot;/login&quot;) public Result login(@RequestBody Admin admin) { String token = adminService.login(admin.getLoginname(), admin.getPassword()); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;token&quot;, token); map.put(&quot;roles&quot;, &quot;admin&quot;); map.put(&quot;loginName&quot;, admin.getLoginname()); return new Result(true, StatusCode.OK, &quot;登录成功&quot;, map); } 2.服务层代码: @Autowired private JwtUtil jwtUtil; public String login(String loginName,String password){ Admin sysAdmin = adminDao.findByLoginname(loginName); if (sysAdmin==null){ throw new RuntimeException(&quot;用户名不存在!&quot;); } if (!bCryptPasswordEncoder.matches(password,sysAdmin.getPassword())){ throw new RuntimeException(&quot;密码错误!&quot;); } String token = jwtUtil.createJWT(loginName, password, &quot;admin&quot;); return token; } 管理员删除用户功能鉴权 需求：删除用户，必须拥有管理员权限，否则不能删除 前后端约定：前端请求微服务时需要添加头信息Authorization ,内容为Bearer+空格+token 业务代码: /** * 删除必须有admin才可以删除 * * @param id */ public void deleteById(String id) { String authorization = request.getHeader(&quot;Authorization&quot;); if (StringUtils.isEmpty(authorization)){ throw new RuntimeException(&quot;权限不足!&quot;); } if (!authorization.startsWith(&quot;Bearer&quot;)){ throw new RuntimeException(&quot;权限不足!&quot;); } //得到token String token = authorization.substring(7); try { Claims claims = jwtUtil.parseJWT(token); if (!claims.get(&quot;roles&quot;).equals(&quot;admin&quot;)||claims.get(&quot;roles&quot;)==null){ throw new RuntimeException(&quot;权限不足!&quot;); } }catch (Exception e){ throw new RuntimeException(&quot;权限不足!&quot;); } userDao.deleteById(id); } 上述代码你会发现个问题，每次验证都需要写一大堆业务，代码过于重复，这里使用拦截器来完成鉴权 一、编写拦截器 /** * 授权拦截器 * * @author huangsm */ @Component public class JwtInterceptor implements HandlerInterceptor { /** * Spring为我们提供了org.springframework.web.servlet.handler.HandlerInterceptorAdapter这个适配器， * 继承此类，可以非常方便的实现自己的拦截器。 * 他有三个方法：分别实现预处理、后处理（调用了Service并返回ModelAndView，但未进行页面渲染）、返回处理（已经渲染了页面） * 在preHandle中，可以进行编码、安全控制等处理； * 在postHandle中，有机会修改ModelAndView； * 在afterCompletion中，可以根据ex是否为null判断是否发生了异常，进行日志记 */ @Autowired private JwtUtil jwtUtil; /** * 前置拦截器 * * @param request * @param response * @param handler * @return * @throws Exception */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(&quot;经过了拦截器&quot;); //无论如何都放下。具体能不能操作还是在具体操作中去判断 //拦截器只是负责把请求头中包含token的令牌进行解析验证。 final String authorization = request.getHeader(&quot;Authorization&quot;); //如果包含有Authorization头信息，就对其进行判断 if (authorization != null &amp;&amp; authorization.startsWith(&quot;Bearer&quot;)) { //得到token final String token = authorization.substring(7); try { Claims claims = jwtUtil.parseJWT(token); if (claims != null) { String roles = (String) claims.get(&quot;roles&quot;); //如果是管理员 if (&quot;admin&quot;.equals(roles) &amp;&amp; roles != null) { request.setAttribute(&quot;admin_claims&quot;, claims); } //如果是用户 if (&quot;user&quot;.equals(roles) &amp;&amp; roles != null) { request.setAttribute(&quot;user_claims&quot;, claims); } } } catch (Exception e) { throw new RuntimeException(&quot;令牌有误!&quot;); } } return true; } } 二、将拦截器加入到SpringMvc中 /** * Web配置类 * * @author huangsm */ @Configuration public class WebConfig extends WebMvcConfigurationSupport { @Autowired private JwtInterceptor jwtInterceptor; /** * 添加拦截器 * addPathPatterns拦截的路径 * excludePathPatterns不拦截的路径 * @param registry */ @Override public void addInterceptors(InterceptorRegistry registry) { //注册拦截器要声明拦截器对象和要拦截的请求 registry.addInterceptor(jwtInterceptor) .addPathPatterns(&quot;/**&quot;) .excludePathPatterns(&quot;/**/login&quot;); } } 三、修改原有的删除用户逻辑 /** * 删除必须有admin才可以删除 * * @param id */ public void deleteById(String id) { Claims admin_claims = (Claims) request.getAttribute(&quot;admin_claims&quot;); if (admin_claims == null) { throw new RuntimeException(&quot;权限不足!&quot;); } userDao.deleteById(id); } 这是是一个拦截器的简单使用，其实可以加上角色认证和aop注解栏控制那些请求不需要拦截]]></content>
      <categories>
        <category>JWT</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>jwt</tag>
        <tag>权限拦截器</tag>
        <tag>鉴权微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于JWT的Token认证机制以及实现]]></title>
    <url>%2F2019%2F01%2F26%2F%E5%9F%BA%E4%BA%8EJWT%E7%9A%84Token%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[前提要求考虑到使用SpringSecurity的BCryptPasswordEncoder盐加密算法所以在服务中引入SpringSecurity 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; 我们在添加了spring security依赖后，所有的地址都被spring security所控制了，我们目前只是需要用到BCrypt密码加密的部分，所以我们要添加一个配置类，配置为所有地址都可以匿名访问 /** * 安全配置类 * @author huangsm */ @EnableWebSecurity @Configuration public class WebSecurityConfig extends WebSecurityConfigurerAdapter { /** * authorizeRequests所有security全注解配置实现的开端，表示开始说明需要的权限。 * 需要的权限分两部分，第一部分是拦截的路径，第二部分访问该路径需要的权限。 * antMatchers表示拦截什么路径，permitAll任何权限都可以访问，直接放行所有。 * anyRequest()任何的请求，authenticated认证后才能访问 * and().csrf().disable()；固定写法，标识csrf失效。 * @param http * @throws Exception */ @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(&quot;/**&quot;).permitAll() .anyRequest().authenticated() .and().csrf().disable(); } /** * 配置BCrypt强哈希方法 每次加密的结果都不一样 * @return */ @Bean public BCryptPasswordEncoder bCryptPasswordEncoder(){ return new BCryptPasswordEncoder(); } } 基于JWT的Token认证机制关于有状态登录和无状态的登录 有状态登录: 服务器端需要存储用户信息 无状态登录: 服务器端不需要存储用户信息 常见的认证机制 HTTP Basic Auth（无状态登录） HTTP Basic Auth简单点说明就是每次请求API时都提供用户的username和password，简言之，Basic Auth是配合RESTful API 使用的最简单的认证方式，只需提供用户名密码即可，但由于有把用户名密码暴露给第三方客户端的风险，在生产 环境下被使用的越来越少。因此，在开发对外开放的RESTful API时，尽量避免采用HTTP BasicAuth Cookie Auth Cookie认证机制就是为一次请求认证在服务端创建一个Session对象，同时在客户端的浏览器端创建了一个 Cookie对象；通过客户端带上来Cookie对象来与服务器端的session对象匹配来实现状态管理的。默认的，当我 们关闭浏览器的时候，cookie会被删除。但可以通过修改cookie 的expire time使cookie在一定时间内有效。 OAuth OAuth（开放授权）是一个开放的授权标准，允许用户让第三方应用访问该用户在 某一web服务上存储的私密的资源（如照片，视频，联系人列表），而无需将用户名和 密码提供给第三方应用。 OAuth允许用户提供一个令牌，而不是用户名和密码来访问他们存放在特定服务提供者的数据。每一个令牌授权一 个特定的第三方系统（例如，视频编辑网站)在特定的时段（例如，接下来的2小时内）内访问特定的资源（例如 仅仅是某一相册中的视频）。这样，OAuth让用户可以授权第三方网站访问他们存储在另外服务提供者的某些特定 信息，而非所有 下面是OAuth2.0的流程: 这种基于OAuth的认证机制适用于个人消费者类的互联网产品，如社交类APP等应 用，但是不太适合拥有自有认证权限管理的企业应用。 Token Auth 使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是 这样的： 1.客户端使用用户名跟密码请求登录 2.服务端收到请求，去验证用户名与密码 3.验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端 4.客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里 5.客户端每次向服务端请求资源的时候需要带着服务端签发的 Token 6.服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向 客户端返回请求的数据 Token Auth的优点: Token机制相对于Cookie机制又有什么好处呢？ 支持跨域访问: Cookie是不允许垮域访问的，这一点对Token机制是不存在的，前提是传输的用户认证信息通过HTTP头传输. 无状态(也称：服务端可扩展行):Token机制在服务端不需要存储session信息，因为Token 自身包含了所有登录用户的信息，只需要在客户端的cookie或本地介质存储状态信息. 更适用CDN: 可以通过内容分发网络请求你服务端的所有资料（如：javascript，HTML,图片等），而你的服务端只要提供API即可. 去耦: 不需要绑定到一个特定的身份验证方案。Token可以在任何地方生成，只要在你的API被调用的时候，你可以进行Token生成调用即可.更适用于移动应用: 当你的客户端是一个原生平台（iOS, Android，Windows 8等）时，Cookie是不被支持的（你需要通过Cookie容器进行处理），这时采用Token认证机制就会简单得多。 CSRF:因为不再依赖于Cookie，所以你就不需要考虑对CSRF（跨站请求伪造）的防范。 性能: 一次网络往返时间（通过数据库查询session信息）总比做一次HMACSHA256计算 的Token验证和解析要费时得多. 不需要为登录页面做特殊处理: 如果你使用Protractor 做功能测试的时候，不再需要为登录页面做特殊处理. 基于标准化:你的API可以采用标准化的 JSON Web Token (JWT). 这个标准已经存在多个后端库（.NET, Ruby, Java,Python, PHP）和多家公司的支持（如：Firebase,Google, Microsoft）.基于JWT的Token认证机制实现 什么是JWT? JSON Web Token（JWT）是一个非常轻巧的规范。这个规范允许我们使用JWT在用户和服务器之间传递安全可靠的信息. JWT组成 一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名。 头部（Header） 头部用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法等。这也可以被表示成一个JSON对象。 {&quot;typ&quot;:&quot;JWT&quot;,&quot;alg&quot;:&quot;HS256&quot;} 在头部指明了签名算法是HS256算法。 我们进行BASE64编码http://base64.xpcha.com/，编码后的字符串如下： eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1Ni 小知识：Base64是一种基于64个可打印字符来表示二进制数据的表示方法。由于2的6次方等于64，所以每6个比特为一个单元，对应某个可打印字符。三个字节有24个比特，对应于4个Base64单元，即3个字节需要用4个可打印字符来表示。JDK 中提供了非常方便的 BASE64Encoder 和 BASE64Decoder，用它们可以非常方便的完成基于 BASE64 的编码和解码 载荷（playload） 载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分 （1）标准中注册的声明（建议但不强制使用） iss: jwt签发者 sub: jwt所面向的用户 aud: 接收jwt的一方 exp: jwt的过期时间，这个过期时间必须要大于签发时间 nbf: 定义在什么时间之前，该jwt都是不可用的. iat: jwt的签发时间 jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。 （2）公共的声明 公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息. 但不建议添加敏感信息，因为该部分在客户端可解密. （3）私有的声明 私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64 是对称解密的，意味着该部分信息可以归类为明文信息。 这个指的就是自定义的claim。比如前面那个结构举例中的admin和name都属于自定的 claim。这些claim跟JWT标准规定的claim区别在于：JWT规定的claim，JWT的接收方在 拿到JWT之后，都知道怎么对这些标准的claim进行验证(还不知道是否能够验证)；而 private claims不会验证，除非明确告诉接收方要对这些claim进行验证以及规则才行. 定义一个payload: {&quot;sub&quot;:&quot;1234567890&quot;,&quot;name&quot;:&quot;John Doe&quot;,&quot;admin&quot;:true} 然后将其进行base64编码，得到Jwt的第二部分。 eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9 签证（signature） jwt的第三部分是一个签证信息，这个签证信息由三部分组成 header (base64后的) payload (base64后的) secr 这个部分需要base64加密后的header和base64加密后的payload使用.连接组成的字符串，然后通过header中声明的 加密方式进行加盐secret组合加密，然后就构成了jwt的第三部分。 TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ 将这三部分用.连接成一个完整的字符串,构成了最终的jwt: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ 注意：secret是保存在服务器端的，jwt的签发生成也是在服务器端的，secret就是用来进行jwt的签发和jwt的验证， 所以，它就是你服务端的私钥，在任何场景都不应该流露出去。一旦客户端得知这个secret, 那就意味着客户端是可以自我签发jwt了。 Java的JJWT实现JWT 什么是JJWT？ JJWT是一个提供端到端的JWT创建和验证的Java库。永远免费和开源(Apache License，版本2.0)，JJWT很容易使用和理解。它被设计成一个以建筑为中心的流畅界 面，隐藏了它的大部分复杂性。 token的创建 一、引入依赖 &lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.6.0&lt;/version&gt; &lt;/dependency&gt; 二、创建类JwtTest，用于生成token /** * 测试生产Json Web Token */ public class CreateJwt { public static void main(String[] args) { /** * signWith实现签名算法和盐(huangsm是盐) * setIssuedAt用于设置签发时间 * signWith用于设置签名秘钥 * setExpiration设置过期时间 */ //为了方便测试，我们将过期时间设置为1分钟 long now = System.currentTimeMillis();// 当前时间 long exp = now + 1000 * 60;//过期时间为1分钟 JwtBuilder jwtBuilder = Jwts.builder() .setId(&quot;666&quot;) .setSubject(&quot;你号&quot;) .setIssuedAt(new Date()) .signWith(SignatureAlgorithm.HS256, &quot;huangsm&quot;) .setExpiration(new Date(exp)); System.out.println(jwtBuilder.compact()); } } token的解析 我们刚才已经创建了token ，在web应用中这个操作是由服务端进行然后发给客户 端，客户端在下次向服务端发送请求时需要携带这个token（这就好像是拿着一张门票一 样），那服务端接到这个token 应该解析出token中的信息（例如用户id）,根据这些信息 查询数据库返回相应的结果。 解析类: /** * JWT解析 * * @author huangsm */ public class ParseJwt { public static void main(String[] args) { String token = &quot;eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiI2NjYiLCJzdWIiOiLkvaDlj7ciLCJpYXQiOjE1NDg1MDI5NzZ9.-MhnLDDDmdsT6c8CX1qXA-kM2HneEgdxIrNH5_54Jn8&quot;; Claims claims = Jwts.parser().setSigningKey(&quot;huangsm&quot;) .parseClaimsJws(token).getBody(); System.out.println(&quot;用户ID:&quot;+claims.getId()); System.out.println(&quot;用户名称:&quot;+claims.getSubject()); System.out.println(&quot;登录时间:&quot;+claims.getIssuedAt()); } } 试着将token或签名秘钥篡改一下，会发现运行时就会报错，所以解析token也就是验证token 自定义claims 我们刚才的例子只是存储了id和subject两个信息，如果你想存储更多的信息（例如角色）可以定义自定义claims /** * 测试生产Json Web Token */ public class CreateJwt { public static void main(String[] args) { /** * signWith实现签名算法和盐(huangsm是盐) * setIssuedAt用于设置签发时间 * signWith用于设置签名秘钥 * setExpiration设置过期时间 * claim自定义claim */ //为了方便测试，我们将过期时间设置为1分钟 long now = System.currentTimeMillis();// 当前时间 long exp = now + 1000 * 60;//过期时间为1分钟 JwtBuilder jwtBuilder = Jwts.builder() .setId(&quot;666&quot;) .setSubject(&quot;你号&quot;) .setIssuedAt(new Date()) .signWith(SignatureAlgorithm.HS256, &quot;huangsm&quot;) .setExpiration(new Date(exp)) .claim(&quot;role&quot;,&quot;admin&quot;) .claim(&quot;image&quot;,&quot;login.png&quot;); System.out.println(jwtBuilder.compact()); } }]]></content>
      <categories>
        <category>JWT</category>
      </categories>
      <tags>
        <tag>Json Web Token</tag>
        <tag>token</tag>
        <tag>JJWT</tag>
        <tag>SpringSecurity</tag>
        <tag>认证机制</tag>
        <tag>无状态登录和有状态登录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ在用户微服务开发中的实战]]></title>
    <url>%2F2019%2F01%2F26%2FRabbitMQ%E5%9C%A8%E7%94%A8%E6%88%B7%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%BC%80%E5%8F%91%E4%B8%AD%E7%9A%84%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[环境准备用户微服务开发 发送短信验证码 实现思路： 在用户微服务编写API ,生成手机验证码，存入Redis并发送到RabbitMQ 一、准备工作 （1）因为要用到缓存和消息队列，所以在用户微服务（tensquare_user）引入依赖redis和amqp的起步依赖。 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; （2）修改application.yml ,在spring 节点下添加配置 spring: redis: host: 192.168.25.133 rabbitmq: host: 192.168.25.133 二、代码实现 （1）在UserService中新增方法，用于发送短信验证码 /** * 发送短信验证码 * * @param mobile 手机号 */ public void sendSms(String mobile) { //1.生成6位短信验证码 String code = RandomStringUtils.randomNumeric(6); System.out.println(mobile + &quot;收到验证码是:&quot; + code); //2.将验证码放于redis(5分钟过期) redisTemplate.opsForValue().set(&quot;smsCode_&quot; + mobile, code, 5, TimeUnit.MINUTES); //3.将验证码和手机号发动到RabbitMQ中 Map&lt;String, String&gt; map = new HashMap&lt;&gt;(2); map.put(&quot;mobile&quot;, mobile); map.put(&quot;code&quot;, code); rabbitTemplate.convertAndSend(&quot;sms&quot;, map); } （2）UserController新增方法 @PostMapping(&quot;/sendSms/{mobile}&quot;) public Result sendSms(@PathVariable(&quot;mobile&quot;) String mobile){ userService.sendSms(mobile); return new Result(true,StatusCode.OK,&quot;发送成功&quot;); } （3）启动微服务，在rabbitMQ中创建名为sms的队列，测试API 三、用户注册服务开发 /** * 用户注册 * @param user 用户信息 * @param code 验证码 */ @Transactional(rollbackFor = Exception.class) public void register(User user,String code){ String sysCode = (String) redisTemplate.opsForValue().get(&quot;smsCode_&quot; + user.getMobile()); if (StringUtils.isEmpty(sysCode)){ throw new RuntimeException(&quot;请点击获取验证码!&quot;); } if (StringUtils.isEmpty(code)){ throw new RuntimeException(&quot;请输入您收到的验证码!&quot;); } if (!sysCode.equals(code)){ throw new RuntimeException(&quot;验证码输入有误，请重新输入!&quot;); } user.setId(idWorker.nextId()+&quot;&quot;); //关注数 user.setFollowcount(0); //粉丝总数 user.setFanscount(0); userDao.save(user); } 短信微服务开发开发短信发送微服务，从rabbitMQ中提取消息，调用阿里大于短信接口实现短信发送。（我们这里实际做的就是消息的消费） 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 创建application.yml server: port: 9009 spring: application: name: tensquare-sms rabbitmq: host: 192.168.25.133 创建消息监听器(消息消费者) /** * 发送短信监听类 * @author huangsm * @date 2019/1/26 17:08:36 */ @Component @RabbitListener(queues = &quot;sms&quot;) public class SmsListener { @RabbitHandler public void sendSms(Map&lt;String,String&gt; map){ System.out.println(map); } } 这里RabbitMQ在短信服务中的应用就开发完成了，这里没有真的发送短信，如果发送短信可以调用第三方(如阿里大于等)]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>RabbitMQ</tag>
        <tag>短信服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件RabbitMQ的使用以及基本概念]]></title>
    <url>%2F2019%2F01%2F26%2F%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6RabbitMQ%E7%9A%84%E4%BD%BF%E7%94%A8%E4%BB%A5%E5%8F%8A%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[RabbitMQRabbitMQ简介 消息队列中间件简介 消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题实现高性能，高可用，可伸缩和 最终一致性[架构]使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ 以下介绍消息队列在实际应用中常用的使用场景：异步处理，应用解耦，流量削锋和消息通讯四个场景 速度:kafka、rabbitmq、activemq最安全的是:activemq 什么是RabbitMQ RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。 AMQP ：Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放 标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不 受产品、开发语言等条件的限制。 RabbitMQ 最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展 性、高可用性等方面表现不俗。具体特点包括： 1.可靠性（Reliability） RabbitMQ 使用一些机制来保证可靠性，如持久化、传输确认、发布确认。 2.灵活的路由（Flexible Routing） 在消息进入队列之前，通过 Exchange 来路由消息的。对于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的路由功能，可以将多个 Exchange 绑定在一起，也通过插件机制实现自己的 Exchange 。 3.消息集群（Clustering） 多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker 。 4.高可用（Highly Available Queues） 队列可以在集群中的机器上进行镜像，使得在部分节点出问题的情况下队列仍然可用。 5.多种协议（Multi-protocol） RabbitMQ 支持多种消息队列协议，比如 STOMP、MQTT 等等。 6.多语言客户端（Many Clients） RabbitMQ 几乎支持所有常用语言，比如 Java、.NET、Ruby 等等。 7.管理界面（Management UI） RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息 Broker 的许多方 面。 8.跟踪机制（Tracing） 如果消息异常，RabbitMQ 提供了消息跟踪机制，使用者可以找出发生了什么。 9.插件机制（Plugin System） RabbitMQ 提供了许多插件，来从多方面进行扩展，也可以编写自己的插件 架构图与主要概念 RabbitMQ架构图 主要概念 RabbitMQ Server： 也叫broker server，它是一种传输服务。 他的角色就是维护一条 从Producer到Consumer的路线，保证数据能够按照指定的方式进行传输。 Producer： 消息生产者，如图A、B、C，数据的发送方。消息生产者连接RabbitMQ服 务器然后将消息投递到Exchange。 Consumer：消息消费者，如图1、2、3，数据的接收方。消息消费者订阅队列， RabbitMQ将Queue中的消息发送到消息消费者。 Exchange：生产者将消息发送到Exchange（交换器），由Exchange将消息路由到一个 或多个Queue中（或者丢弃）。Exchange并不存储消息。RabbitMQ中的Exchange有 direct、fanout、topic、headers四种类型，每种类型对应不同的路由规则。 Queue：（队列）是RabbitMQ的内部对象，用于存储消息。消息消费者就是通过订阅 队列来获取消息的，RabbitMQ中的消息都只能存储在Queue中，生产者生产消息并最终 投递到Queue中，消费者可以从Queue中获取消息并消费。多个消费者可以订阅同一个 Queue，这时Queue中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者 都收到所有的消息并处理。 RoutingKey：生产者在将消息发送给Exchange的时候，一般会指定一个routing key， 来指定这个消息的路由规则，而这个routing key需要与Exchange Type及binding key联 合使用才能最终生效。在Exchange Type与binding key固定的情况下（在正常使用时一 般这些内容都是固定配置好的），我们的生产者就可以在发送消息给Exchange时，通过 指定routing key来决定消息流向哪里。RabbitMQ为routing key设定的长度限制为255 bytes Connection： （连接）：Producer和Consumer都是通过TCP连接到RabbitMQ Server 的。以后我们可以看到，程序的起始处就是建立这个TCP连接。 Channels： （信道）：它建立在上述的TCP连接中。数据流动都是在Channel中进行 的。也就是说，一般情况是程序起始建立TCP连接，第二步就是建立这个Channel。 VirtualHost：权限控制的基本单位，一个VirtualHost里面有若干Exchange和 MessageQueue，以及指定被哪些user使用 RabbitMQ的使用 RabbitMQ安装与启动 一、windows环境下的安装 （1）下载并安装 Eralng配套软件中已提供otp_win64_20.2.exe （以管理员身份运行安装） （2）下载并安装rabbitmq配套软件中已提供rabbitmq-server-3.7.4.exe。双击安装，注意不要安装在包含 中文和空格的目录下！安装后window服务中就存在rabbitMQ了，并且是启动状态。 （3）安装管理界面（插件）进入rabbitMQ安装目录的sbin目录，输入命令 rabbitmq‐plugins enable rabbitmq_management （4）重新启动服务 （5）打开浏览器，地址栏输入http://127.0.0.1:15672 ,即可看到管理界面的登陆页 二、docker容器中按照RabbitMQ （1）拉去rabbitMQ镜像 docker pull rabbitmq:management （2）创建容器，rabbitmq需要有映射以下端口: 5671 5672 4369 15671 15672 25672 15672 (if management plugin is enabled) 15671 management监听端口 5672, 5671 (AMQP 0-9-1 without and with TLS) 4369 (epmd) epmd 代表 Erlang 端口映射守护进程 25672 (Erlang distribution) (3)启动容器: docker run -d --name=myrabbitmq -p 5671:5671 -p 5672:5672 -p 4369:4369 -p 15671:15671 -p 15672:15672 -p 25672:25672 d69a5113ceae 输入http://192.168.25.133:15672进入RabbitMQ登录页面 输入用户名和密码，都为guest 进入主界 最上侧的导航以此是：概览、连接、信道、交换器、队列、用户管理 直接模式(Direct) 一、什么是Direct模式 我们需要将消息发给唯一一个节点时使用这种模式，这是最简单的一种形式。 任何发送到Direct Exchange的消息都会被转发到RouteKey中指定的Queue。 1.一般情况可以使用rabbitMQ自带的Exchange：&quot;&quot;(该Exchange的名字为空字符串，下 文称其为default Exchange)。 2.这种模式下不需要将Exchange进行任何绑定(binding)操作 3.消息传递时需要一个“RouteKey”，可以简单的理解为要发送到的队列名字。 4.如果vhost中不存在RouteKey中指定的队列名，则该消息会被抛弃。 二、创建队列 做下面的例子前，我们先建立一个叫myQue的队列 Durability：是否做持久化 Durable（持久） transient（临时） Auto delete : 是否自动删除 三、代码实现-消息生产者 1.引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 2.编写配置文件application.yml spring: rabbitmq: host: 192.168.25.133 3.编写测试类 @Autowired private RabbitTemplate rabbitTemplate; @Test public void contextLoads() { /** * 第一个参数是队列名也就是routingKey */ rabbitTemplate.convertAndSend(&quot;myQue&quot;,&quot;测试下直接模式(Direct)&quot;); } 四、代码实现-消息消费者 （1）编写消息消费者类 @Component @RabbitListener(queues = &quot;myQue&quot;) public class Customer { @RabbitHandler public void showMessage(String msg){ System.out.println(&quot;myQue接收的消息:&quot;+msg); } } (2)运行启动类，可以在控制台看到刚才发送的消息 利用IDEA启用俩个消费者实例，在利用生产者发送消息，多次测试后发现俩个消费者实例收到消息的比例相同为1:1（负载均衡） 分列模式（Fanout） 一、什么是分列（Fanout）模式 当我们需要将消息一次发给多个队列时，需要使用这种模式。 任何发送到Fanout Exchange的消息都会被转发到与该Exchange绑定(Binding)的所有 Queue上。 1.可以理解为路由表的模式 2.这种模式不需要RouteKey 3.这种模式需要提前将Exchange与Queue进行绑定，一个Exchange可以绑定多个 Queue，一个Queue可以同多个Exchange进行绑定。 4.如果接受到消息的Exchange没有与任何Queue绑定，则消息会被抛弃。 创建交换机 绑定QUEUE 二、代码实现---分列模式消息生产者 /** * * 分列模式(Fanout) */ @Test public void sendMsg2() { /** * 第一个参数是交换机名称，第二个队列名称是routingkey */ rabbitTemplate.convertAndSend(&quot;huangsm&quot;,&quot;&quot;,&quot;测试分列模式(Fanout)&quot;); } 三、代码实现-分列模式消息消费者 @Component @RabbitListener(queues = &quot;myQue2&quot;) public class Customer2 { @RabbitHandler public void showMessage(String msg){ System.out.println(&quot;myQue3接收的消息:&quot;+msg); } } 主题模式（Topic） 一、什么是主题模式 任何发送到Topic Exchange的消息都会被转发到所有关心RouteKey中指定话题的Queue上 由上图看出: 此类交换器使得来自不同的源头的消息可以到达一个队列，其实说的更明白一点就是模 糊匹配的意思，例如：上图中红色对列的routekey为usa.#，#代表匹配任意字符，但是 要想消息能到达此对列，usa.必须匹配后面的#好可以随意。图中usa.news usa.weather,都能找到红色队列，符号 # 匹配一个或多个词，符号 * 匹配不多不少一个 词。因此 usa.# 能够匹配到 usa.news.XXX ，但是 usa.* 只会匹配到 usa.XXX 。 注： 交换器说到底是一个名称与队列绑定的列表。当消息发布到交换器时，实际上是由你所 连接的信道，将消息路由键同交换器上绑定的列表进行比较，最后路由消息。 任何发送到Topic Exchange的消息都会被转发到所有关心RouteKey中指定话题的 Queue上 1.这种模式较为复杂，简单来说，就是每个队列都有其关心的主题，所有的消息都带有一 个“标题”(RouteKey)，Exchange会将消息转发到所有关注主题能与RouteKey模糊匹配的 队列。 2.这种模式需要RouteKey，也许要提前绑定Exchange与Queue。 3.在进行绑定时，要提供一个该队列关心的主题，如“#.log.#”表示该队列关心所有涉及 log的消息(一个RouteKey为”MQ.log.error”的消息会被转发到该队列)。 4.“#”表示0个或若干个关键字，“”表示一个关键字。如“log.”能与“log.warn”匹配，无法 与“log.warn.timeout”匹配；但是“log.#”能与上述两者匹配。 5.同样，如果Exchange没有发现能够与RouteKey匹配的Queue，则会抛弃此消息 创建队列与绑定 （1）新建一个交换器 ，类型选择topic （2）点击新建的交换器topichuang,添加匹配规则，添加后列表如下： 消息生产者代码已经消费者测试结果 /** * 测试主题模式(topic) */ @Test public void sendMsg3() { /** * 第一个参数是交换机名称，第二个队列名称是routingKey */ rabbitTemplate.convertAndSend(&quot;topichuang&quot;,&quot;huang.aaa&quot;,&quot;aaa消息发送给谁呢&quot;); } /** * 测试主题模式(topic) */ @Test public void sendMsg4() { /** * 第一个参数是交换机名称，第二个队列名称是routingKey */ rabbitTemplate.convertAndSend(&quot;topichuang&quot;,&quot;huang.log&quot;,&quot;huang.log消息发送给谁呢&quot;); } /** * 测试主题模式(topic) */ @Test public void sendMsg5() { /** * 第一个参数是交换机名称，第二个队列名称是routingKey */ rabbitTemplate.convertAndSend(&quot;topichuang&quot;,&quot;log.ccc&quot;,&quot;ccc消息发送给谁呢&quot;); } Topic模式测试结果 Topic模式流程图 结束语这篇博客主要讲述RabbitMQ的一些概念和一些操作方式，下篇博客会介绍RabbitMQ的实战，开发一个用户微服务]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
        <tag>主题模式Topic</tag>
        <tag>直接模式Direct</tag>
        <tag>分列模式（Fanout)</tag>
        <tag>AMQP</tag>
        <tag>Erlang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker下部署elasticsearch环境]]></title>
    <url>%2F2019%2F01%2F25%2Fdocker%E4%B8%8B%E9%83%A8%E7%BD%B2elasticsearch%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[环境准备 阿里云服务器 docker最新版环境 部署步骤容器的创建与远程连接 下载镜像 docker pull elasticsearch:5.6.8 创建容器 docker run -d --name es -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; 6c0bdf761f3b 如果启动报错，通过docker logs es查看日志，如果错误是 Java HotSpot(TM) 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000085330000, 2060255232, 0) failed; error=’Cannot allocate memory’ (errno=12) 因为这是由于elasticsearch5.0默认分配jvm空间大小为2g，内存不足以分配导致修改elasticsearch分配的jvm空间 find /var/lib/docker/overlay2/ -name jvm.options vim /var/lib/docker/overlay2/7f59cf980d035aa1f8e5275e4e64eb9ec9a775b0d62bacf94ee3d562b782c136/diff/etc/elasticsearch/jvm.options 最后重新启动即可 测试 输入http://192.168.25.133:9200/ 使用写好的搜索服务，改变elasticsearch服务器地址后启动测试报错: 进入容器 一、输入命令 docker exec es -it /bin/bash 此时，我们看到elasticsearch所在的目录为/usr/share/elasticsearch, 进入config看到了配置文件elasticsearch.yml 我们通过vi命令编辑此文件，尴尬的是容器并没有vi命令 ，咋办？我们需要以文件挂载的 方式创建容器才行，这样我们就可以通过修改宿主机中的某个文件来实现对容器内配置文件的修改 二、拷贝配置文件到宿主机 首先退出容器，然后执行命令： docker cp es:/usr/share/elasticsearch/config/elasticsearch.yml /usr/share/elasticsearch.yml 三、停止和删除原来创建的容器 docker stop es docker rm es 四、重新执行创建容器命令 docker run -d --name=es -p 9200:9200 -p 9300:9300 -v /usr/share/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml elasticsearch:5.6.8 五、修改/usr/share/elasticsearch.yml 将 transport.host: 0.0.0.0 前的#去掉后保存文件退出。 其作用是允许任何ip地址访问elasticsearch开发测试阶段可以这么做，生产环境下指定具体的IP 重启启动 docker restart es重新启动失败怎么办? 重启后发现重启启动失败了，这时什么原因呢？这与我们刚才修改的配置有关，因为elasticsearch在启动的时候会进行一些检查， 比如最多打开的文件的个数以及虚拟内存区域数量等等，如果你放开了此配置，意味着需要打开更多的文件以及虚拟内存， 所以我们还需要系统调优。 系统调优(宿主机问题) 我们一共需要修改两处 第一步:修改/etc/security/limits.conf 配置文件,追加 * soft nofile 65536 * hard nofile 655 nofile是单个进程允许打开的最大文件个数 soft nofile 是软限制 hard nofile是硬限制 第二步:修改/etc/sysctl.conf，追加内容 vm.max_map_count=655360 限制一个进程可以拥有的VMA(虚拟内存区域)的数量 执行下面命令 修改内核参数马上生效 安装IK分词器 （1）快捷键alt+p进入sftp , 将ik文件夹上传至宿主机 put -r D:\friendprojec\elasticsearch-5.6.8\plugins\ik （2）在宿主机中将ik文件夹拷贝到容器内 /usr/share/elasticsearch/plugins 目录下。 docker cp ik es:/usr/share/elasticsearch/plugins/ （3）重启容器 HEAD插件安装 （1）修改/usr/share/elasticsearch.yml ,添加允许跨域配置 http.cors.enabled: true http.cors.allow‐origin: &quot;*&quot; （2）重新启动elasticseach容器（3）下载head镜像 docker pull mobz/elasticsearch‐head:5 （4）创建head容器 docker run ‐di ‐‐name=myhead ‐p 9100:9100 mobz/elasticsearch‐head:5 这样我们在docker中部署elasticsearch就完成了]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>head</tag>
        <tag>elasticsearch</tag>
        <tag>docker</tag>
        <tag>IK</tag>
        <tag>docker系统优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Logstash同步ElasticSearch与Mysql数据]]></title>
    <url>%2F2019%2F01%2F24%2F%E4%BD%BF%E7%94%A8Logstash%E5%90%8C%E6%AD%A5ElasticSearch%E4%B8%8EMysql%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[ElasticSearch与MYSQL数据库的同步(使用logstash) 概述 Logstash是一款轻量级的日志搜集处理框架，可以方便的把分散的、多样化的日志搜集起来，并进行自定义的理，然后传输 到指定的位置，比如某个服务器或者文件。 Logstash的安装和测试 解压，进入bin目录 logstash ‐e &apos;input { stdin { } } output { stdout {} }&apos; 控制台输入字符，随后就有日志输出 stdin，表示输入流，指从键盘输入 stdout，表示输出流，指从显示器输出 命令行参数: -e 执行 --config 或 -f 配置文件，后跟参数类型可以是一个字符串的配置或全路径文件名或全路径 (如：/etc/logstash.d/，logstash会自动读取/etc/logstash.d/目录下所有*.conf 的文本文件， 然后在自己内存里拼接成一个完整的大配置文件再去执行) MySQL数据导入Elasticsearch 第一步: 在logstansh根目录下创建mysqletc(名称任意)目录，目录中创建mysql.conf（名字任意）文件，已经mysql的驱动jar包 第二步: 编写mysql.conf文件 input { jdbc { # mysql jdbc connection string to our backup databse jdbc_connection_string =&gt; &quot;jdbc:mysql://47.107.44.169:33061/tensquare_article?characterEncoding=UTF8&quot; # the user we wish to excute our statement as jdbc_user =&gt; &quot;root&quot; jdbc_password =&gt; &quot;123456&quot; # the path to our downloaded jdbc driver jdbc_driver_library =&gt; &quot;D:\friendprojec\logstash-5.6.8\mysqletc\mysql-connector-java-5.1.46.jar&quot; # the name of the driver class for mysql jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot; jdbc_paging_enabled =&gt; &quot;true&quot; jdbc_page_size =&gt; &quot;50&quot; #以下对应着要执行的sql的绝对路径。 #statement_filepath =&gt; &quot;&quot; statement =&gt; &quot;SELECT id,title,content,state FROM tb_article&quot; #定时字段 各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新（测试结果，不同的话请留言指出） schedule =&gt; &quot;* * * * *&quot; } } output { elasticsearch { #ESIP地址与端口 hosts =&gt; &quot;127.0.0.1:9200&quot; #ES索引名称（自己定义的） index =&gt; &quot;tensquare_article&quot; #自增ID编号 document_id =&gt; &quot;%{id}&quot; document_type =&gt; &quot;article&quot; } stdout { #以JSON格式输出 codec =&gt; json_lines } } 第三步: 启动logstansh，用-f的方式 logstash -f ../mysqletc/mysql.conf 注意mysql.conf路径为相对路径 logstansh一些注意的问题 logstansh支持多数据库同步ElasticSearch 这就是logstansh同步数据库的基础使用，也可以部署logstansh集群配合kafka或redis做到缓存同步效果]]></content>
      <categories>
        <category>Logstash</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>Logstash</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch基础入门及搜索服务的开发]]></title>
    <url>%2F2019%2F01%2F23%2FElasticSearch%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E5%8F%8A%E6%90%9C%E7%B4%A2%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[概述什么是ElasticSearchElasticsearch是一个实时的分布式搜索和分析引擎。它可以帮助你用前所未有的速度去处理大规模数据。 ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引 擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 ElasticSearch特点（1）可以作为一个大型分布式集群（数百台服务器）技术，处理PB级数据，服务大公司；也可以运行在单机上 （2）将全文检索、数据分析以及分布式技术，合并在了一起，才形成了独一无二的ES； （3）开箱即用的，部署简单 （4）全文检索，同义词处理，相关度排名，复杂数据分析，海量数据的近实时 ElasticSearch体系结构 环境准备ElasticSearch部署与启动 下载ElasticSearch 5.6.8版本 https://www.elastic.co/downloads/past-releases/elasticsearch-5-6-8 在命令提示符下，进入ElasticSearch安装目录下的bin目录,执行命令即可启动。 我们打开浏览器，在地址栏输入http://127.0.0.1:9200/ 即可看到输出结果 不同操作方式使用ElasticSearch通过PostMan使用RestFul风格操作ElasticSearch 新建索引库 新建文档 查询全部文档 修改文档如果ID不存在则重新创建 按ID查询文档 基本匹配查询 模糊查询 删除文档Head插件方式操控ElasticSearch安装head 下载head插件 https://github.com/mobz/elasticsearch-head 解压到任意目录，但是要和elasticsearch的安装目录区别开 按照node js，按照cnpm npm install -g cnpm --registry=https://registry.npm.taobao.org 将grunt安装为全局命令 。Grunt是基于Node.js的项目构建工具。它可以自动运行你所设定的任务 npm install ‐g grunt‐cli 安装依赖 cnpm install 进入head目录启动head，在命令提示符下输入命令 grunt server 打开浏览器，输入 http://localhost:9100 点击连接按钮没有任何相应，按F12发现有如下错误 No &apos;Access-Control-Allow-Origin&apos; header is present on the requested resour 这个错误是由于elasticsearch默认不允许跨域调用，而elasticsearch-head是属于前端工程，所以报错。 我们这时需要修改elasticsearch的配置，让其允许跨域访问。 修改elasticsearch配置文件：elasticsearch.yml，增加以下两句命令： http.cors.enabled: true http.cors.allow‐origin: &quot;*&quot; 此步为允许elasticsearch跨越访问 点击连接即可看到相关信息 IK分词器的使用 安装IK分词器下载地址：https://github.com/medcl/elasticsearch-analysis-ik/releases 下载5.6.8版本 （1）先将其解压，将解压后的elasticsearch文件夹重命名文件夹为ik （2）将ik文件夹拷贝到elasticsearch/plugins 目录下。 （3）重新启动，即可加载IK分词器 IK分词器测试IK提供了两个分词算法ik_smart 和 ik_max_word其中ik_smart为最少切分，ik_max_word为最细粒度划分我们分别来试一下 （1）最小切分：在浏览器地址栏输入地址 http://127.0.0.1:9200/_analyze?analyzer=ik_smart&amp;pretty=true&amp;text=我是中国程序员 输出的结果为： （2）最细切分：在浏览器地址栏输入地址 http://127.0.0.1:9200/_analyze?analyzer=ik_max_word&amp;pretty=true&amp;text=我是中国程序员 输出结果为: IK自定义词库步骤： （1）进入elasticsearch/plugins/ik/config目录 （2）新建一个my.dic文件，编辑内容 （3）修改IKAnalyzer.cfg.xml（在ik/config目录下）,然后重启elasticsearch服务 注意my.dic文件需要存储为UTF-8无BOM格式 JAVA操作ElasticSearch 关于索引库文档类概念 是否索引，就是看该域是否能被搜索 是否分词，就表示搜索的时候是整体匹配还是单词匹配，如果不分词的话代表整句匹配 是否存储，就是是否在页面上显示 引入依赖和修改配置文件 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; 修改配置文件: spring: data: elasticsearch: cluster-nodes: localhost:9300 创建索引文档类 /** * SpringDataElasticSearch索引库文档类 * indexName 索引库名称 * type 数据库类型 * @author huangsm */ @Document(indexName = &quot;tensquare_article&quot;,type = &quot;article&quot;) @Data public class Article implements Serializable { @Id private String id; /** * index 是否索引，就是看该域是否能被搜索 * 是否分词，就表示搜索的时候是整体匹配还是单词匹配，如果不分词的话代表整句匹配 * 是否存储，就是是否在页面上显示 */ @Field(index = true, analyzer = &quot;ik_smart&quot;,searchAnalyzer = &quot;ik_smart&quot;) private String title; @Field(index = true, analyzer = &quot;ik_smart&quot;,searchAnalyzer = &quot;ik_smart&quot;) private String content; /** * 审核状态 */ private String state; } 编写文章持久层 public interface ArticleSearchDao extends ElasticsearchRepository&lt;Article,String&gt; { /** * 检索 * @param title * @param content * @param pageable * @return */ public Page&lt;Article&gt;findByTitleOrContentLike(String title, String content, Pageable pageable); } 编写业务层 /** * 文章搜索业务 * @author huangsm */ @Service public class ArticleSearchService { @Autowired private ArticleSearchDao articleSearchDao; @Autowired private IdWorker idWorker; /** * 增加文章 * @param article */ public void add(Article article){ article.setId(idWorker.nextId()+&quot;&quot;); articleSearchDao.save(article); } public Page&lt;Article&gt;findByTitleLike(String keywords,int page,int size){ PageRequest pageRequest = PageRequest.of(page - 1, size); return articleSearchDao.findByTitleOrContentLike(keywords,keywords,pageRequest); } } 编写控制层 /** * 搜索controller * * @author huangsm */ @RestController @CrossOrigin @RequestMapping(&quot;/article&quot;) public class ArticleController { @Autowired private ArticleSearchService articleSearchService; @PostMapping(&quot;/&quot;) public Result save(@RequestBody Article article) { articleSearchService.add(article); return new Result(true, StatusCode.OK, &quot;操作成功&quot;); } @GetMapping(value = &quot;/search/{keywords}/{page}/{size}&quot;) public Result findByTitleLike(@PathVariable(&quot;keywords&quot;) String keywords, @PathVariable(&quot;page&quot;) int page, @PathVariable(&quot;size&quot;) int size) { Page&lt;Article&gt; pageData = articleSearchService.findByTitleLike(keywords, page, size); return new Result(true, StatusCode.OK, &quot;查询成功&quot;, new PageResult&lt;Article&gt;(pageData.getTotalElements(), pageData.getContent())); } } 测试 ElasticSearch和Solr的对比ES和Solr的对比]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>head</tag>
        <tag>SpringData</tag>
        <tag>IK分词器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringDataMongoDB的基本使用及服务开发]]></title>
    <url>%2F2019%2F01%2F23%2FSpringDataMongoDB%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E5%8F%8A%E6%9C%8D%E5%8A%A1%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[SpringDataMongoDb概述 SpringData家族成员之一，用于操作MongoDb的持久层框架，封装了底层的mongodb-driver 快速入门 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; 配置application.yml配置文件 spring: data: mongodb: host: ip地址 database: 数据库名称 通过IOC注入SpringDataMongoDB封装的模版 在业务层注入： @Autowired private MongoTemplate mongoTemplate; //根据id，修改huangsm表下的num字段，每次加1，代码如下 Query query = new Query(); query.addCriteria(Criteria.where(&quot;_id&quot;).is(id)); Update update = new Update(); update.inc(&quot;num&quot;, 1); mongoTemplate.updateFirst(query, update, &quot;huangsm&quot;); 关于服务开发首先引入依赖，配置配置文件，然后引入MongoDB模版，剩余操作参考根据业务来选择SpringDataMongoDB提供的API来完成业务。本文只是一个简单的入门，更为详细建议参考官方文档，其实笔者认为MongoDB主要使用与数据价值低而且数据量大的场景，掌握常用的CURD就可以玩转Java中MongoDB的使用了，SpringDataMongoDb是个不错的操作MongoDb的框架，推荐。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>SpringData</tag>
        <tag>MongoDB</tag>
        <tag>NOSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简述HTTP和RPC的优缺点]]></title>
    <url>%2F2019%2F01%2F20%2F%E7%AE%80%E8%BF%B0HTTP%E5%92%8CRPC%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%2F</url>
    <content type="text"><![CDATA[在HTTP和RPC的选择上，可能有些人是迷惑的，主要是因为，有些RPC框架配置复杂，如果走HTTP也能完成同样的功能，那么为什么要选择RPC，而不是更容易上手的HTTP来实现了。 本文主要来阐述HTTP和RPC的异同，让大家更容易根据自己的实际情况选择更适合的方案。 传输协议 RPC，可以基于TCP协议，也可以基于HTTP协议 HTTP，基于HTTP协议 传输效率 RPC，使用自定义的TCP协议，可以让请求报文体积更小，或者使用HTTP2协议，也可以很好的减少报文的体积，提高传输效率 HTTP，如果是基于HTTP1.1的协议，请求中会包含很多无用的内容，如果是基于HTTP2.0，那么简单的封装以下是可以作为一个RPC来使用的，这时标准RPC框架更多的是服务治理 性能消耗，主要在于序列化和反序列化的耗时 RPC，可以基于thrift实现高效的二进制传输 HTTP，大部分是通过json来实现的，字节大小和序列化耗时都比thrift要更消耗性能 负载均衡 RPC，基本都自带了负载均衡策略 HTTP，需要配置Nginx，HAProxy来实现 服务治理（下游服务新增，重启，下线时如何不影响上游调用者） RPC，能做到自动通知，不影响上游 HTTP，需要事先通知，修改Nginx/HAProxy配置 总结： RPC主要用于公司内部的服务调用，性能消耗低，传输效率高，服务治理方便。HTTP主要用于对外的异构环境，浏览器接口调用，APP接口调用，第三方接口调用等。 博客地址: https://www.babywang.huangsm.xyz Git地址: https://github.com/babybabywang 码云地址: https://gitee.com/wangyuanbaby]]></content>
      <categories>
        <category>服务发现</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Dubbo</tag>
        <tag>HTTP</tag>
        <tag>RPC</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB的基本使用姿势及概念]]></title>
    <url>%2F2019%2F01%2F20%2FMongoDB%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E5%A7%BF%E5%8A%BF%E5%8F%8A%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[文档型数据库MongoDBMongoDB的特点和体系结构MongoDB简介1. 什么是mongodb mongodb 是一个跨平台的,面向文档的数据库,是当前 nosql 数据库产品中最热门的一种。它介于关系数据库和非关系数据库之间， 是非关系数据库当中功能最丰富,最像关系数据库的产品。它支持的数据结构非常松散，是类似 json的 bson 格式，因此可以存储比较复杂 的数据类型。 mongodb 的官方网站地址是:http://www.mongodb.org 2. mongodb特点 mongodb 最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系 数据库单表查询的绝大部分功能，而且还支持对数据建立索引。它是一个面向集合的,模式自由的文档型数据库。 具体特点总结如下: （1）面向集合存储,易于存储对象类型的数据 （2）模式自由 （3）支持动态查询 （4）支持完全索引,包含内部对象 （5）支持复制和故障恢复 （6）使用高效的二进制数据存储，包括大型对象（如视频等） （7）自动处理碎片,以支持云计算层次的扩展性 （8）支持python,php,ruby,java,c,c#,javascript，perl及c++语言的驱动程 序,社区中也提供了对erlang及.net等平台的驱动程序 （9） 文件存储格式为 bson（一种 json 的扩展） 3. 什么时候使用mongodb （1）数据量大 （2）写入操作频繁 （3）价值较低 对于这样的数据，我们更适合使用mongodb来实现数据的 4. mongodb体系结构 mongodb 的逻辑结构是一种层次结构。主要由： 文档(document)、集合(collection)、数据库(database)这三部分组成的。逻辑结构是面 向用户的，用户使用 mongodb 开发应用程序使用的就是逻辑结构。 （1）mongodb 的文档（document），相当于关系数据库中的一行记录。 （2）多个文档组成一个集合（collection），相当于关系数据库的表。 （3）多个集合（collection），逻辑上组织在一起，就是数据库（database）。 （4）一个 mongodb 实例支持多个数据库（database）。 5. 数据类型 基本数据类型 null：用于表示空值或者不存在的字段，{“x”:null} 布尔型：布尔类型有两个值true和false，{“x”:true} 数值：shell默认使用64为浮点型数值。{“x”：3.14}或{“x”：3}。对于整型值，可以使用numberint（4字节符号整数）或numberlong（8字节符号整数），{“x”:numberint(“3”)}{“x”:numberlong(“3”)} 字符串：utf-8字符串都可以表示为字符串类型的数据，{“x”：“呵呵”} 日期：日期被存储为自新纪元依赖经过的毫秒数，不存储时区，{“x”:new date()} 正则表达式：查询时，使用正则表达式作为限定条件，语法与javascript的正则表达式相同，{“x”:/[abc]/} 数组：数据列表或数据集可以表示为数组，{“x”： [“a“，“b”,”c”]} 内嵌文档：文档可以嵌套其他文档，被嵌套的文档作为值来处理，{“x”:{“y”:3 }} 对象id：对象id是一个12字节的字符串，是文档的唯一标识，{“x”: objectid() } 二进制数据：二进制数据是一个任意字节的字符串。它不能直接在shell中使用。如果要将非utf-字符保存到数据库中，二进制数据是唯一的方式。 代码：查询和文档中可以包括任何javascript代码 Mysql和MongoDB的区别: 常用的MongoDB命令 首先说下Windows端mongodb的启动 md e:/data mongod –dbpath=e:/data 在b端cmd中输入 mongo即可启动 docker中安装mongoDB 拉取镜像docker pull mongo 启动容器docker run -d –name mymongodb -p 27017:27017 mongo 常用的MongoDB命令 使用JAVA操作MongoDBmongodb-driver是mongo官方推出的java连接mongoDB的驱动包，相当于JDBC驱动。我们通过一个入门的案例来了解mongodb-driver的基本 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.mongodb&lt;/groupId&gt; &lt;artifactId&gt;mongodb‐driver&lt;artifactId&gt; &lt;version&gt;3.6.3&lt;/version&gt; &lt;/dependency&gt; 测试 1. 查询全部数据 /** * 测试Java操作mongoDb * @author huangsm */ public class MongoDbDemo { /** * 查询mongodb中全部数据 * @param args */ public static void main(String[] args) { //创建连接 MongoClient mongoClient = new MongoClient(&quot;47.107.44.169&quot;); //打开数据库 MongoDatabase spitdb = mongoClient.getDatabase(&quot;spitdb&quot;); //获取集合 MongoCollection&lt;Document&gt; spit = spitdb.getCollection(&quot;spit&quot;); //查询记录获取文档集合 FindIterable&lt;Document&gt; documents = spit.find(); for (Document document : documents) { System.out.println(&quot;内容:&quot;+document.getString(&quot;content&quot;)); System.out.println(&quot;访客:&quot;+document.getInteger(&quot;visits&quot;)); } mongoClient.close(); } } 2. 条件查询 /** * 测试条件查询 * @author huangsm */ public class MongoDbDemo1 { /** * 根据条件查询 * BasicDBObject对象：表示一个具体的记录，BasicDBObject实现了DBObject，是keyvalue的数据结构，用起来和HashMap是基本一致的。 * @param args */ public static void main(String[] args) { //创建连接 MongoClient mongoClient = new MongoClient(&quot;47.107.44.169&quot;); //打开数据库 MongoDatabase spitdb = mongoClient.getDatabase(&quot;spitdb&quot;); //获取集合 MongoCollection&lt;Document&gt; spit = spitdb.getCollection(&quot;spit&quot;); BasicDBObject basicDBObject=new BasicDBObject(&quot;_id&quot;,&quot;ObjectId(\&quot;5c446ba292035401c76895f0\&quot;)&quot;); //查询记录获取文档集合 FindIterable&lt;Document&gt; documents = spit.find(); for (Document document : documents) { System.out.println(&quot;id:&quot;+document.getObjectId(&quot;_id&quot;)); System.out.println(&quot;内容:&quot;+document.getString(&quot;content&quot;)); System.out.println(&quot;访客:&quot;+document.getInteger(&quot;visits&quot;)); } mongoClient.close(); } } 3. 插入数据 /** * 插入数据 * @author huangsm */ public class MongoDbDemo2 { /** * 插入数据 * @param args */ public static void main(String[] args) { //创建连接 MongoClient mongoClient = new MongoClient(&quot;47.107.44.169&quot;); //打开数据库 MongoDatabase spitdb = mongoClient.getDatabase(&quot;spitdb&quot;); //获取集合 MongoCollection&lt;Document&gt; spit = spitdb.getCollection(&quot;spit&quot;); HashMap&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); map.put(&quot;content&quot;,&quot;git&quot;); map.put(&quot;userId&quot;,&quot;222&quot;); map.put(&quot;visits&quot;,123); Document document = new Document(map); spit.insertOne(document); mongoClient.close(); } } 总结 总的来说MongoDB是一款非关系性的文档数据库，它适合存储那种存储价值低而且数据量大的数据。总的来说操作起来也是否的便捷，下篇文章我会使用SpringDataMongoDB来开发一个微服务。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>JAVA操作</tag>
        <tag>NOSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于吞吐量(TPS)、QPS、并发数、响应时间(RT)的概念]]></title>
    <url>%2F2019%2F01%2F19%2F%E5%85%B3%E4%BA%8E%E5%90%9E%E5%90%90%E9%87%8F-TPS-%E3%80%81QPS%E3%80%81%E5%B9%B6%E5%8F%91%E6%95%B0%E3%80%81%E5%93%8D%E5%BA%94%E6%97%B6%E9%97%B4-RT-%E7%9A%84%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[概述因为开发的原因，需要对吞吐量（TPS）、QPS、并发数、响应时间（RT）几个概念做下了解，查自百度百科，记录如下： 1.响应时间(RT) 响应时间是指系统对请求作出响应的时间。直观上看，这个指标与人对软件性能的主观感受是非常一致的，因为它完整地记录了整个计算机系统处理请求的时间。由于一个系统通常会提供许多功能，而不同功能的处理逻辑也千差万别，因而不同功能的响应时间也不尽相同，甚至同一功能在不同输入数据的情况下响应时间&gt;也不相同。所以，在讨论一个系统的响应时间时，人们通常是指该系统所有功能的平均时间或者所有功能的最大响应时间。当然，往往也需要对每个或每组功能讨论&gt;其平均响应时间和最大响应时间。 对于单机的没有并发操作的应用系统而言，人们普遍认为响应时间是一个合理且准确的性能指标。需要指出的是，响应时间的绝对值并不能直接反映软 件的性能的高低，软件性能的高低实际上取决于用户对该响应时间的接受程度。对于一个游戏软件来说，响应时间小于100毫秒应该是不错的，响应时 间在1秒左右可能属于勉强可以接受，如果响应时间达到3秒就完全难以接受了。而对于编译系统来说，完整编译一个较大规模软件的源代码可能需要几 十分钟甚至更长时间，但这些响应时间对于用户来说都是可以接受的。 2.吞吐量(TPS) 吞吐量是指系统在单位时间内处理请求的数量。对于无并发的应用系统而言，吞吐量与响应时间成严格的反比关系，实际上此时吞吐量就是响应时间的倒数。前面已经说过，对于单用户的系统，响应时间（或者系统响应时间和应用延迟时间）可以很好地度量系统的性能，但对于并发系统，通常需要用吞吐量作为性能指标。 &nbsp;&nbsp;&nbsp;&nbsp;对于一个多用户的系统，如果只有一个用户使用时系统的平均响应时间是t，当有你n个用户使用时，每个用户看到的响应时间通常并不是n×t，而往往比n×t小很多（当然，在某些特殊情况下也可能比n×t大，甚至大很多）。这是因为处理每个请求需要用到很多资源，由于每个请求的处理过程中有许多不走难以并发执行，这导致在具体的一个时间点，所占资源往往并不多。也就是说在处理单个请求时，在每个时间点都可能有许多资源被闲置，当处理多个请求时，如果资源配置合理，每个用户看到的平均响应时间并不随用户数的增加而线性增加。实际上，不同系统的平均响应时间随用户数增加而增长的速度也不大相同，这也是采用吞吐量来度量并发系统的性能的主要原因。一般而言，吞吐量是一个比较通用的指标，两个具有不同用户数和用户使用模式的系统，如果其最大吞吐量基本一致，则可以判断两个系统的处理能力基本一致。 3.并发数 并发用户数是指系统可以同时承载的正常使用系统功能的用户的数量。与吞吐量相比，并发用户数是一个更直观但也更笼统的性能指标。实际上，并发用户数是一个非常不准确的指标，因为用户不同的使用模式会导致不同用户在单位时间发出不同数量的请求。一网站系统为例，假设用户只有注册后才能使用，但注册用户并不是每时每刻都在使用该网站，因此具体一个时刻只有部分注册用户同时在线，在线用户就在浏览网站时会花很多时间阅读网站上的信息，因而具体一个时刻只有部分在线用户同时向系统发出请求。这样，对于网站系统我们会有三个关于用户数的统计数字：注册用户数、在线用户数和同时发请求用户数。由于注册用户可能长时间不登陆网站，使用注册用户数作为性能指标会造成很大的误差。而在线用户数和同事发请求用户数都可以作为性能指标。相比而言，以在线用户作为性能指标更直观些，而以同时发请求用户数作为性能指标更准确些。 4.QPS每秒查询率(Query Per Second) &gt;每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。对应fetches/sec，即每秒的响应请求数，也即是最大吞吐能力。 （看来是类似于TPS，只是应用于特定场景的吞吐量）]]></content>
      <categories>
        <category>系统概念</category>
      </categories>
      <tags>
        <tag>系统概述</tag>
        <tag>概念分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RateLimiter配合注解的使用]]></title>
    <url>%2F2019%2F01%2F19%2FRateLimiter%E9%85%8D%E5%90%88%E6%B3%A8%E8%A7%A3%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[首先我们来了解下什么是RateLimiter RateLimiter 从概念上来讲，速率限制器会在可配置的速率下分配许可证。如果必要的话，每个acquire() 会阻塞当前线程直到许可证可用后获取该许可证。一旦获取到许可证，不需要再释放许可证。校对注：RateLimiter使用的是一种叫令牌桶的流控算法，RateLimiter会按照一定的频率往桶里扔令牌，线程拿到令牌才能执行，比如你希望自己的应用程序QPS不要超过1000，那么RateLimiter设置1000的速率后，就会每秒往桶里扔1000个令牌。 RateLimiter经常用于限制对一些物理资源或者逻辑资源的访问速率。与Semaphore 相比，Semaphore 限制了并发访问的数量而不是使用速率。（注意尽管并发性和速率是紧密相关的，比如参考Little定律） 通过设置许可证的速率来定义RateLimiter。在默认配置下，许可证会在固定的速率下被分配，速率单位是每秒多少个许可证。为了确保维护配置的速率，许可会被平稳地分配，许可之间的延迟会做调整。可能存在配置一个拥有预热期的RateLimiter 的情况，在这段时间内，每秒分配的许可数会稳定地增长直到达到稳定的速率。举例来说明如何使用RateLimiter，想象下我们需要处理一个任务列表，但我们不希望每秒的任务提交超过两个： //速率是每秒两个许可 final RateLimiter rateLimiter = RateLimiter.create(2.0); void submitTasks(List tasks, Executor executor) { for (Runnable task : tasks) { rateLimiter.acquire(); // 也许需要等待 executor.execute(task); } } 进入正题准备工作 引入依赖 &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;25.1-jre&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.28&lt;/version&gt; &lt;/dependency&gt; 创建自定义注解 import java.lang.annotation.*; /** * 自定义RateLimiter限流注解 * @author huang * @PACKAGE_NAME cn.huangsm.advance.ratelimiter * @PROJECT_NAME advance-code * @date 2019/1/19 */ @Inherited @Documented @Target({ElementType.METHOD,ElementType.FIELD,ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) public @interface RateLimitAspect { } 自定义切面类解析自定义注解 import com.alibaba.fastjson.JSON; import com.google.common.util.concurrent.RateLimiter; import lombok.extern.slf4j.Slf4j; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Scope; import org.springframework.stereotype.Component; import javax.servlet.ServletOutputStream; import javax.servlet.http.HttpServletResponse; import java.io.IOException; /** * 自定义切面类解析注解 * * @author huang * @PACKAGE_NAME cn.huangsm.advance.ratelimiter.aop * @PROJECT_NAME advance-code * @date 2019/1/19 */ @Component @Aspect @Scope @Slf4j public class RateLimitAop { @Autowired private HttpServletResponse response; /** * 需要处理一个任务列表，但我们不希望每秒的任务提交超过五个 */ private RateLimiter rateLimiter = RateLimiter.create(5.0); @Pointcut(&quot;@annotation(cn.huangsm.advance.ratelimiter.RateLimitAspect)&quot;) public void rateLimiterPointCut() { } ; @Around(&quot;rateLimiterPointCut()&quot;) public Object around(ProceedingJoinPoint joinPoint) { /** * 得到令牌 */ Boolean flag = rateLimiter.tryAcquire(); Object obj = null; try { if (flag) { obj = joinPoint.proceed(); log.info(&quot;得到令牌!&quot;); } else { String result = JSON.toJSONString(&quot;抱歉，操作过于频繁，请稍等片刻在操作！&quot;); log.info(&quot;未获得令牌!&quot;); output(response, result); } } catch (Throwable e) { e.printStackTrace(); } System.out.println(&quot;是否得到令牌=&quot; + flag + &quot;,参数=&quot; + obj); return obj; } public void output(HttpServletResponse response, String msg) throws IOException { response.setContentType(&quot;application/json;charset=UTF-8&quot;); ServletOutputStream outputStream = null; try { outputStream = response.getOutputStream(); outputStream.write(msg.getBytes(&quot;UTF-8&quot;)); } catch (IOException e) { e.printStackTrace(); } finally { outputStream.flush(); outputStream.close(); } } } 测试Controller类 /** * 限流测试 * @author huang * @PACKAGE_NAME cn.huangsm.advance.ratelimiter * @PROJECT_NAME advance-code * @date 2019/1/19 */ @RestController public class TestController { @RateLimitAspect @GetMapping(&quot;/test&quot;) public String test(){ return &quot;nihao&quot;; } } 测试阶段 上文中的编码阶段算是结束了，总体来说就是自定义一个限流注解方便以后每次的使用，其实我这里做的还不够细致，如果可以的话可以自定义速率，本例中默认速率为5.0表示：想象下我们需要处理一个任务列表，但我们不希望每秒的任务提交超过五个。 话不多说开始测试首先打开JMeter并发测试工具类，定义好线程组，以及Http请求和结果树，在线程组和HTTP请求中输入必要的参数JMeter线程组参数HTTP请求参数启动测试可以看到有10个结果在结果树中分别查看10个HTTP请求的响应调用成功限流请求结果 结论不管重试多少次都是10次请求有4次被限制访问，6次成功访问. 因此我重新设置线程次的参数为20个线程，重新发送请求后得到结果为:6次成功，14次失败，得出结论美妙的认为提交不超过六个。对于为什么是五个而不是六个，在RateLimiter的github看下issue了解。]]></content>
      <categories>
        <category>RateLimiter</category>
      </categories>
      <tags>
        <tag>RateLimiter</tag>
        <tag>限流</tag>
        <tag>自定义注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Docker部署maven私服]]></title>
    <url>%2F2019%2F01%2F18%2F%E4%BD%BF%E7%94%A8Docker%E9%83%A8%E7%BD%B2maven%E7%A7%81%E6%9C%8D%2F</url>
    <content type="text"><![CDATA[使用docker配置maven私服环境准备 安装docker环境使用docker -v查看服务器docker环境 下拉nexus3镜像使用命令，拉去最新版本的nexus镜像 docker pull sonatype/nexus3 启动镜像使用命令 docker run –rm -d –privileged=true -p 8088:8088 –name nexus -v /root/nexus-data:/var/nexus-data sonatype/nexus3 上面命令是指使用nexus3镜像创建并启动一个容器，然后指定暴露8081端口到对应主机的8081端口 将容器内部/var/nexus-data挂载到主机/root/nexus-data目录。 如果没有任何问题的话，Nexus应该是搭建成功了。 此时在浏览器输入：http://ip:8081即可看到以下页面：(ip为远程主机的ip地址) 修改nexus帐号密码 点击右上方的Sign in进行登录，初始账号密码为admin/admin123.请登录后修改密码如下图可以看到默认情况下Nexus会帮我们创建了几个仓库，仔细观察红色框住的地方，里面有几种仓库的类型，解释如下： proxy 远程仓库的代理，比如说nexus配置了一个central repository的proxy,当用户向这个proxy请求一个 artifact的时候，会现在本地查找，如果找不到，则会从远程仓库下载，然后返回给用户。 hosted 宿主仓库，用户可以把自己的一些仓库deploy到这个仓库中 group 仓库组，是nexus特有的概念，目的是将多个仓库整合，对用户暴露统一的地址，这样就不需要配置多个仓库地址。 下面我们仔细看一下里面的一些仓库。点击maven-central仓库:可以看到是一个proxy类型的仓库，他代理的远程仓库地址是https://repo1.maven.org/maven2/。后退，在进入maven-public查看:可以看到这是一个group类型的仓库，里面包含了maven-releases/maven-snapshots/maven-central仓库，意思是我们只需要在本地添加这个仓库，则可以依赖到上述3个仓库中的库了。]]></content>
      <categories>
        <category>maven私服</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>maven</tag>
        <tag>nexus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ribbon+Feign扩展]]></title>
    <url>%2F2019%2F01%2F18%2FRibbon-Feign%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[Ribbon扩展切换Ribbon加载策略，ribbon默认加载策略为懒加载，修改为饥饿加载ribbon: eager-load: enabled: true # 多个用,分隔 clients: microservice-provider-user Feign配置自定义【通用配置】feign: client: config: default: connectTimeout: 5000 readTimeout: 5000 loggerLevel: basic 配置优先级如果你不小心又使用了Java代码配置Feign，同时又使用了配置属性配置Feign，那么使用配置属性的优先级更高。配置属性配置的方式将会覆盖Java代码配置。 如果你想修改代码配置方式的优先级，可使用如下属性：feign.client.default-to-properties=false 。 压缩一些场景下，我们可能需要对请求或响应进行压缩，此时可使用以下属性启用Feign的压缩功能。 feign.compression.request.enabled=true feign.compression.response.enabled=true 对于请求的压缩，Feign还提供了更为详细的设置，例如： feign.compression.request.enabled=true feign.compression.request.mime-types=text/xml,application/xml,application/json feign.compression.request.min-request-size=2048 其中，feign.compression.request.mime-types 用于支持的媒体类型列表，默认是text/xml、application/xml以及application/json。feign.compression.request.min-request-size 用于设置请求的最小阈值，默认是2048。]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作-人事管理项目开发]]></title>
    <url>%2F2019%2F01%2F18%2F%E5%B7%A5%E4%BD%9C-%E4%BA%BA%E4%BA%8B%E7%AE%A1%E7%90%86%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[概述&nbsp;&nbsp;&nbsp;&nbsp;这是我的第二份工作的第二个项目，相比于第一个安全响应项目。这个项目是针对公司内部使用的人事管理系统。主要包含数据的导入和导出，已经公司人员的管理和工资记录的管理，另一个就是这个系统基本上都是我来开发的。除了框架是公司的一个同事搭建的，因为考虑到后期该系统会调用第三方接口因此框架设计使用的和公司一样的架子，引入公司封装好的一些启动器，关闭eureka注册中心后我就开始工作了，说是架子是公司同事搭建的其实本质的技术还是我来进行选择的。 技术选型1SpringBoot+Mybatis-plus+Mybatis代码生成器+POI+SpringCloud+OpenFeign+swagger2+公司的一些工具类和异常处理等 开发前期&nbsp;&nbsp;&nbsp;&nbsp; 因为需求很简单这样我就需要先考虑系统的优化，考虑到并发小因此选择使用version字段来实现乐观锁，使用mybatis-plus的乐观锁插件来控制接口的幂等性，从而解决防止同一人操作同一条数据带来的脏数据问题。对于一些工资计算算法进行封装工具类，创建常用的策略模式,这些做完后基本上就可以开始开发了。 感受&nbsp;&nbsp;&nbsp;&nbsp;这是我第二次开发前后端分离的项目，关于前后端分离对我来说是便捷的，起码我不需要去考虑前后端数据的交互了，但是这对刚刚进入工作不久的我不是个好事，因此在空闲时间我还是需要去研究前端学习一些前端的框架，保持自己的竞争力。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>工作日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术图谱]]></title>
    <url>%2F2019%2F01%2F17%2F%E6%8A%80%E6%9C%AF%E5%9B%BE%E8%B0%B1%2F</url>
    <content type="text"><![CDATA[这是我收集的一些技术图片，是我平时写的一下项目的架构，以及一些用到的流程图. Java技术图片 Java高级体系结构图 毕业设计框架图 异步化结构图]]></content>
      <categories>
        <category>技术图谱</category>
      </categories>
      <tags>
        <tag>technology_image</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[SB框架]SpringBoot中对多个配置文件中的属性进行提取的简易方法]]></title>
    <url>%2F2019%2F01%2F17%2FSB%E6%A1%86%E6%9E%B6-SpringBoot%E4%B8%AD%E5%AF%B9%E5%A4%9A%E4%B8%AA%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E5%B1%9E%E6%80%A7%E8%BF%9B%E8%A1%8C%E6%8F%90%E5%8F%96%E7%9A%84%E7%AE%80%E6%98%93%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[SpringBoot中对多个配置文件中的属性进行提取的简易方法 我们要提取一下属性:首先创建一个GirlProperties类 12345678910111213141516171819202122232425262728293031323334package com.springboot.properties;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;/** * @BelongsProject: springbootideademo * @BelongsPackage: com.springboot.properties * @Author: HUANG * @CreateTime: 2018-11-15 21:46 * @PROJECT_NAME: springbootideademo */@Component@ConfigurationProperties(prefix = &quot;girl&quot;)public class GirlProperties &#123; private String cupSize; private Integer age; public String getCupSize() &#123; return cupSize; &#125; public void setCupSize(String cupSize) &#123; this.cupSize = cupSize; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125; 调用方式: 通过属性调用:]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
</search>
